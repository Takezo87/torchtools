{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from torchtools.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch.nn as nn\n",
    "import torch as torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.1'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7616])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(torch.tensor([-2.])) * (1 - -1) + -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f01b00f21d0>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "t = torch.arange(-10,10).float()\n",
    "# plt.plot(t)\n",
    "plt.plot(F.softplus(t, beta=1))\n",
    "plt.plot(F.softplus(t, beta=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# This is an unofficial PyTorch implementation by Ignacio Oguiza - oguiza@gmail.com based on:\n",
    "\n",
    "# Fawaz, H. I., Lucas, B., Forestier, G., Pelletier, C., Schmidt, D. F., Weber, J., ... & Petitjean, F. (2019). InceptionTime: Finding AlexNet for Time Series Classification. arXiv preprint arXiv:1909.04939.\n",
    "# Official InceptionTime tensorflow implementation: https://github.com/hfawaz/InceptionTime\n",
    "\n",
    "\n",
    "def noop(x):\n",
    "    return x\n",
    "\n",
    "def shortcut(c_in, c_out):\n",
    "    return nn.Sequential(*[nn.Conv1d(c_in, c_out, kernel_size=1), \n",
    "                           nn.BatchNorm1d(c_out)])\n",
    "    \n",
    "class Inception(nn.Module):\n",
    "    def __init__(self, c_in, bottleneck=32, ks=40, nb_filters=32):\n",
    "\n",
    "        super().__init__()\n",
    "        self.bottleneck = nn.Conv1d(c_in, bottleneck, 1) if bottleneck and c_in > 1 else noop\n",
    "        mts_feat = bottleneck or c_in\n",
    "        conv_layers = []\n",
    "        kss = [ks // (2**i) for i in range(3)]\n",
    "        # ensure odd kss until nn.Conv1d with padding='same' is available in pytorch 1.3\n",
    "        kss = [ksi if ksi % 2 != 0 else ksi - 1 for ksi in kss]  \n",
    "        for i in range(len(kss)):\n",
    "            conv_layers.append(\n",
    "                nn.Conv1d(mts_feat, nb_filters, kernel_size=kss[i], padding=kss[i] // 2))\n",
    "        self.conv_layers = nn.ModuleList(conv_layers)\n",
    "        self.maxpool = nn.MaxPool1d(3, stride=1, padding=1)\n",
    "        self.conv = nn.Conv1d(c_in, nb_filters, kernel_size=1)\n",
    "        self.bn = nn.BatchNorm1d(nb_filters * 4)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_tensor = x.to(torch.float)\n",
    "        x = self.bottleneck(input_tensor)\n",
    "        for i in range(3):\n",
    "            out_ = self.conv_layers[i](x)\n",
    "            if i == 0: out = out_\n",
    "            else: out = torch.cat((out, out_), 1)\n",
    "        mp = self.conv(self.maxpool(input_tensor))\n",
    "        inc_out = torch.cat((out, mp), 1)\n",
    "        return self.act(self.bn(inc_out))\n",
    "\n",
    "\n",
    "class InceptionBlock(nn.Module):\n",
    "    def __init__(self,c_in,bottleneck=32,ks=40,nb_filters=32,residual=True,depth=6):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual = residual\n",
    "        self.depth = depth\n",
    "\n",
    "        #inception & residual layers\n",
    "        inc_mods = []\n",
    "        res_layers = []\n",
    "        res = 0\n",
    "        for d in range(depth):\n",
    "            inc_mods.append(\n",
    "                Inception(c_in if d == 0 else nb_filters * 4, bottleneck=bottleneck if d > 0 else 0,ks=ks,\n",
    "                          nb_filters=nb_filters))\n",
    "            if self.residual and d % 3 == 2:\n",
    "                res_layers.append(shortcut(c_in if res == 0 else nb_filters * 4, nb_filters * 4))\n",
    "                res += 1\n",
    "            else: res_layer = res_layers.append(None)\n",
    "        self.inc_mods = nn.ModuleList(inc_mods)\n",
    "        self.res_layers = nn.ModuleList(res_layers)\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        for d, l in enumerate(range(self.depth)):\n",
    "            x = self.inc_mods[d](x)\n",
    "            if self.residual and d % 3 == 2:\n",
    "                res = self.res_layers[d](res)\n",
    "                x += res\n",
    "                res = x\n",
    "                x = self.act(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export    \n",
    "class InceptionTime(nn.Module):\n",
    "    def __init__(self,c_in,c_out,bottleneck=32,ks=40,nb_filters=32,residual=True,depth=6):\n",
    "        super().__init__()\n",
    "        self.block = InceptionBlock(c_in,bottleneck=bottleneck,ks=ks,nb_filters=nb_filters,\n",
    "                                    residual=residual,depth=depth)\n",
    "        self.gap = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(nb_filters * 4, c_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        x = self.gap(x).squeeze(-1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Sigmoid(nn.Module):\n",
    "    '''\n",
    "    sigmoid layer\n",
    "    '''\n",
    "    def __init__(self, low, high):\n",
    "        super().__init__()\n",
    "        self.high, self.low = high, low\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(x)*(self.high-self.low)+self.low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class InceptionTimeSgmOld(nn.Module):\n",
    "    '''\n",
    "    add a sigmoid layer to InceptionTime to get the ouput in a certain range\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, n_in, n_out):\n",
    "        super().__init__()\n",
    "        nn.Sequential()\n",
    "        self.inc = InceptionTime(n_in, n_out)\n",
    "        self.low, self.high = -1., 1.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.inc(x)) * (self.high - self.low) + self.low\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class InceptionTimeSgm(nn.Module):\n",
    "    '''\n",
    "    add a sigmoid layer to InceptionTime to get the ouput in a certain range\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, n_in, n_out, range=(-1,1)):\n",
    "        super().__init__()\n",
    "        self.mod = nn.Sequential(InceptionTime(n_in, n_out), Sigmoid(*range))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        return self.mod(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class InceptionTimeD(nn.Module):\n",
    "    '''\n",
    "    add a sigmoid layer to InceptionTime to get the ouput in a certain range\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, n_in, n_out):\n",
    "        super().__init__()\n",
    "        self.mod = nn.Sequential(InceptionTime(n_in, n_out), Sigmoid(-1., 1.))\n",
    "        \n",
    "    def forward(self, xc, xd):\n",
    "        x = torch.cat([xc.float(), xd.float()], dim=-2)\n",
    "        x = x.float()\n",
    "#         print(f'InceptionTimeSgm dtype {x.dtype}')\n",
    "        return self.mod(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class InceptionTimeVar(nn.Module):\n",
    "    '''\n",
    "    output mean and variance\n",
    "    regression model, sigmoid for the mean output optional\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, n_in, n_out, meanrange=None):\n",
    "        super().__init__()\n",
    "        models  = [InceptionTime(n_in, n_out+1)]\n",
    "        if meanrange:\n",
    "            self.sigmoid = Sigmoid(*meanrange)\n",
    "        self.mod = nn.Sequential(*models)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        output = self.mod(x)\n",
    "        ## enforce positivity of sigma^2\n",
    "        ##output_sig_pos = tf.log(1 + tf.exp(output_sig)) + 1e-06\n",
    "#         output[:,-1] = (output[:,-1].exp()+1).log_() + 1e-06\n",
    "        output[:,-1] = F.softplus(output[:,-1])\n",
    "        \n",
    "        if getattr(self, 'sigmoid', None): output[:,:-1] = self.sigmoid(output[:,:-1])\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model sanity checks\n",
    "xb = torch.randn((128,10,100))\n",
    "yb = torch.rand(128,1)\n",
    "model = InceptionTimeVar(10,1)\n",
    "\n",
    "preds = model(xb)\n",
    "assert preds.shape == (128,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def nll_regression(preds, y_true, c=5):\n",
    "    '''\n",
    "    negative log likelihood loss for regression, both mu and sigma are predicted\n",
    "    \n",
    "    Simple and Scalable Predictive UncertaintyEstimation using Deep Ensembles\n",
    "    Balaji Lakshminarayanan, Alexander Pritzel, Charles Blundell, DeepMind\n",
    "\n",
    "    '''\n",
    "    \n",
    "    s1 = 0.5*preds[:,1].log() \n",
    "    s2 = 0.5*(yb.squeeze()-preds[:,0]).pow(2).div(preds[:,1])\n",
    "    loss = (s1+s2).mean() + c\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def nll_leaky_loss(preds, y_true, c=5, alpha=0.5):\n",
    "    '''\n",
    "    leaky_loss with variance\n",
    "    \n",
    "    Simple and Scalable Predictive UncertaintyEstimation using Deep Ensembles\n",
    "    Balaji Lakshminarayanan, Alexander Pritzel, Charles Blundell, DeepMind\n",
    "\n",
    "    '''\n",
    "    \n",
    "    s1 = 0.5*preds[:,1].log() \n",
    "    l1 = -F.leaky_relu(preds[:,0], alpha)*y_true.float().squeeze()\n",
    "    s2 = 0.5*(l1.div(preds[:,1]+1)) ## +1 to prevent optimizing for variance, maybe just an artifical problem\n",
    "    loss = (s1+s2).mean() + c\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.7944, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = nll_leaky_loss(preds, yb)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_var = InceptionTimeVar(10,1,meanrange=(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.7193, grad_fn=<AddBackward0>)\n",
      "tensor(4.6247, grad_fn=<AddBackward0>)\n",
      "tensor(4.5210, grad_fn=<AddBackward0>)\n",
      "tensor(4.4083, grad_fn=<AddBackward0>)\n",
      "tensor(4.2872, grad_fn=<AddBackward0>)\n",
      "tensor(4.1583, grad_fn=<AddBackward0>)\n",
      "tensor(4.0228, grad_fn=<AddBackward0>)\n",
      "tensor(3.8817, grad_fn=<AddBackward0>)\n",
      "tensor(3.7362, grad_fn=<AddBackward0>)\n",
      "tensor(3.5873, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#simple training loop\n",
    "\n",
    "lr = 0.01\n",
    "epochs = 10\n",
    "loss_fn = nll_regression\n",
    "m = model_var\n",
    "loss_fn = nll_leaky_loss\n",
    "\n",
    "\n",
    "for i in range(epochs):\n",
    "    preds = m(xb)\n",
    "    loss = loss_fn(preds, yb)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        for p in m.parameters():\n",
    "            p.sub_(lr*p.grad)\n",
    "    m.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4946)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unweighted_profit(m(xb)[:,0], yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_var = InceptionTimeVar(10,1)\n",
    "opt = torch.optim.Adam(model_var.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.4290, grad_fn=<AddBackward0>)\n",
      "tensor(5.0269, grad_fn=<AddBackward0>)\n",
      "tensor(4.8126, grad_fn=<AddBackward0>)\n",
      "tensor(4.6762, grad_fn=<AddBackward0>)\n",
      "tensor(4.5883, grad_fn=<AddBackward0>)\n",
      "tensor(4.5294, grad_fn=<AddBackward0>)\n",
      "tensor(4.4923, grad_fn=<AddBackward0>)\n",
      "tensor(4.4652, grad_fn=<AddBackward0>)\n",
      "tensor(4.4323, grad_fn=<AddBackward0>)\n",
      "tensor(4.3830, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "m = model_var\n",
    "for i in range(epochs):\n",
    "    preds = m(xb)\n",
    "    loss = nll_regression(preds, yb)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.1520, grad_fn=<AddBackward0>)\n",
      "tensor(0.)\n",
      "tensor(5.1394, grad_fn=<AddBackward0>)\n",
      "tensor(0.)\n",
      "tensor(5.1270, grad_fn=<AddBackward0>)\n",
      "tensor(0.)\n",
      "tensor(5.1148, grad_fn=<AddBackward0>)\n",
      "tensor(0.)\n",
      "tensor(5.1026, grad_fn=<AddBackward0>)\n",
      "tensor(0.)\n",
      "tensor(5.0905, grad_fn=<AddBackward0>)\n",
      "tensor(0.)\n",
      "tensor(5.0783, grad_fn=<AddBackward0>)\n",
      "tensor(0.)\n",
      "tensor(5.0660, grad_fn=<AddBackward0>)\n",
      "tensor(0.)\n",
      "tensor(5.0535, grad_fn=<AddBackward0>)\n",
      "tensor(0.)\n",
      "tensor(5.0408, grad_fn=<AddBackward0>)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "model_var = InceptionTimeVar(10,1,meanrange=(-10,5))\n",
    "m = model_var\n",
    "loss_fn = partial(nll_leaky_loss, alpha=0.5)\n",
    "epochs=10\n",
    "\n",
    "opt = torch.optim.Adam(m.parameters(), lr=1e-4)\n",
    "\n",
    "for i in range(epochs):\n",
    "    preds = m(xb)\n",
    "    loss = loss_fn(preds, yb)\n",
    "    print(loss)\n",
    "    print(unweighted_profit(preds[:,0], yb))\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unweighted_profit(m(xb)[:,0],yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.17,  0.8 ],\n",
       "       [-1.8 ,  0.75],\n",
       "       [-3.86,  0.76],\n",
       "       [-3.1 ,  0.73],\n",
       "       [-2.33,  0.75],\n",
       "       [-3.93,  0.74],\n",
       "       [-2.93,  0.75],\n",
       "       [-2.35,  0.72],\n",
       "       [-3.42,  0.78],\n",
       "       [-3.2 ,  0.74],\n",
       "       [-1.83,  0.83],\n",
       "       [-3.06,  0.71],\n",
       "       [-3.48,  0.8 ],\n",
       "       [-4.16,  0.73],\n",
       "       [-3.68,  0.76],\n",
       "       [-3.1 ,  0.69],\n",
       "       [-1.5 ,  0.76],\n",
       "       [-1.45,  0.79],\n",
       "       [-5.18,  0.68],\n",
       "       [-2.34,  0.76],\n",
       "       [-4.19,  0.66],\n",
       "       [-4.51,  0.66],\n",
       "       [-2.35,  0.8 ],\n",
       "       [-2.4 ,  0.82],\n",
       "       [-2.24,  0.73],\n",
       "       [-3.72,  0.72],\n",
       "       [-3.03,  0.74],\n",
       "       [-3.01,  0.72],\n",
       "       [-2.87,  0.77],\n",
       "       [-4.23,  0.71],\n",
       "       [-2.57,  0.83],\n",
       "       [-3.53,  0.7 ],\n",
       "       [-3.51,  0.74],\n",
       "       [-2.64,  0.68],\n",
       "       [-2.39,  0.78],\n",
       "       [-2.61,  0.76],\n",
       "       [-1.85,  0.77],\n",
       "       [-2.53,  0.76],\n",
       "       [-1.52,  0.74],\n",
       "       [-2.99,  0.74],\n",
       "       [-4.16,  0.75],\n",
       "       [-2.63,  0.7 ],\n",
       "       [-3.39,  0.71],\n",
       "       [-1.79,  0.76],\n",
       "       [-3.11,  0.73],\n",
       "       [-3.11,  0.67],\n",
       "       [-3.37,  0.71],\n",
       "       [-3.49,  0.81],\n",
       "       [-2.36,  0.75],\n",
       "       [-2.  ,  0.77],\n",
       "       [-3.13,  0.74],\n",
       "       [-2.73,  0.78],\n",
       "       [-3.4 ,  0.7 ],\n",
       "       [-2.06,  0.76],\n",
       "       [-1.51,  0.71],\n",
       "       [-3.2 ,  0.67],\n",
       "       [-1.8 ,  0.76],\n",
       "       [-2.58,  0.76],\n",
       "       [-2.24,  0.71],\n",
       "       [-3.05,  0.72],\n",
       "       [-2.82,  0.74],\n",
       "       [-2.73,  0.82],\n",
       "       [-4.15,  0.65],\n",
       "       [-2.79,  0.76],\n",
       "       [-1.93,  0.79],\n",
       "       [-2.85,  0.74],\n",
       "       [-3.91,  0.77],\n",
       "       [-4.43,  0.72],\n",
       "       [-2.14,  0.74],\n",
       "       [-4.33,  0.66],\n",
       "       [-2.22,  0.86],\n",
       "       [-3.27,  0.71],\n",
       "       [-2.87,  0.78],\n",
       "       [-4.13,  0.75],\n",
       "       [-4.44,  0.66],\n",
       "       [-3.48,  0.72],\n",
       "       [-3.49,  0.71],\n",
       "       [-2.37,  0.79],\n",
       "       [-1.89,  0.79],\n",
       "       [-4.88,  0.75],\n",
       "       [-2.9 ,  0.77],\n",
       "       [-3.53,  0.74],\n",
       "       [-3.69,  0.76],\n",
       "       [-3.33,  0.74],\n",
       "       [-2.63,  0.83],\n",
       "       [-2.1 ,  0.73],\n",
       "       [-2.99,  0.73],\n",
       "       [-2.43,  0.75],\n",
       "       [-2.7 ,  0.78],\n",
       "       [-2.76,  0.75],\n",
       "       [-3.92,  0.77],\n",
       "       [-1.77,  0.8 ],\n",
       "       [-1.19,  0.8 ],\n",
       "       [-3.92,  0.72],\n",
       "       [-1.82,  0.74],\n",
       "       [-3.02,  0.73],\n",
       "       [-3.69,  0.77],\n",
       "       [-1.8 ,  0.78],\n",
       "       [-2.65,  0.84],\n",
       "       [-2.96,  0.72],\n",
       "       [-3.71,  0.79],\n",
       "       [-4.7 ,  0.68],\n",
       "       [-1.71,  0.78],\n",
       "       [-2.74,  0.79],\n",
       "       [-1.77,  0.88],\n",
       "       [-1.62,  0.84],\n",
       "       [-3.2 ,  0.81],\n",
       "       [-3.12,  0.74],\n",
       "       [-2.73,  0.8 ],\n",
       "       [-1.64,  0.8 ],\n",
       "       [-4.35,  0.68],\n",
       "       [-2.69,  0.77],\n",
       "       [-1.41,  0.77],\n",
       "       [-0.88,  0.78],\n",
       "       [-1.67,  0.75],\n",
       "       [-4.48,  0.7 ],\n",
       "       [-3.3 ,  0.78],\n",
       "       [-1.41,  0.83],\n",
       "       [-1.58,  0.74],\n",
       "       [-1.22,  0.73],\n",
       "       [-4.23,  0.76],\n",
       "       [-3.92,  0.69],\n",
       "       [-2.95,  0.7 ],\n",
       "       [-2.48,  0.82],\n",
       "       [-2.73,  0.71],\n",
       "       [-3.36,  0.71],\n",
       "       [-3.71,  0.76],\n",
       "       [-3.5 ,  0.82]], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(m(xb).detach().numpy(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.zeros(128,1)\n",
    "x2 = torch.ones(128,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_p = torch.cat([x1,x2], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.1679)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll_regression(x_p, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1095, 1.1603, 1.1815, 1.1474, 1.1794, 1.2441, 1.1129, 1.1118, 1.1436,\n",
       "        1.0182, 1.0465, 0.9802, 1.2020, 1.0536, 1.2171, 1.0186, 0.9801, 1.0531,\n",
       "        0.9563, 1.1134, 0.9458, 0.9907, 1.2233, 1.0600, 1.1663, 1.0706, 1.1901,\n",
       "        1.1641, 1.0343, 1.1157, 1.0153, 0.9864, 1.1957, 1.1244, 1.0309, 1.0621,\n",
       "        1.0693, 0.9547, 1.0510, 1.2013, 1.1592, 1.1030, 1.1770, 1.1139, 1.1817,\n",
       "        1.0980, 0.9601, 1.1749, 1.1532, 1.2252, 1.0789, 1.1025, 1.0111, 1.1277,\n",
       "        1.0475, 1.0164, 1.2084, 0.9721, 1.0259, 1.0407, 1.1503, 1.1958, 1.1083,\n",
       "        1.1249, 1.2411, 0.9974, 0.9957, 1.0811, 1.0228, 0.9572, 1.0547, 1.0277,\n",
       "        0.9785, 1.2495, 0.9694, 1.0753, 1.2210, 1.1757, 1.1876, 1.0128, 0.9789,\n",
       "        1.2055, 1.0980, 1.0387, 1.0779, 1.0374, 0.9951, 1.1748, 1.1349, 0.9995,\n",
       "        1.0444, 1.1635, 1.2683, 1.0247, 1.0698, 1.0439, 1.1007, 1.1141, 1.1531,\n",
       "        1.0812])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=torch.randn(100)\n",
    "torch.sigmoid(t)*(1.3-0.9)+0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5913, 0.7275, 0.6183, 0.5189, 0.6616, 0.6775, 0.7000, 0.7109, 0.5841,\n",
       "        0.6315, 0.7232, 0.5411, 0.6829, 0.7191, 0.5508, 0.5162, 0.7131, 0.7207,\n",
       "        0.5158, 0.7128, 0.6950, 0.5704, 0.6903, 0.7302, 0.5538, 0.5747, 0.6909,\n",
       "        0.6565, 0.6839, 0.5790, 0.7144, 0.6901, 0.7021, 0.5765, 0.6108, 0.6747,\n",
       "        0.7227, 0.7173, 0.7185, 0.5146, 0.6119, 0.7285, 0.6731, 0.7155, 0.5086,\n",
       "        0.6942, 0.6788, 0.5290, 0.5611, 0.7158, 0.6941, 0.6132, 0.6277, 0.6278,\n",
       "        0.6790, 0.6894, 0.5219, 0.5740, 0.7114, 0.7063, 0.6639, 0.5869, 0.6681,\n",
       "        0.6533, 0.6566, 0.6462, 0.6430, 0.7135, 0.6631, 0.5016, 0.6098, 0.6257,\n",
       "        0.7183, 0.7010, 0.7022, 0.6265, 0.6993, 0.7100, 0.6913, 0.5921, 0.6228,\n",
       "        0.7095, 0.5008, 0.6969, 0.5941, 0.5423, 0.7106, 0.6369, 0.6663, 0.6127,\n",
       "        0.6994, 0.5936, 0.6483, 0.5113, 0.5580, 0.5715, 0.5325, 0.6815, 0.6862,\n",
       "        0.6572])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_random_results(size):\n",
    "    high, low = 1.2, 0.9\n",
    "    res=torch.randn(size)\n",
    "    res = torch.sigmoid(res)*(high-low)+low\n",
    "    res *= -100\n",
    "    res[torch.rand(size)>0.5] = 100.\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb = _create_random_results((128,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(38.1166, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll_leaky_loss(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-7.1893)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_var = InceptionTimeVar(10,1,meanrange=(-1,1))\n",
    "m = model_var\n",
    "loss_fn = partial(nll_leaky_loss, alpha=0.5)\n",
    "epochs=20\n",
    "\n",
    "opt = torch.optim.Adam(m.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-5.8582, grad_fn=<AddBackward0>)\n",
      "tensor(-3.5385)\n",
      "tensor(-6.6025, grad_fn=<AddBackward0>)\n",
      "tensor(-3.4823)\n",
      "tensor(-7.3244, grad_fn=<AddBackward0>)\n",
      "tensor(-3.4261)\n",
      "tensor(-8.0178, grad_fn=<AddBackward0>)\n",
      "tensor(-3.4261)\n",
      "tensor(-8.6825, grad_fn=<AddBackward0>)\n",
      "tensor(-3.4261)\n",
      "tensor(-9.3129, grad_fn=<AddBackward0>)\n",
      "tensor(-3.4261)\n",
      "tensor(-9.9017, grad_fn=<AddBackward0>)\n",
      "tensor(-3.4261)\n",
      "tensor(-10.4434, grad_fn=<AddBackward0>)\n",
      "tensor(-3.4261)\n",
      "tensor(-10.9383, grad_fn=<AddBackward0>)\n",
      "tensor(-3.4261)\n",
      "tensor(-11.3915, grad_fn=<AddBackward0>)\n",
      "tensor(-3.4261)\n",
      "tensor(-11.8113, grad_fn=<AddBackward0>)\n",
      "tensor(-3.4261)\n",
      "tensor(-12.2062, grad_fn=<AddBackward0>)\n",
      "tensor(-3.4261)\n",
      "tensor(-12.5798, grad_fn=<AddBackward0>)\n",
      "tensor(-3.4261)\n",
      "tensor(-12.9334, grad_fn=<AddBackward0>)\n",
      "tensor(-3.4261)\n",
      "tensor(-13.2676, grad_fn=<AddBackward0>)\n",
      "tensor(-3.4261)\n",
      "tensor(-13.5844, grad_fn=<AddBackward0>)\n",
      "tensor(-3.4261)\n",
      "tensor(-13.8866, grad_fn=<AddBackward0>)\n",
      "tensor(-3.4261)\n",
      "tensor(-14.1788, grad_fn=<AddBackward0>)\n",
      "tensor(-3.4261)\n",
      "tensor(-14.4650, grad_fn=<AddBackward0>)\n",
      "tensor(-3.4261)\n",
      "tensor(-14.7484, grad_fn=<AddBackward0>)\n",
      "tensor(-3.4261)\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    preds = m(xb)\n",
    "    loss = loss_fn(preds, yb)\n",
    "    print(loss)\n",
    "    print(unweighted_profit(preds[:,0], yb))\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-9317.9912, grad_fn=<AddBackward0>)\n",
      "tensor(-3.7070)\n",
      "tensor(-30340.9004, grad_fn=<AddBackward0>)\n",
      "tensor(-3.7070)\n",
      "tensor(-90235.2656, grad_fn=<AddBackward0>)\n",
      "tensor(-3.8755)\n",
      "tensor(-214640.3750, grad_fn=<AddBackward0>)\n",
      "tensor(-3.9878)\n",
      "tensor(-359202.5312, grad_fn=<AddBackward0>)\n",
      "tensor(-4.0440)\n",
      "tensor(-397443.5000, grad_fn=<AddBackward0>)\n",
      "tensor(-4.1001)\n",
      "tensor(-444806.8125, grad_fn=<AddBackward0>)\n",
      "tensor(-4.1001)\n",
      "tensor(-444799.9375, grad_fn=<AddBackward0>)\n",
      "tensor(-4.1001)\n",
      "tensor(-444794.8438, grad_fn=<AddBackward0>)\n",
      "tensor(-4.1001)\n",
      "tensor(-444791.0625, grad_fn=<AddBackward0>)\n",
      "tensor(-4.1001)\n",
      "tensor(-444788.1875, grad_fn=<AddBackward0>)\n",
      "tensor(-4.1001)\n",
      "tensor(-444786., grad_fn=<AddBackward0>)\n",
      "tensor(-4.1563)\n",
      "tensor(-444784.2500, grad_fn=<AddBackward0>)\n",
      "tensor(-4.1563)\n",
      "tensor(-444782.7812, grad_fn=<AddBackward0>)\n",
      "tensor(-4.3248)\n",
      "tensor(-444781.6250, grad_fn=<AddBackward0>)\n",
      "tensor(-4.3248)\n",
      "tensor(-444780.6250, grad_fn=<AddBackward0>)\n",
      "tensor(-4.4933)\n",
      "tensor(-444779.7500, grad_fn=<AddBackward0>)\n",
      "tensor(-4.6056)\n",
      "tensor(-444778.9688, grad_fn=<AddBackward0>)\n",
      "tensor(-4.6618)\n",
      "tensor(-444778.1875, grad_fn=<AddBackward0>)\n",
      "tensor(-4.6618)\n",
      "tensor(-444777.6250, grad_fn=<AddBackward0>)\n",
      "tensor(-4.8303)\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    preds = m(xb)\n",
    "    loss = loss_fn(preds, yb)\n",
    "    print(loss)\n",
    "    print(unweighted_profit(preds[:,0], yb))\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8102,  0.3178],\n",
       "        [-0.5239,  0.6837],\n",
       "        [ 0.7969,  0.3428],\n",
       "        [ 0.8238,  0.3040],\n",
       "        [-0.6941,  0.6855],\n",
       "        [-0.5750,  0.6674],\n",
       "        [ 0.8599,  0.2828],\n",
       "        [-0.6396,  0.6581],\n",
       "        [-0.6178,  0.6803],\n",
       "        [-0.6704,  0.7044],\n",
       "        [ 0.7746,  0.3350],\n",
       "        [-0.4117,  0.6518],\n",
       "        [ 0.7976,  0.3109],\n",
       "        [-0.6089,  0.6810],\n",
       "        [ 0.7839,  0.3432],\n",
       "        [ 0.8260,  0.3253],\n",
       "        [-0.6338,  0.7247],\n",
       "        [ 0.8098,  0.2983],\n",
       "        [-0.7259,  0.6800],\n",
       "        [ 0.7886,  0.3059],\n",
       "        [-0.4271,  0.6483],\n",
       "        [ 0.8405,  0.2760],\n",
       "        [ 0.8067,  0.3065],\n",
       "        [ 0.7801,  0.3093],\n",
       "        [-0.6602,  0.6911],\n",
       "        [ 0.7929,  0.3536],\n",
       "        [ 0.7634,  0.3492],\n",
       "        [-0.7213,  0.6978],\n",
       "        [-0.6269,  0.7063],\n",
       "        [ 0.7730,  0.3216],\n",
       "        [ 0.8197,  0.2993],\n",
       "        [ 0.8387,  0.2986],\n",
       "        [ 0.8390,  0.2937],\n",
       "        [ 0.7963,  0.3075],\n",
       "        [-0.6434,  0.7037],\n",
       "        [-0.5897,  0.6951],\n",
       "        [ 0.8069,  0.3289],\n",
       "        [-0.5431,  0.6712],\n",
       "        [-0.5118,  0.6954],\n",
       "        [ 0.8070,  0.3409],\n",
       "        [-0.5894,  0.6192],\n",
       "        [ 0.8343,  0.2936],\n",
       "        [-0.5271,  0.6456],\n",
       "        [-0.6154,  0.6583],\n",
       "        [ 0.8333,  0.3005],\n",
       "        [-0.6157,  0.7255],\n",
       "        [-0.5690,  0.6801],\n",
       "        [ 0.8136,  0.2901],\n",
       "        [ 0.8361,  0.3272],\n",
       "        [-0.5298,  0.7013],\n",
       "        [ 0.8339,  0.3044],\n",
       "        [-0.6459,  0.6985],\n",
       "        [-0.6424,  0.7266],\n",
       "        [-0.5261,  0.6575],\n",
       "        [ 0.8036,  0.3322],\n",
       "        [ 0.8275,  0.3105],\n",
       "        [ 0.8149,  0.3106],\n",
       "        [ 0.8105,  0.2903],\n",
       "        [-0.4714,  0.6741],\n",
       "        [ 0.8174,  0.3127],\n",
       "        [ 0.7837,  0.3433],\n",
       "        [-0.6115,  0.6627],\n",
       "        [-0.6071,  0.7099],\n",
       "        [ 0.8061,  0.3094],\n",
       "        [ 0.8387,  0.3063],\n",
       "        [-0.6945,  0.7227],\n",
       "        [ 0.8292,  0.2883],\n",
       "        [ 0.8283,  0.2970],\n",
       "        [ 0.8274,  0.2986],\n",
       "        [ 0.8054,  0.3035],\n",
       "        [ 0.8054,  0.3292],\n",
       "        [-0.5444,  0.6650],\n",
       "        [-0.6767,  0.7035],\n",
       "        [-0.5492,  0.6872],\n",
       "        [-0.5918,  0.6855],\n",
       "        [-0.6481,  0.6900],\n",
       "        [ 0.8205,  0.3029],\n",
       "        [-0.5748,  0.6860],\n",
       "        [ 0.8184,  0.2873],\n",
       "        [-0.5876,  0.6837],\n",
       "        [ 0.7957,  0.3320],\n",
       "        [ 0.8325,  0.2979],\n",
       "        [-0.5924,  0.7199],\n",
       "        [ 0.8353,  0.3017],\n",
       "        [ 0.8656,  0.2744],\n",
       "        [-0.5516,  0.6911],\n",
       "        [-0.6387,  0.6578],\n",
       "        [ 0.8391,  0.3027],\n",
       "        [-0.5607,  0.6783],\n",
       "        [-0.5742,  0.6996],\n",
       "        [-0.5799,  0.6655],\n",
       "        [-0.5217,  0.6808],\n",
       "        [ 0.8239,  0.3124],\n",
       "        [-0.5923,  0.6208],\n",
       "        [-0.6012,  0.6716],\n",
       "        [ 0.8322,  0.2753],\n",
       "        [-0.5909,  0.6835],\n",
       "        [-0.4380,  0.6229],\n",
       "        [ 0.7928,  0.3090],\n",
       "        [-0.5745,  0.6928],\n",
       "        [ 0.7712,  0.3466],\n",
       "        [ 0.8064,  0.3226],\n",
       "        [-0.6104,  0.6598],\n",
       "        [ 0.8143,  0.3111],\n",
       "        [-0.5438,  0.6740],\n",
       "        [ 0.7976,  0.3137],\n",
       "        [-0.4920,  0.6633],\n",
       "        [-0.7181,  0.7156],\n",
       "        [-0.5889,  0.6741],\n",
       "        [ 0.7896,  0.3479],\n",
       "        [ 0.7899,  0.3399],\n",
       "        [-0.6214,  0.6625],\n",
       "        [ 0.8369,  0.2983],\n",
       "        [-0.5505,  0.6481],\n",
       "        [ 0.8312,  0.3085],\n",
       "        [-0.6113,  0.6070],\n",
       "        [-0.6210,  0.6519],\n",
       "        [-0.5778,  0.6665],\n",
       "        [-0.6429,  0.6874],\n",
       "        [ 0.8278,  0.2942],\n",
       "        [-0.6555,  0.7006],\n",
       "        [-0.5862,  0.6934],\n",
       "        [-0.5371,  0.7025],\n",
       "        [-0.6234,  0.6196],\n",
       "        [-0.6825,  0.6794],\n",
       "        [ 0.7964,  0.3077],\n",
       "        [-0.6964,  0.6912],\n",
       "        [ 0.8083,  0.2941]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.1196, grad_fn=<MulBackward0>)\n",
      "tensor(0.)\n",
      "tensor(-0.1918, grad_fn=<MulBackward0>)\n",
      "tensor(0.)\n",
      "tensor(-0.2503, grad_fn=<MulBackward0>)\n",
      "tensor(0.)\n",
      "tensor(-0.3002, grad_fn=<MulBackward0>)\n",
      "tensor(0.)\n",
      "tensor(-0.3442, grad_fn=<MulBackward0>)\n",
      "tensor(0.)\n",
      "tensor(-0.3833, grad_fn=<MulBackward0>)\n",
      "tensor(0.)\n",
      "tensor(-0.4182, grad_fn=<MulBackward0>)\n",
      "tensor(0.)\n",
      "tensor(-0.4494, grad_fn=<MulBackward0>)\n",
      "tensor(0.)\n",
      "tensor(-0.4771, grad_fn=<MulBackward0>)\n",
      "tensor(0.)\n",
      "tensor(-0.5019, grad_fn=<MulBackward0>)\n",
      "tensor(0.)\n",
      "tensor(-0.5238, grad_fn=<MulBackward0>)\n",
      "tensor(0.)\n",
      "tensor(-0.5433, grad_fn=<MulBackward0>)\n",
      "tensor(0.)\n",
      "tensor(-0.5605, grad_fn=<MulBackward0>)\n",
      "tensor(0.)\n",
      "tensor(-0.5757, grad_fn=<MulBackward0>)\n",
      "tensor(0.)\n",
      "tensor(-0.5891, grad_fn=<MulBackward0>)\n",
      "tensor(0.)\n",
      "tensor(-0.6010, grad_fn=<MulBackward0>)\n",
      "tensor(0.)\n",
      "tensor(-0.6116, grad_fn=<MulBackward0>)\n",
      "tensor(0.)\n",
      "tensor(-0.6209, grad_fn=<MulBackward0>)\n",
      "tensor(0.)\n",
      "tensor(-0.6293, grad_fn=<MulBackward0>)\n",
      "tensor(0.)\n",
      "tensor(-0.6368, grad_fn=<MulBackward0>)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "model_mean = InceptionTimeSgm(10,1, range=(-1,1))\n",
    "m = model_mean\n",
    "loss_fn = partial(leaky_loss, alpha=0.1)\n",
    "# loss_fn = F.mse_loss\n",
    "\n",
    "epochs=20\n",
    "\n",
    "opt = torch.optim.Adam(m.parameters(), lr=1e-3)\n",
    "\n",
    "for i in range(epochs):\n",
    "    preds = m(xb)\n",
    "    loss = loss_fn(preds, yb)\n",
    "    print(loss)\n",
    "    print(unweighted_profit(preds, yb))\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 59.69],\n",
       "       [-44.33],\n",
       "       [ 32.03],\n",
       "       [ 48.34],\n",
       "       [-71.35],\n",
       "       [-90.21],\n",
       "       [ 31.71],\n",
       "       [-74.66],\n",
       "       [-63.18],\n",
       "       [-85.05],\n",
       "       [ 27.3 ],\n",
       "       [-40.44],\n",
       "       [ 22.68],\n",
       "       [-72.75],\n",
       "       [ 16.64],\n",
       "       [ 59.72],\n",
       "       [-79.17],\n",
       "       [ 51.5 ],\n",
       "       [-74.85],\n",
       "       [ 15.23],\n",
       "       [-46.47],\n",
       "       [ 54.3 ],\n",
       "       [ 39.65],\n",
       "       [ 40.41],\n",
       "       [-78.55],\n",
       "       [ 23.05],\n",
       "       [ 19.68],\n",
       "       [-73.84],\n",
       "       [-63.5 ],\n",
       "       [ 15.34],\n",
       "       [ 32.78],\n",
       "       [ 43.81],\n",
       "       [ 47.92],\n",
       "       [ 21.04],\n",
       "       [-72.07],\n",
       "       [-62.32],\n",
       "       [ 55.13],\n",
       "       [-50.59],\n",
       "       [-22.92],\n",
       "       [ 25.04],\n",
       "       [-52.25],\n",
       "       [ 58.79],\n",
       "       [-80.96],\n",
       "       [-63.03],\n",
       "       [ 45.97],\n",
       "       [-51.07],\n",
       "       [-44.96],\n",
       "       [ 36.12],\n",
       "       [ 38.38],\n",
       "       [-35.93],\n",
       "       [ 48.57],\n",
       "       [-81.71],\n",
       "       [-75.16],\n",
       "       [-14.51],\n",
       "       [ 18.78],\n",
       "       [ 45.45],\n",
       "       [ 64.61],\n",
       "       [ 21.41],\n",
       "       [-47.83],\n",
       "       [ 25.56],\n",
       "       [ 29.67],\n",
       "       [-45.24],\n",
       "       [-74.35],\n",
       "       [ 51.18],\n",
       "       [ 70.01],\n",
       "       [-66.95],\n",
       "       [ 50.7 ],\n",
       "       [ 31.65],\n",
       "       [ 73.51],\n",
       "       [ 45.24],\n",
       "       [ 15.79],\n",
       "       [-46.97],\n",
       "       [-66.19],\n",
       "       [-52.27],\n",
       "       [-31.99],\n",
       "       [-62.17],\n",
       "       [ 47.18],\n",
       "       [-61.29],\n",
       "       [ 51.05],\n",
       "       [-81.69],\n",
       "       [ 36.47],\n",
       "       [ 60.53],\n",
       "       [-59.38],\n",
       "       [ 49.58],\n",
       "       [ 55.02],\n",
       "       [-46.87],\n",
       "       [-52.48],\n",
       "       [ 68.52],\n",
       "       [-59.73],\n",
       "       [-65.89],\n",
       "       [-70.77],\n",
       "       [-42.74],\n",
       "       [ 25.96],\n",
       "       [-74.5 ],\n",
       "       [-51.23],\n",
       "       [ 45.24],\n",
       "       [-54.63],\n",
       "       [-35.25],\n",
       "       [ 22.76],\n",
       "       [-82.95],\n",
       "       [ 40.13],\n",
       "       [ 42.83],\n",
       "       [-79.73],\n",
       "       [  9.94],\n",
       "       [-79.8 ],\n",
       "       [ 56.69],\n",
       "       [-59.82],\n",
       "       [-77.28],\n",
       "       [-72.12],\n",
       "       [ 25.76],\n",
       "       [ 33.63],\n",
       "       [-40.13],\n",
       "       [ 39.33],\n",
       "       [-19.84],\n",
       "       [ 59.07],\n",
       "       [-38.63],\n",
       "       [-71.31],\n",
       "       [-52.19],\n",
       "       [-67.08],\n",
       "       [ 41.86],\n",
       "       [-78.22],\n",
       "       [-73.28],\n",
       "       [-64.8 ],\n",
       "       [-40.85],\n",
       "       [-87.33],\n",
       "       [ 46.48],\n",
       "       [-61.11],\n",
       "       [ 50.97]], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(preds.detach().numpy(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-8.0606, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_profit(preds, yb, threshold=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = 0.5*preds[:,1].log() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.4077, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = F.leaky_relu(preds[:,0], 0.5)*yb.float().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(50.2426, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4.0440)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unweighted_profit(preds[:,0], yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8.1925e-01,  2.2035e-01,  7.7802e-01,  7.5209e-01, -9.6370e-03,\n",
       "        -5.4069e-03,  8.3000e-01, -5.6366e-03, -9.5591e-03,  1.5291e-02,\n",
       "         8.0178e-01,  1.9101e-01,  6.7007e-01, -9.8845e-03,  5.9902e-01,\n",
       "         7.5299e-01, -1.4802e-03,  7.7943e-01, -9.4004e-03,  7.8837e-01,\n",
       "        -4.1210e-03,  7.9112e-01,  7.8203e-01,  7.0024e-01, -1.0000e-02,\n",
       "         7.9763e-01,  7.3333e-01, -4.8869e-03, -6.0198e-03,  5.9659e-01,\n",
       "         6.4868e-01,  8.3074e-01,  8.6674e-01,  8.1339e-01, -8.5559e-03,\n",
       "        -8.0417e-03,  8.7010e-01, -7.2772e-03,  2.4229e-01,  6.5914e-01,\n",
       "        -9.9913e-03,  8.0144e-01, -6.2689e-03, -5.1532e-03,  8.4950e-01,\n",
       "        -7.8629e-04, -5.0912e-03,  8.3450e-01,  6.9821e-01, -6.6265e-03,\n",
       "         8.4684e-01, -1.4540e-03, -1.1866e-03, -5.2012e-04,  6.9449e-01,\n",
       "         8.3494e-01,  7.6754e-01,  8.4125e-01, -7.3983e-03,  8.4954e-01,\n",
       "         6.6644e-01, -7.9540e-03, -9.4522e-03,  7.9308e-01,  5.6524e-01,\n",
       "        -4.2100e-03,  4.8191e-01,  8.4140e-01,  8.2408e-01,  8.4799e-01,\n",
       "         7.0922e-01, -2.8092e-03, -9.7226e-03, -2.9480e-04, -1.5744e-03,\n",
       "        -7.0143e-03,  6.9547e-01, -2.8341e-03,  6.0642e-01, -9.1840e-03,\n",
       "         8.6263e-01,  8.9377e-01,  7.6320e-02,  8.4966e-01,  8.5309e-01,\n",
       "        -1.5595e-03,  8.9373e-02,  7.4599e-01, -9.4146e-03, -6.8390e-03,\n",
       "        -6.1355e-03, -6.6092e-03,  8.2144e-01, -8.1095e-03,  5.5224e-03,\n",
       "         8.5346e-01,  4.2325e-02, -2.0239e-03,  8.7500e-01, -3.8894e-03,\n",
       "         6.3018e-01,  8.1290e-01, -9.7854e-03,  7.9471e-01, -1.9305e-03,\n",
       "         6.8138e-01, -9.0449e-03, -9.6631e-03, -3.2488e-03,  7.9622e-01,\n",
       "         8.0945e-01,  1.5524e-02,  8.8755e-01,  2.4855e-01,  6.4081e-01,\n",
       "        -9.5659e-03, -9.2554e-03, -8.2808e-03, -9.9988e-03,  8.0530e-01,\n",
       "         2.1511e-02, -7.4787e-03, -4.0604e-04, -9.1842e-03, -6.4931e-03,\n",
       "         8.6702e-01, -8.8407e-03,  8.4123e-01], grad_fn=<LeakyReluBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.leaky_relu(preds[:,0], 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 81.9255, -22.0001,  77.8021,  75.2093,  52.1226,  25.8011,  82.9995,\n",
       "         28.4714,  48.0399,  -1.5908,  80.1777, -19.7501,  67.0073,  55.0419,\n",
       "         59.9020,  75.2989,   7.4788,  77.9432,  54.3332,  78.8372,  20.9156,\n",
       "         79.1120,  78.2034,  70.0237,  56.1900,  79.7627,  73.3333,  27.1952,\n",
       "         33.1130,  59.6591,  64.8677,  83.0743,  86.6744,  81.3389,  45.9245,\n",
       "         42.3194,  87.0103,  41.0345, -25.5582,  65.9136,  55.6011,  80.1443,\n",
       "         29.4647,  28.9230,  84.9501,   3.7070,  26.5617,  83.4499,  69.8207,\n",
       "         33.9378,  84.6835,   7.3470,   5.6708,   2.5431,  69.4486,  83.4943,\n",
       "         76.7540,  84.1252,  37.5089,  84.9543,  66.6443,  41.6723,  44.7566,\n",
       "         79.3078,  56.5244,  21.7490,  48.1913,  84.1402,  82.4076,  84.7987,\n",
       "         70.9222,  15.2145,  51.2575,   1.5143,   7.5915,  38.2872,  69.5466,\n",
       "         15.8526,  60.6424,  48.2346,  86.2634,  89.3767,  -7.8546,  84.9656,\n",
       "         85.3088,   7.4551,  -8.3118,  74.5987,  50.2686,  32.9276,  32.0365,\n",
       "         35.4898,  82.1441,  46.4378,  -0.5498,  85.3464,  -4.3913,   9.9212,\n",
       "         87.5000,  18.6303,  63.0184,  81.2898,  55.2142,  79.4711,  10.0563,\n",
       "         68.1381,  44.9391,  55.2910,  16.6259,  79.6222,  80.9447,  -1.5727,\n",
       "         88.7554, -27.5071,  64.0814,  54.4578,  52.9549,  45.0890,  50.1575,\n",
       "         80.5303,  -2.4074,  38.8905,   2.2394,  49.3734,  36.0351,  86.7023,\n",
       "         49.4738,  84.1235], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = 0.5*(l1.div(preds[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.300000e+01, -8.000000e+00,  9.100000e+01,  4.700000e+01,\n",
       "        5.150000e+02,  2.200000e+01,  4.500000e+01,  2.800000e+01,\n",
       "        3.400000e+02, -1.000000e+00,  9.500000e+01, -7.000000e+00,\n",
       "        4.400000e+01,  1.124000e+03,  5.500000e+01,  3.700000e+01,\n",
       "        3.000000e+00,  4.100000e+01,  3.570000e+02,  9.000000e+01,\n",
       "        1.500000e+01,  8.000000e+01,  1.010000e+02,  9.400000e+01,\n",
       "        3.717994e+06,  5.000000e+01,  4.800000e+01,  3.100000e+01,\n",
       "        3.200000e+01,  4.700000e+01,  4.500000e+01,  4.100000e+01,\n",
       "        4.600000e+01,  7.500000e+01,  1.430000e+02,  7.400000e+01,\n",
       "        6.100000e+01,  4.700000e+01, -6.000000e+00,  5.600000e+01,\n",
       "        1.050800e+04,  6.000000e+01,  5.800000e+01,  2.400000e+01,\n",
       "        4.300000e+01,  2.000000e+00,  2.100000e+01,  5.900000e+01,\n",
       "        4.300000e+01,  4.900000e+01,  4.000000e+01,  3.000000e+00,\n",
       "        3.000000e+00,  1.000000e+00,  4.100000e+01,  4.700000e+01,\n",
       "        4.800000e+01,  1.710000e+02,  5.800000e+01,  7.900000e+01,\n",
       "        4.900000e+01,  1.140000e+02,  3.100000e+02,  4.900000e+01,\n",
       "        2.900000e+01,  1.800000e+01,  6.800000e+01,  3.900000e+01,\n",
       "        3.900000e+01,  5.700000e+01,  3.600000e+01,  9.000000e+00,\n",
       "        5.560000e+02,  1.000000e+00,  4.000000e+00,  5.700000e+01,\n",
       "        5.100000e+01,  7.000000e+00,  7.300000e+01,  1.870000e+02,\n",
       "        5.200000e+01,  4.600000e+01, -3.000000e+00,  4.200000e+01,\n",
       "        4.100000e+01,  4.000000e+00, -2.000000e+00,  6.800000e+01,\n",
       "        2.520000e+02,  4.800000e+01,  5.400000e+01,  3.700000e+01,\n",
       "        9.500000e+01,  1.080000e+02, -0.000000e+00,  4.600000e+01,\n",
       "       -2.000000e+00,  4.000000e+00,  7.200000e+01,  1.500000e+01,\n",
       "        4.500000e+01,  3.300000e+01,  8.200000e+02,  6.800000e+01,\n",
       "        7.000000e+00,  5.000000e+01,  1.490000e+02,  5.370000e+02,\n",
       "        1.000000e+01,  6.700000e+01,  5.500000e+01, -1.000000e+00,\n",
       "        4.700000e+01, -1.100000e+01,  2.800000e+01,  5.210000e+02,\n",
       "        2.570000e+02,  1.210000e+02,  2.937700e+04,  5.300000e+01,\n",
       "       -1.000000e+00,  4.300000e+01,  1.000000e+00,  2.440000e+02,\n",
       "        3.400000e+01,  6.200000e+01,  1.480000e+02,  4.500000e+01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(s2.detach().numpy(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    loss = (s1+s2).mean() + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "with torch.no_grad():\n",
    "    for p in model_v.parameters():\n",
    "        p -= p.grad * lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_2 = model_v(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_2 = nll_regression(preds_2, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.6749, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.1327, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.5*preds[:,1].log() + 0.5*(yb.squeeze()-preds[:,0]).pow(2).div(preds[:,1].pow(2))).mean() + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = list(model.parameters())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QD loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High-Quality Prediction Intervals for Deep Learning: A Distribution-Free, Ensembled Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_results = _create_random_results(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 100.0000,  100.0000, -105.5246,  100.0000,  100.0000, -103.9725,\n",
       "        -109.0025, -103.6679,  100.0000, -109.7297])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.randn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lower=preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_upper = preds + torch.rand(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.5228,  0.6698, -1.3370, -1.4433,  1.6161, -1.7076,  1.1021,  0.2209,\n",
       "         -0.4566,  0.1096]),\n",
       " tensor([ 1.4219,  1.4838, -0.6285, -0.9521,  2.0129, -1.4467,  1.1511,  0.5733,\n",
       "          0.2181,  0.3509]),\n",
       " tensor([-0.4609,  1.7691, -0.4418, -0.9305,  1.5658, -0.4735, -0.2524, -0.1192,\n",
       "          1.4725,  0.7472]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_lower, y_upper, y_toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hard\n",
    "y_toy = torch.randn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "khu = (torch.sign(y_upper-y_toy) > 0).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "khl = (torch.sign(y_toy-y_lower) > 0).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 1, 0, 1, 0, 1, 0, 1], dtype=torch.int32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "khl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 0, 1, 0, 1, 1, 1, 0], dtype=torch.int32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "khu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##soft\n",
    "s = 10\n",
    "ksu = torch.sigmoid((y_upper-y_toy)*s)\n",
    "ksl = torch.sigmoid((y_toy-y_lower)*s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.    , 1.    , 0.    , 0.    , 1.    , 0.    , 0.9997, 0.9653,\n",
       "       0.9992, 0.005 ], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(ksu.numpy(),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.   , 1.   , 1.   , 0.   , 1.   , 0.   , 0.55 , 0.393,\n",
       "       1.   ], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(ksl.numpy(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##soft\n",
    "s = 10\n",
    "ksu = torch.sigmoid((y_upper-y_results)*s)\n",
    "ksl = torch.sigmoid((y_results-y_lower)*s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 0., 0., 1., 1., 1., 0., 1.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 0., 1., 1., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ksl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 100.0000,  100.0000, -105.5246,  100.0000,  100.0000, -103.9725,\n",
       "        -109.0025, -103.6679,  100.0000, -109.7297])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.4219,  1.4838, -0.6285, -0.9521,  2.0129, -1.4467,  1.1511,  0.5733,\n",
       "         0.2181,  0.3509])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8056, 0.8152, 0.6600, 0.2785, 0.8821, 0.8182, 0.2219, 0.3556, 0.5543,\n",
       "        0.4049])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(y_upper*y_results*0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Betting adaption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given results targets `y_results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 100.0000,  100.0000, -105.5246,  100.0000,  100.0000, -103.9725,\n",
       "        -109.0025, -103.6679,  100.0000, -109.7297])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the NN predicts upper and lower bounds `y_upper`, `y_lower`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.4219,  1.4838, -0.6285, -0.9521,  2.0129, -1.4467,  1.1511,  0.5733,\n",
       "          0.2181,  0.3509]),\n",
       " tensor([ 0.5228,  0.6698, -1.3370, -1.4433,  1.6161, -1.7076,  1.1021,  0.2209,\n",
       "         -0.4566,  0.1096]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_upper, y_lower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to leaky loss, we want both bounds to have the same sign as the target `y_results` and higher absolute values for more confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def qd_loss(preds, y_true, alpha=0.4, l=0.01, s=0.01, add=False):\n",
    "    '''\n",
    "    qd loss implementation adapted for \"leaky loss problems\"\n",
    "    preds: predictions for both lower and upper bounds\n",
    "    alpha: confidence intervall parameter, different from alpha in leaky_loss\n",
    "    s: smoothing factor for sigmoid\n",
    "    l: agrangian controlling width vs coverage (default in the paper impl. is 0.01 which seems lowI)\n",
    "    '''\n",
    "    if not add:\n",
    "        y_lower, y_upper = preds[:, 0].clone(), preds[:, 1].clone()\n",
    "    else:\n",
    "        y_lower, y_upper = preds[:, 0].clone(), preds[:,0]+preds[:, 1]\n",
    "    # hard counts, how many of the predictions have the right sign?\n",
    "    khu = (torch.sign(y_upper*y_true) > 0).int()\n",
    "    khl = (torch.sign(y_lower*y_true) > 0).int()\n",
    "    # soft counts, sign step function replaced by a smoother sigmoid\n",
    "    ksu = torch.sigmoid((y_upper*y_true)*s)\n",
    "    ksl = torch.sigmoid((y_true*y_lower)*s)\n",
    "    kh,ks = khu*khl, ksu*ksl\n",
    "    print(kh.sum(), ks.sum())\n",
    "    \n",
    "    #mpiw: mean predicted interval width\n",
    "    f = 1/kh.sum() if kh.sum()>0 else 1000 ## hack\n",
    "    mpiw = ((y_upper-y_lower)*kh).sum()*f\n",
    "    \n",
    "    #picp: predicted interval coverage probability\n",
    "    picp_s = ks.mean()\n",
    "    \n",
    "    print(mpiw, picp_s)\n",
    "    s2 = l*preds.shape[0]/(alpha*(1-alpha))\n",
    "    s3 = torch.max(torch.zeros(1, device=preds.device), picp_s).pow(2)\n",
    "    loss_s = mpiw + l*preds.shape[0]/(alpha*(1-alpha)) * torch.max(torch.zeros(1, device=preds.device), \n",
    "                                                                   picp_s).pow(2)\n",
    "    return loss_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f019c50a310>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(F.softplus(torch.arange(-5,5).float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johannes/anaconda3/envs/nbdev/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f019c4c51d0>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(F.softmax(torch.arange(-5,5).float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lower, y_upper = preds[:, 0], preds[:, 0]+preds[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksu = torch.sigmoid((y_upper*y_true)*s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "khu = (torch.sign(y_upper*y_true) > 0).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "khu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2150, -0.0373, -0.0664, -0.1514, -0.0763, -0.1669, -0.2402, -0.2522,\n",
       "        -0.2219, -0.1682, -0.2088, -0.1296, -0.0894, -0.2470, -0.0757, -0.1998,\n",
       "         0.0426, -0.2163, -0.0432, -0.1383, -0.2627, -0.1482, -0.2261, -0.1615,\n",
       "        -0.1781, -0.1812, -0.1635, -0.3006, -0.1287, -0.3097, -0.1423, -0.0867,\n",
       "        -0.3076, -0.2707, -0.1401, -0.1619, -0.1846, -0.1943, -0.3508, -0.2030,\n",
       "        -0.0949, -0.2206, -0.1296, -0.0740, -0.1855, -0.0868, -0.0605, -0.1596,\n",
       "        -0.1182, -0.1774, -0.1584, -0.0428, -0.1503, -0.3000, -0.2229, -0.0940,\n",
       "        -0.1599,  0.0036, -0.1962, -0.1582, -0.1363, -0.1152, -0.1080, -0.0295,\n",
       "        -0.1667, -0.1917, -0.1041, -0.0410, -0.0946, -0.0379, -0.1147, -0.1163,\n",
       "        -0.2333, -0.3011, -0.2240, -0.0911, -0.1724, -0.1288, -0.1447, -0.1738,\n",
       "        -0.1851, -0.1214, -0.1903, -0.1865, -0.1321, -0.2168, -0.1115, -0.1393,\n",
       "        -0.1593, -0.1440, -0.1833, -0.1896, -0.0744, -0.1577, -0.0946, -0.2391,\n",
       "        -0.2719,  0.0006, -0.1742, -0.1997, -0.1440, -0.1906, -0.2540, -0.1729,\n",
       "        -0.1432, -0.1905, -0.2166, -0.2520, -0.1877, -0.2848, -0.1640, -0.0961,\n",
       "        -0.1329, -0.1534, -0.0458, -0.2350,  0.0208, -0.0539, -0.1917, -0.2521,\n",
       "        -0.1840, -0.2482, -0.1150, -0.0458, -0.0821,  0.0129, -0.2282, -0.2099],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0125, 0.9507, 1.1341, 1.2261, 0.9578, 1.2655, 1.0331, 1.3799, 1.1758,\n",
       "        1.0343, 1.0520, 1.1780, 1.1278, 0.9600, 1.1459, 1.0721, 1.2432, 0.8925,\n",
       "        1.3539, 1.2006, 1.2460, 1.3015, 1.1666, 1.1699, 1.3345, 1.0551, 1.3872,\n",
       "        1.3417, 1.1222, 1.0703, 1.1570, 1.1313, 1.2327, 1.3396, 1.1941, 1.1885,\n",
       "        1.3074, 1.0672, 1.0710, 1.2454, 1.4943, 1.1268, 1.2031, 1.4435, 1.1855,\n",
       "        1.1028, 1.1619, 1.4476, 1.1487, 1.5705, 1.3223, 0.8941, 1.0758, 1.2868,\n",
       "        1.3020, 1.2579, 1.2519, 1.1587, 1.1629, 1.0649, 1.1168, 1.2001, 1.0949,\n",
       "        1.0564, 1.0763, 1.0126, 1.3438, 0.9129, 1.1583, 0.9154, 1.1087, 1.3220,\n",
       "        1.2802, 1.0433, 1.3633, 1.2038, 1.0183, 1.3108, 1.1089, 1.2248, 1.2072,\n",
       "        1.1324, 1.2276, 1.1366, 1.4469, 1.0298, 1.1344, 1.2845, 1.4002, 0.8993,\n",
       "        1.0610, 1.3647, 1.1205, 1.1292, 1.1420, 1.0606, 1.0974, 0.9439, 1.1388,\n",
       "        1.4899, 1.3278, 1.1295, 1.2323, 1.1965, 1.1490, 1.0899, 0.9409, 0.9582,\n",
       "        1.1029, 1.0597, 1.1515, 1.0839, 1.3351, 1.4174, 1.5295, 1.0450, 1.1649,\n",
       "        1.1465, 1.2916, 1.1645, 1.1412, 1.1342, 1.1175, 1.3182, 1.3614, 1.0792,\n",
       "        1.2999, 1.3858], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3678])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(torch.zeros(1), picp_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.cat([y_lower[:,None], y_upper[:, None]], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 2]), torch.Size([10]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape, y_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6159) tensor(0.3678)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.0650)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_loss(preds, y_results, alpha=0.4, l=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class InceptionTimeBounds(nn.Module):\n",
    "    '''\n",
    "    use InceptionTimeVar implementation for bounds\n",
    "    output[:, -1] is positive and y_upper corresponds to output[:,0]+output[:,1] --> loss\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, n_in, n_out, meanrange=None):\n",
    "        super().__init__()\n",
    "        models  = [InceptionTime(n_in, n_out+1)]\n",
    "        if meanrange:\n",
    "            self.sigmoid = Sigmoid(*meanrange)\n",
    "        self.mod = nn.Sequential(*models)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        output = self.mod(x)\n",
    "        ## enforce positivity of sigma^2\n",
    "        ##output_sig_pos = tf.log(1 + tf.exp(output_sig)) + 1e-06\n",
    "#         output[:,-1] = (output[:,-1].exp()+1).log_() + 1e-06\n",
    "        output[:,-1] = F.softplus(output[:,-1])\n",
    "        \n",
    "        if getattr(self, 'sigmoid', None): output[:,:-1] = self.sigmoid(output[:,:-1])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InceptionTimeBounds(10,1, meanrange=(-3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3760) tensor(3948.7781, grad_fn=<SumBackward0>)\n",
      "tensor(0.5312, grad_fn=<DivBackward0>) tensor(0.2410, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.8410], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_loss(model(xb), y_true, add=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nbdev]",
   "language": "python",
   "name": "conda-env-nbdev-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
