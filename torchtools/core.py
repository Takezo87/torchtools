# AUTOGENERATED! DO NOT EDIT! File to edit: 00_core.ipynb (unless otherwise specified).

__all__ = ['test', 'leaky_loss', 'leaky_loss_2d', 'unweighted_profit', 'unweighted_profit_05', 'weighted_profit',
           'get_loss_fn', 'is_array', 'listify', 'FixedSplitter', 'TSSplitter']

# Cell
#hide
import torch.nn.functional as F
import torch as torch
from functools import partial
from fastai2.basics import *

# Cell
def test():
    '''a test function'''
    print('test')

# Cell
def leaky_loss(preds, y_true, alpha=0.05):
    '''
    objective function, including negative predictions with factor alpha
    '''
    loss_1 = (F.leaky_relu(preds, alpha).squeeze()*y_true.float()).mean()*(-1)
    loss_1.requires_grad_(True)
    return loss_1

# Cell
def leaky_loss_2d(preds, y_true, alpha=0.05, weights=None):
    '''
    objective function, including negative predictions with factor alpha
    weights: target variable weights
    '''
    assert len(y_true.shape)==2, 'y_true needs to be 2d'
     # weight of the first y-value
    prod = (F.leaky_relu(preds, alpha).squeeze()*y_true.float())
    print(prod)
    if weights:
        prod.mul_(torch.tensor(weights)[:, None])
#     print(prod)
    loss_1 = prod.mean()*(-1)
    loss_1.requires_grad_(True)
    return loss_1


# Cell
def unweighted_profit(preds, y_true, threshold=0):
    '''
    metric, negative predictions ignored, y_true of positive predictions equally weighted
    '''
    m_value = ((preds.squeeze()>threshold).float()*y_true.float()).mean()
    return m_value

# Cell
def unweighted_profit_05(preds, y_true, threshold=0.5):
    '''
    metric, negative predictions ignored, y_true of positive predictions equally weighted
    '''
    m_value = ((preds.squeeze()>threshold).float()*y_true.float()).mean()
    return m_value

# Cell
def weighted_profit(preds, y_true, threshold=0):
    '''
    metric, negative predictions ignored, results weighted by positive predictions
    adding threshold possible
    '''
    loss_1 = ((preds.squeeze()>threshold).float()*(preds.squeeze())*y_true.float()).mean()
    return loss_1

# Cell
def get_loss_fn(loss_fn_name, **kwargs):
    '''
    wrapper to create a partial with a more convenient __name__ attribute
    '''
    if loss_fn_name == 'leaky_loss':
        assert kwargs.get('alpha', None) is not None, 'need to specify alpha with leaky_loss'
        _loss_fn = partial(leaky_loss, alpha=kwargs['alpha'])
        _loss_fn.__name__ = loss_fn_name
        return _loss_fn
    return None

# Cell
#fastcore.foundations
def is_array(x): return hasattr(x,'__array__') or hasattr(x,'iloc')
def listify(o):
    if o is None: return []
    if isinstance(o, list): return o
    if isinstance(o, str) or is_array(o): return [o]
    if is_iter(o): return list(o)
    return [o]

# Cell
def FixedSplitter(end_train=10000, end_valid=15000):
    def _inner(o, **kwargs):
        return L(range(0, end_train)), L(range(end_train, end_valid))
    return _inner

# Cell
def TSSplitter(train_perc=0.8, test=False):
    def _inner(o, **kwargs):
        l = len(o)
        end_train = int(l*train_perc)
        end_val = l if not test else int(l*(train_perc+(1-train_perc)*0.5))
        end_test = l
        if test: return L(range(end_train), range(end_train, end_val), range(end_val, end_test))
        return L(range(end_train), range(end_train, end_val))
    return _inner