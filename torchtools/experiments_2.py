# AUTOGENERATED! DO NOT EDIT! File to edit: 201_experiments_2.ipynb (unless otherwise specified).

__all__ = ['df_path', 'col_config', 'col_config', 'main']

# Cell
from .core import *
from .data import *
from .models import *
from .datasets import *
from .augmentations import *
from .datablock import *
from .dataloader import *
from .experiments import *
from .configs import *

# Cell
import pandas as pd
import numpy as np
from fastai2.basics import *

# Cell
df_path = Path('./data/custom/bi_sample_anon.csv')

# Cell
## column configuration as dict, eventually move to separate configuration file
col_config = defaultdict(lambda:None)
col_config['cols_c'] = [[f'x{i}_{j}' for j in range(10)] for i in [0,1,3,4]]
col_config['cols_d'] = [[f'x{i}_{j}' for j in range(10)] for i in [2,5]]
col_config['cols_y']= 'y0'
col_config['id']='anon10hc_4c_2d_y'  ## put it all in one config file with this unique identifier

# Cell
## column configuration as dict, eventually move to separate configuration file
col_config = defaultdict(lambda:None)
col_config['cols_c'] = [[f'x{i}_{j}' for j in range(10)] for i in [0,1,2,3,4,5]]
# col_config['cols_d'] = [[f'x{i}_{j}' for j in range(10)] for i in [2,5]]
col_config['cols_d'] = None
col_config['cols_y']= 'y0'
col_config['id']='anon10hc_6c_y'  ## put it all in one config file with this unique identifier

# Cell
def _get_arch(arch:str, with_discrete=False):
    if arch.lower()=='inception': return InceptionTimeSgm if not with_discrete else InceptionTimeD
    elif arch.lower()=='resnet': return 'ResNet not implemented'
    else: return None

# Cell
from fastscript import *
@call_parse
def main(n_epochs:Param(help="n_epochs list", nargs='+', type=int)=[10],
         max_lr:Param(help="max_lr list", nargs='+', type=float)=[1e-5],
         wd:Param(help="wd (weight decay) hpyerparameter list", nargs='+', type=float)=[0.03],
         div_factor:Param(help="div_factor hpyerparameter list", nargs='+', type=float)=[25.0],
         seed:Param(help="seed hpyerparameter list", nargs='+', type=int)=[1234],
         N:Param(help="N hpyerparameter list", nargs='+', type=int)=[3],
         magnitude:Param(help="magnitude hpyerparameter list", nargs='+', type=float)=[0.3],
         alpha:Param(help="alpha hpyerparameter list", nargs='+', type=float)=[0.5],
         aug:Param(help="augmentation policy", choices=[None, 'randaugment', 'augmix'], type=str)=None,
         nrows:Param(help="n_epochs list", type=int)=None,
         bs:Param(help="batch size", type=int)=128,
         trn_end:Param(help="n_epochs list", type=int)=None,
         val_end:Param(help="n_epochs list", type=int)=None,
         test_end:Param(help="n_epochs list", type=int)=None,
         df_fn:Param(help="dataframe filename", type=str)='bi_sample_anon.csv',
         df_dir:Param(help="dataframe dir", type=str)='./data/custom',
         df_results:Param(help="results dataframe filename", type=str)='results_script.csv',
         config_fn:Param(help="json column configuration filename", type=str)='config2.json',
         config_id:Param(help="column configuration id", type=str)='anon2hc_4c_2d_y',
         arch:Param(help="model architecture", choices=['inception', 'resnet'], type=str)='inception',
         upper:Param("Convert to uppercase?", bool_arg)=False):
#     print(msg.upper() if upper else msg)



    train_params['aug']=aug

    df_path=Path(df_dir)/df_fn
    print(df_path)

    col_config=read_config(config_id, config_fn)
    data_params = build_data_params(df_path, col_config=col_config, nrows=nrows, trn_end=trn_end, val_end=val_end,
                                   test_end=test_end, bs=bs)
#     print(data_params)

    train_params['metrics']=[unweighted_profit, unweighted_profit_05]
    train_params['arch']=_get_arch(arch, col_config['cols_d'] is not None)
    ts_experiment = TSExperiments()
    ts_experiment.setup_data(data_params)
    ts_experiment.setup_training(train_params)

    hypers = {'n_epochs': n_epochs, 'max_lr':max_lr, 'wd':wd, 'seed': seed, 'div_factor':div_factor,
             'N':N, 'magnitude':magnitude}
    print(hypers)

    ts_experiment.run_grid_search(hypers, df_results)