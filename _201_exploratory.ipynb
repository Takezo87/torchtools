{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp experiments_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "> refactor modelling, experiment functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.1+cu102'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torchtools.core import *\n",
    "from torchtools.data import *\n",
    "from torchtools.models import *\n",
    "from torchtools.datasets import *\n",
    "from torchtools.augmentations import *\n",
    "#from torchtools.datablock import *\n",
    "from torchtools.dataloader import *\n",
    "from torchtools.experiments import *\n",
    "from torchtools.configs import *\n",
    "from torchtools.evaluation import *\n",
    "#from torchtools.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastai.basics import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torchtools.core.double_loss_squared(preds, y_true, alpha=0.5)>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_loss_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.20'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fastcore\n",
    "fastcore.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arch': torchtools.models.InceptionTimeD,\n",
       " 'n_epochs': 5,\n",
       " 'max_lr': 1e-05,\n",
       " 'wd': 0.03,\n",
       " 'loss_fn_name': 'leaky_loss',\n",
       " 'alpha': 0.5,\n",
       " 'metrics': [<function torchtools.core.unweighted_profit(preds, y_true, threshold=0)>],\n",
       " 'N': 3,\n",
       " 'magnitude': 0.4,\n",
       " 'seed': 1234,\n",
       " 'pct_start': 0.3,\n",
       " 'div_factor': 25.0,\n",
       " 'aug': 'augmix'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## most recent datasets are bi_sample_pruned_anon_222.csv and ts_experiments_anon_ts_exp_2020818.csv. make sure\n",
    "## that config and dataset correspond to each other (different naming conventions)\n",
    "/#export\n",
    "df_path_old = Path('./data/custom/bi_sample_anon.csv')\n",
    "# df_path = Path('./data/custom/bi_sample_pruned_anon.csv')\n",
    "# df_path = Path('~/coding/python/betting/experiments/datasets/bi_sample_pruned_anon.csv').expanduser()\n",
    "df_path = Path('~/coding/python/betting/experiments/datasets/bi_sample_pruned_anon_222.csv').expanduser()\n",
    "df_path = Path('~/coding/python/betlib/data/processed/ts_experiments_anon_ts_exp_2020818.csv').expanduser()\n",
    "df_path = Path('~/coding/python/scrape/bets_processed.csv').expanduser()\n",
    "df_path = Path('~/coding/python/scrape/bets_anon_new.csv').expanduser()\n",
    "# df_path = Path('~/coding/python/scrape/bets_anon_new_gb.csv').expanduser()\n",
    "df_path= Path('~/coding/python/scrape/bets_anon_new.csv').expanduser()\n",
    "df_path= Path('~/coding/python/scrape/bets_historic_20210302_over.csv').expanduser()\n",
    "df_path= Path('/home/johannes/google-drive/data/bets_tennis_20210330_opp_full.csv').expanduser()\n",
    "\n",
    "# df_path = Path('~/coding/python/betting/experiments/datasets/bi_50_218_anon.csv').expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_CONFIG = 'config2.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anon_10sl_4c_2d_1yml',\n",
       " 'anon_10sl_6c_1yml',\n",
       " 'anon_10sl_6c_1yhc',\n",
       " 'anon_10sl_6c_2y',\n",
       " 'anon_10sl_4c_2d_1yhc',\n",
       " 'anon_10sl_4c_2d_2y',\n",
       " 'anon_20sl_4c_2d_2y',\n",
       " 'anon_30sl_4c_2d_2y',\n",
       " 'anon_10sl_4c_2d_4tc_4cat_2y',\n",
       " 'anon_10sl_4c_2d_4tc_4cat_1yhc',\n",
       " 'anon_10sl_4c_1yhc',\n",
       " 'anon_10sl_6c_1yclass',\n",
       " 'anon_10sl_4c_2d_1yclass',\n",
       " 'anon_10sl_4c_2d_4tc_4cat_1yclass',\n",
       " 'tsexp_10sl_12c_1yhc',\n",
       " 'tsexp_10sl_12c_1yclass',\n",
       " 'anon_10sl_4c_2d_1yhc_prune',\n",
       " 'bets_processed_6c_1yhc',\n",
       " 'bets_processed_14c_1you',\n",
       " 'bets_processed_15c_1yover',\n",
       " 'bets_processed_8c_1yover',\n",
       " 'bets_processed_8c_2yoverunder',\n",
       " 'bets_processed_26c_2yoverunder',\n",
       " 'bets_processed_12c_2yoverunder',\n",
       " 'bets_processed_6c_2yahopp',\n",
       " 'bets_processed_14c_2yahopp',\n",
       " 'bets_tennis_6c_2yahopp',\n",
       " 'bets_tennis_6c_2y_ha_opp',\n",
       " 'bets_tennis_12c_2y_over_under',\n",
       " 'bets_fb_10c_2y',\n",
       " 'bets_fb_10c_2y_ah_opp',\n",
       " 'bets_ts_basic_10c_2y_ah_opp',\n",
       " 'bets_fb_10c_log_2y_ah_opp']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_keys(COL_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_id =  'anon_10sl_6c_1yclass'\n",
    "config_id = 'anon_10sl_4c_2d_1yhc'\n",
    "config_id =  'tsexp_10sl_12c_1yclass'\n",
    "config_id =  'bets_processed_8c_2yoverunder'\n",
    "config_id =  'bets_tennis_6c_2y_ha_opp'\n",
    "col_config = read_config(config_id, COL_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cols_c', 'cols_y', 'id', 'cols_d'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cols_c', 'cols_y', 'id', 'cols_d'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_config.get('hcodds_col')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(col_config.get, ['hcodds_col', 'prune']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _anon_config(n_channels, n_seq, prefix='c'):\n",
    "    cols=[]\n",
    "    for i in range(n_channels):\n",
    "        cols.append([f'{prefix}{i}_{j}' for j in range(n_seq)])\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_config.get('prune')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_config.get('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = Path('~/coding/python/betting/experiments/datasets/bi_sample_pruned_anon_222.csv').expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params = build_data_params(df_path, col_config=col_config, classification=False, trn_end=160000,val_end=185000, \n",
    "                                test_end=210000, ss_dis=True, bs=256)\n",
    "# data_params = build_data_params(df_path, col_config=col_config, classification=True, trn_end=16000,val_end=18500, \n",
    "#                                 test_end=21000, ss_dis=True, bs=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_exp = TSExperiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_exp.setup_data(data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_params['loss_fn_name'] = \"crossentropy\"\n",
    "# train_params['loss_fn_name'] = \"rww\"\n",
    "# train_params['metrics'] = [accuracy]\n",
    "train_params\n",
    "train_params['aug'] = 'randaugment'\n",
    "# train_params['aug'] = ['None']\n",
    "train_params['max_lr'] = 3e-3\n",
    "train_params['weight'] = tensor([1., 1., 1., 1., 1.]) ## crossentropy weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_loss_fn??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params['loss_fn_name']='leaky_loss'\n",
    "train_params['metrics'] = [unweighted_profit, unweighted_profit_05]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_exp.setup_training(train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers={'max_lr':[3e-3], 'n_epochs':[1], 'N':[1], 'magnitude':[0.1],  'wd':[0.1], \n",
    "        'weight':[tensor([1., 10., 1., 10., 1.]) ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_exp.classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_fn='results_exploration_class.csv'\n",
    "df_results_fn='results_exploration.csv' ##regression\n",
    "ts_exp.run_grid_search(hypers, df_results_fn='results_exploration_class.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ts_exp.learn.loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_exp.learn.fit(3, lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_exp.learn.fit(3, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, y_true = ts_exp.learn.get_preds(split_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(preds, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = F.softmax(preds, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = torch.where(preds[:,1]>0.45)[0]\n",
    "len(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ts_exp.df_base.iloc[ts_exp.splits[0]]['y1'].mean())\n",
    "print(ts_exp.df_base.iloc[ts_exp.splits[1]]['y1'].mean())\n",
    "print(ts_exp.df_base.iloc[ts_exp.splits[2]]['y1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_exp.df_base.iloc[ts_exp.splits[split_idx]].iloc[idxs][['y0', 'y1']].agg(['mean', 'sum', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_exp.df_base.iloc[ts_exp.splits[split_idx]].iloc[complement_idxs(idxs)][\n",
    "    ['y0', 'y1']].agg(['mean', 'sum', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complement_idxs(idxs):  \n",
    "    def _c(idx):\n",
    "        return idx+1 if idx%2==0 else idx-1\n",
    "    return tensor([_c(idx) for idx in idxs.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_exp.df_base.iloc[160000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CrossEntropyLossFlat(weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(df_path, nrows=25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_cols_cont=[['tc0', 'tc1', 'tc2', 'tc3']]\n",
    "tab_cols_cat=[['tcat0', 'tcat1', 'tcat2', 'tcat3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[tab_cols_cont[0]].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats=cats_from_df(df, tab_cols_cat[0], 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = items_from_df(df, col_config['cols_c'], col_config['cols_y'], 10000, tab_cols_c=tab_cols_cont[0],\n",
    "                     cols_d=col_config['cols_d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items_from_df(df, col_config['cols_c'], col_config['cols_y'], 10000, tab_cols_c=tab_cols_cont[0],\n",
    "                     cols_d=col_config['cols_d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ars = items_to_arrays(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ars[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits=TSSplitter()(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_dls(df, col_config['cols_c'], col_config['cols_y'], splits, ds_type=TSDatasets4, cols_d=col_config['cols_d'],\n",
    "              cols_cont=tab_cols_cont[0], cols_cat=tab_cols_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.one_batch()[2][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def pytorch_count_params(model):\n",
    "  \"count number trainable parameters in a pytorch model\"\n",
    "  total_params = sum(reduce( lambda a, b: a*b, x.size()) for x in model.parameters())\n",
    "  return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dloaders=TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc,xd,xtab_cont, xtab_cat, yb = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc.shape, xd.shape, xtab_cont.shape, xtab_cat.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_dls(df, col_config['cols_c'], col_config['cols_y'], splits, ds_type=TSDatasets4, cols_d=col_config['cols_d'],\n",
    "              cols_cont=tab_cols_cont[0], cols_cat=tab_cols_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.one_batch()[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _get_model(dls, arch='inception'):\n",
    "#     if hasattr(dls, 'cols_cat'):\n",
    "#         emb_szs= [_one_emb_sz(dls.voc, c) for c in dls.cols_cat]\n",
    "#         return InceptionTimeD_Mixed(dls.n_channels, dls.n_targets, len(dls.cols_cont), emb_szs=emb_szs)\n",
    "#     else:\n",
    "#         if dls.dataset.has_xtype[1]: ##discrete channels\n",
    "#             return InceptionTimeD(dls.n_channels, dls.n_targets)\n",
    "#         else:\n",
    "#             return InceptionTimeSgm(dls.n_channels, dls.n_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_dls(df, col_config['cols_c'], col_config['cols_y'], splits, ds_type=TSDatasets4, cols_d=col_config['cols_d'],\n",
    "              cols_cont=tab_cols_cont[0], cols_cat=tab_cols_cat[0])\n",
    "# dls = get_dls(df, col_config['cols_c'], col_config['cols_y'], splits, ds_type=TSDatasets4, \n",
    "#               cols_d=col_config['cols_d'])\n",
    "# dls = get_dls(df, col_config['cols_c'], col_config['cols_y'], splits, ds_type=TSDatasets4, \n",
    "#               cols_d=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment = TSExperiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params = build_data_params(df_path, col_config=col_config, nrows=None, bs=256, ss_dis=True,\n",
    "                               trn_end=160000, val_end=185000, test_end=210000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params.__getitem__('dsds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_config.get('cols_cont')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params['cols_cont']=tab_cols_cont[0]\n",
    "data_params['cols_cat']=tab_cols_cat[0]\n",
    "data_params['bs']=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params['cols_cont']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params['cols_cat']=None\n",
    "ts_experiment.setup_data(data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = ts_experiment.dls.one_batch()\n",
    "\n",
    "# list(map(lambda x: x.shape, [a,b,c,d,e]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn=get_loss_fn('leaky_loss', alpha=0.5)\n",
    "# learn = Learner(ts_experiment.dls, m, loss_func=loss_fn, metrics=None, model_dir=ts_experiment.model_path,\n",
    "#                        wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.setup_training(train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.mean(0), c.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.dls.n_channels_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def emb_sz_rule(n_cat):\n",
    "    \"Rule of thumb to pick embedding size corresponding to `n_cat`\"\n",
    "    return min(600, round(1.6 * n_cat**0.56))\n",
    "\n",
    "# Cell\n",
    "def _one_emb_sz(classes, n, sz_dict=None):\n",
    "    \"Pick an embedding size for `n` depending on `classes` if not given in `sz_dict`.\"\n",
    "    sz_dict = ifnone(sz_dict, {})\n",
    "    n_cat = len(classes[n])\n",
    "    sz = sz_dict.get(n, int(emb_sz_rule(n_cat)))  # rule of thumb\n",
    "    return n_cat,sz\n",
    "\n",
    "# Cell\n",
    "def get_emb_sz(to, sz_dict=None):\n",
    "    \"Get default embedding size from `TabularPreprocessor` `proc` or the ones in `sz_dict`\"\n",
    "    return [_one_emb_sz(to.classes, n, sz_dict) for n in to.cat_names]\n",
    "\n",
    "def _get_model(dls, arch='inception'):\n",
    "    if dls.cols_cat is not None or dls.cols_cont is not None:\n",
    "        emb_szs= [_one_emb_sz(dls.voc, c) for c in listify(dls.cols_cat)] \n",
    "        return InceptionTimeD_Mixed(dls.n_channels_c, dls.n_channels_d, dls.n_targets, \n",
    "                                    len(dls.cols_cont), emb_szs=emb_szs)\n",
    "    else:\n",
    "        if dls.dataset.has_xtype[1]: ##discrete channels\n",
    "            return InceptionTimeD(dls.n_channels, dls.n_targets)\n",
    "        else:\n",
    "            return InceptionTimeSgm(dls.n_channels, dls.n_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = _get_model(ts_experiment.dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.tab_mod.cuda()(None, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers={'n_epochs':[20]}\n",
    "df_results_fn = 'results_exploration.csv'\n",
    "ts_experiment.run_grid_search(hypers, df_results_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.run_training(n_epochs=1, loss_fn_name='leaky_loss', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params['splits']=TSSplitter()(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dls(df, data_params['cols_c'], data_params['cols_y'], data_params['splits'], ds_type=TSDatasets4,\n",
    "       cols_cont=data_params['cols_cont'], cols_cat=data_params['cols_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params['bs']=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.setup_data(data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worklflow with Discrete Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_CONFIG = 'config2.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anon_10sl_4c_2d_1yml',\n",
       " 'anon_10sl_6c_1yml',\n",
       " 'anon_10sl_6c_1yhc',\n",
       " 'anon_10sl_6c_2y',\n",
       " 'anon_10sl_4c_2d_1yhc',\n",
       " 'anon_10sl_4c_2d_2y',\n",
       " 'anon_20sl_4c_2d_2y',\n",
       " 'anon_30sl_4c_2d_2y',\n",
       " 'anon_10sl_4c_2d_4tc_4cat_2y',\n",
       " 'anon_10sl_4c_2d_4tc_4cat_1yhc',\n",
       " 'anon_10sl_4c_1yhc',\n",
       " 'anon_10sl_6c_1yclass',\n",
       " 'anon_10sl_4c_2d_1yclass',\n",
       " 'anon_10sl_4c_2d_4tc_4cat_1yclass',\n",
       " 'tsexp_10sl_12c_1yhc',\n",
       " 'tsexp_10sl_12c_1yclass',\n",
       " 'anon_10sl_4c_2d_1yhc_prune',\n",
       " 'bets_processed_6c_1yhc',\n",
       " 'bets_processed_14c_1you',\n",
       " 'bets_processed_15c_1yover',\n",
       " 'bets_processed_8c_1yover',\n",
       " 'bets_processed_8c_2yoverunder',\n",
       " 'bets_processed_26c_2yoverunder',\n",
       " 'bets_processed_12c_2yoverunder',\n",
       " 'bets_processed_6c_2yahopp',\n",
       " 'bets_processed_14c_2yahopp',\n",
       " 'bets_tennis_6c_2yahopp',\n",
       " 'bets_tennis_6c_2y_ha_opp',\n",
       " 'bets_tennis_12c_2y_over_under',\n",
       " 'bets_fb_10c_2y',\n",
       " 'bets_fb_10c_2y_ah_opp',\n",
       " 'bets_ts_basic_10c_2y_ah_opp',\n",
       " 'bets_fb_10c_log_2y_ah_opp']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_keys(COL_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_id =  'anon_10sl_4c_2d_1yhc'\n",
    "config_id =  'anon_10sl_4c_2d_4tc_4cat_1yhc'\n",
    "config_id =  'anon_10sl_4c_2d_1yhc_prune'\n",
    "config_id = 'anon_10sl_6c_1yhc'\n",
    "config_id =  'anon_10sl_4c_2d_1yhc'\n",
    "config_id = 'bets_processed_6c_1yhc'\n",
    "config_id =  'bets_processed_12c_2yoverunder'\n",
    "config_id =  'bets_tennis_6c_2y_ha_opp'\n",
    "#config_id =  'tsexp_10sl_4c_2d_1yhc'\n",
    "col_config = read_config(config_id, COL_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# def build_data_params(df_path, trn_end=None, val_end=None, test_end=None, splitter_fn=TSSplitter(), \n",
    "#                       col_config=None, col_fn=None, bs=64, nrows=None, ss_dis=True):\n",
    "# #     assert col_config or col_fn, 'need to pass either cont. cols and y cols, or a col_fn'\n",
    "\n",
    "#     assert col_config, 'need to pass columns configuration'\n",
    "    \n",
    "#     if trn_end and val_end:\n",
    "#         splits=L(L(range(trn_end)), L(range(trn_end, val_end)))\n",
    "#         if test_end: splits.append(L(range(val_end, test_end)))\n",
    "#     else:\n",
    "#         splits = splitter_fn\n",
    "    \n",
    "#     cols_c, cols_d, cols_y, cols_config_id, cols_cont, cols_cat = map(\n",
    "#         col_config.__getitem__, ['cols_c', 'cols_d', 'cols_y', 'id', 'cols_cont', 'cols_cat'])\n",
    "\n",
    "# #     dataset_name = f'{df\n",
    "    \n",
    "#     data_params = defaultdict(lambda:None, {'df_path':df_path, 'splits':splits, 'col_config_id':cols_config_id, \n",
    "#                                             'cols_c':cols_c, 'cols_d':cols_d, 'cols_y':cols_y, 'cols_cont':cols_cont,\n",
    "#                                              'cols_cat':cols_cat, 'bs':bs,  'nrows':nrows, 'ss_dis':ss_dis})\n",
    "# #                'ds_full_path':ds_full_path, \n",
    "#                  #'dataset_name':dataset_id, \n",
    "              \n",
    "#     return data_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cols_c', 'cols_y', 'id', 'cols_d'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_config['prune']='hcodds_col'\n",
    "# col_config['hcodds_col'] = 'nf2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_config['cols_d']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/johannes/google-drive/data/bets_tennis_20210330_opp_full.csv')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_config['cols_y'] = 'y1_gb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_path=Path('/home/johannes/coding/python/scrape/bets_processed.csv')\n",
    "#df_path=Path('/home/johannes/coding/python/scrape/bets_historic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.read_csv(df_path).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_params = build_data_params(df_path, col_config=col_config, nrows=218000, bs=256, ss_dis=True,\n",
    "#                                trn_end=160000, val_end=185000, test_end=210000)\n",
    "\n",
    "data_params = build_data_params(df_path, col_config=col_config, nrows=100000, bs=256, ss_dis=True,\n",
    "                                trn_end=10000, val_end=15000, test_end=20000)\n",
    "#data_params = build_data_params(df_path, col_config=col_config, nrows=None, bs=256, ss_dis=True,\n",
    "#                               trn_end=80000, val_end=120000, test_end=120010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['df_path', 'splits', 'col_config_id', 'cols_c', 'cols_d', 'cols_y', 'cols_cont', 'cols_cat', 'hcodds_col', 'bs', 'prune', 'nrows', 'ss_dis', 'classification'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## no timeseries columns\n",
    "# data_params['cols_c']=None\n",
    "# data_params['cols_d']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bets_tennis_6c_2y_ha_opp'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pl_home_away', 'pl_home_away_opp']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_params['cols_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['arch', 'n_epochs', 'max_lr', 'wd', 'loss_fn_name', 'alpha', 'metrics', 'N', 'magnitude', 'seed', 'pct_start', 'div_factor', 'aug'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "fn = 'db_stats.pkl'\n",
    "with open(fn, 'rb') as f:\n",
    "    stats = pickle.load(f)\n",
    "#data_params['stats'] = stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[-1.23145979],\n",
       "         [-1.58481115],\n",
       "         [ 0.01152437],\n",
       "         [-1.62793487],\n",
       "         [-2.01656012],\n",
       "         [-0.0115425 ]]]),\n",
       " array([[[87.22504699],\n",
       "         [91.45116496],\n",
       "         [ 1.72462071],\n",
       "         [86.52716082],\n",
       "         [91.44620106],\n",
       "         [ 1.72461679]]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'augmix'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_params['stats']=None\n",
    "train_params['aug']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params['metrics']=[unweighted_profit, unweighted_profit_05]\n",
    "train_params['aug']='randaugment'\n",
    "train_params['arch']='transformer_gb'\n",
    "train_params['arch']='inception'\n",
    "train_params['arch']='transformer_dl'\n",
    "train_params['aug_params']='nodim'\n",
    "train_params['dropout']=0.1\n",
    "train_params['fc_dropout']=0.1\n",
    "train_params['save_best'] = False\n",
    "train_params['pretrained'] = 'bets_historic_20210302_over_bets_processed_12c_2yoverunder_80_110_110_tst_tsbert_100_points.pth'\n",
    "# train_params['metrics']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 2\n",
      "<class 'torchtools.dataloader.TSDatasets5'>\n",
      "[<class 'torchtools.data.TSTensor'>, <class 'torchtools.data.TensorFloat'>]\n",
      "fast part\n",
      "3\n",
      "[True, False, False]\n",
      "[<class 'torchtools.data.TSTensor'>, <class 'torchtools.data.TensorFloat'>]\n",
      "fast part\n",
      "[<class 'torchtools.data.TSTensor'>, <class 'torchtools.data.TensorFloat'>]\n",
      "fast part\n",
      "[<class 'torchtools.data.TSTensor'>, <class 'torchtools.data.TensorFloat'>]\n",
      "fast part\n",
      "setups torch.Size([10000, 6, 10]) False\n"
     ]
    }
   ],
   "source": [
    "ts_experiment = TSExperiments(save_model=False) #can set save model flag here\n",
    "ts_experiment.setup_data(data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline: TSStandardize"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_experiment.dls.after_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_params['loss_fn_name']='gambler'\n",
    "#train_params['metrics']=[gl_profit]\n",
    "train_params['metrics'] = [top10_double, top5_double]\n",
    "#train_params['alpha']=1.002\n",
    "#train_params['arch'] = 'inception'\n",
    "train_params['loss_fn_name'] = 'leaky_loss_squared'\n",
    "train_params['loss_fn_name'] = 'leaky_loss_2d'\n",
    "train_params['loss_fn_name'] = 'double_loss_squared'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.setup_training(train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_experiment.save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline: TSStandardize"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_experiment.dls.after_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arch': 'transformer_dl', 'n_epochs': 2, 'max_lr': 3e-06, 'wd': 0.03, 'loss_fn_name': 'double_loss_squared', 'alpha': 0.5, 'metrics': [<function top10_double at 0x7f09f54daaf0>, <function top5_double at 0x7f09f54dab80>], 'N': 2, 'magnitude': 0.3, 'seed': 1234, 'pct_start': 0.3, 'div_factor': 25.0, 'aug': 'randaugment', 'aug_params': 'nodim', 'dropout': 0.1, 'fc_dropout': 0.1, 'save_best': False, 'pretrained': 'bets_historic_20210302_over_bets_processed_12c_2yoverunder_80_110_110_tst_tsbert_100_points.pth', 'bs': 256, 'ds_id': 'bets_tennis_20210330_opp_full_bets_tennis_6c_2y_ha_opp_10_15_20', 'classification': False, 'prune': None}\npct_start: 0.3 div_factor: 25.0\n[TSStandardize:\nencodes: (NumpyTensor,object) -> encodes\n(TSTensor,object) -> encodes\n(TSIntTensor,object) -> encodes\ndecodes: ]\nPipeline: TSStandardize Pipeline: TSStandardize Pipeline: TSStandardize\nRandAugment:\nencodes: (TSTensor,object) -> encodes\n(TSIntTensor,object) -> encodes\ndecodes: \nFalse\n<function double_loss_squared at 0x7f09f54da310>\ncheck unmatched_layers: ['backbone.W_P.weight']\nPipeline: RandAugment -> TSStandardize\n"
     ]
    },
    {
     "data": {
      "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    \n",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='0' class='' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      \n    </div>\n    ",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hypers = {'n_epochs' : [2], 'max_lr':[3e-6], 'N':[2], 'magnitude':[0.3], 'wd':[0.03]}\n",
    "df_results_fn = 'results_exploration.csv'\n",
    "ts_experiment.run_grid_search(hypers, df_results_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=ts_experiment.dls.train.after_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[YWarp:\n",
       " encodes: (TSTensor,object) -> encodes\n",
       " (TSIntTensor,object) -> encodes\n",
       " decodes: ,\n",
       " YNormal:\n",
       " encodes: (TSTensor,object) -> encodes\n",
       " (TSIntTensor,object) -> encodes\n",
       " decodes: ,\n",
       " YScale:\n",
       " encodes: (TSTensor,object) -> encodes\n",
       " (TSIntTensor,object) -> encodes\n",
       " decodes: ,\n",
       " YScaleChannel:\n",
       " encodes: (TSTensor,object) -> encodes\n",
       " (TSIntTensor,object) -> encodes\n",
       " decodes: ,\n",
       " TimeWarp:\n",
       " encodes: (TSTensor,object) -> encodes\n",
       " (TSIntTensor,object) -> encodes\n",
       " decodes: ,\n",
       " TimeNormal:\n",
       " encodes: (TSTensor,object) -> encodes\n",
       " decodes: ,\n",
       " Zoomin:\n",
       " encodes: (TSTensor,object) -> encodes\n",
       " (TSIntTensor,object) -> encodes\n",
       " decodes: ,\n",
       " Zoomout:\n",
       " encodes: (TSTensor,object) -> encodes\n",
       " (TSIntTensor,object) -> encodes\n",
       " decodes: ,\n",
       " RandZoom:\n",
       " encodes: (TSTensor,object) -> encodes\n",
       " (TSIntTensor,object) -> encodes\n",
       " decodes: ,\n",
       " RandTimesteps:\n",
       " encodes: (TSTensor,object) -> encodes\n",
       " (TSIntTensor,object) -> encodes\n",
       " decodes: ,\n",
       " Cutout:\n",
       " encodes: (TSTensor,object) -> encodes\n",
       " (TSIntTensor,object) -> encodes\n",
       " decodes: ,\n",
       " TimestepZero:\n",
       " encodes: (TSTensor,object) -> encodes\n",
       " (TSIntTensor,object) -> encodes\n",
       " decodes: ,\n",
       " Crop:\n",
       " encodes: (TSTensor,object) -> encodes\n",
       " (TSIntTensor,object) -> encodes\n",
       " decodes: ,\n",
       " RandomCrop:\n",
       " encodes: (TSTensor,object) -> encodes\n",
       " (TSIntTensor,object) -> encodes\n",
       " decodes: ,\n",
       " Maskout:\n",
       " encodes: (TSTensor,object) -> encodes\n",
       " (TSIntTensor,object) -> encodes\n",
       " decodes: ]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe[0].tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = ts_experiment.dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, y = ts_experiment.learn.get_preds(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_mod(ts_experiment.dls, arch='transformer_dl', dropout=0.1, fc_dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = torch.where(preds>torch.quantile(preds, 0.99))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[idxs, 0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augs=RandAugment(N=2, magnitude=0.2, verbose=False)\n",
    "# ts_experiment.dls.after_batch.add(augs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn=gamblers_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.df_base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m = get_mod(ts_experiment.dls, arch='inception_gb')\n",
    "m = get_mod(ts_experiment.dls, arch='transformer', dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsai.models.InceptionTimePlus import *\n",
    "from tsai.models.TSTPlus import *\n",
    "from tsai.learner import ts_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = InceptionTimePlus(6, 1, seq_len=10, y_range=(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = get_loss_fn('leaky_loss_squared', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(ts_experiment.dls, m, MSELossFlat(), cbs=TSBERT())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.TSBERT.show_preds(sharey=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsai.models.utils import build_ts_model, transfer_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m2 = InceptionTimePlus(6, 1, seq_len=10, y_range=(-1,1))\n",
    "m2 = TSTPlus(6, 1, seq_len=10, y_range=(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_weights(m2, Path('./data/TSBERT/model.pth') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augs=RandAugment(N=3, magnitude=0.3, verbose=False)\n",
    "ts_experiment.dls.after_batch.add(augs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(ts_experiment.dls, m2, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, 3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, 3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, y = learn.get_preds(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_10(preds, y), top_10(preds, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.softmax(preds)[:,1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = F.softmax(preds, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = torch.where(preds[:, 1]>0.9)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[idxs].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = ts_experiment.df_base.iloc[40000:45000].y1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1[idxs].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# class TabNetTT(nn.Module):\n",
    "#     '''\n",
    "#     convenience wrapper for pure TabNetModel models\n",
    "#     '''\n",
    "#     def __init__(self, emb_szs, n_cont, out_sz, **kwargs):\n",
    "#         super().__init__()\n",
    "#         self.tab = TabNetModel(emb_szs, n_cont, out_sz, **kwargs)\n",
    "        \n",
    "#     def forward(self, xt, xcat):\n",
    "#         xcat=xcat.long() if xcat is not None else None\n",
    "#         xt=xt.float() if xt is not None else None\n",
    "#         return self.tab(xcat, xt)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# def emb_sz_rule(n_cat):\n",
    "#     \"Rule of thumb to pick embedding size corresponding to `n_cat`\"\n",
    "#     return min(600, round(1.6 * n_cat**0.56))\n",
    "\n",
    "# # Cell\n",
    "# def _one_emb_sz(classes, n, sz_dict=None):\n",
    "#     \"Pick an embedding size for `n` depending on `classes` if not given in `sz_dict`.\"\n",
    "#     sz_dict = ifnone(sz_dict, {})\n",
    "#     n_cat = len(classes[n])\n",
    "#     sz = sz_dict.get(n, int(emb_sz_rule(n_cat)))  # rule of thumb\n",
    "#     return n_cat,sz\n",
    "\n",
    "# # Cell\n",
    "# def get_emb_sz(to, sz_dict=None):\n",
    "#     \"Get default embedding size from `TabularPreprocessor` `proc` or the ones in `sz_dict`\"\n",
    "#     return [_one_emb_sz(to.classes, n, sz_dict) for n in to.cat_names]\n",
    "\n",
    "# def get_mod(dls, arch='inception'):\n",
    "    \n",
    "#     if dls.n_channels==0:\n",
    "#         assert dls.cols_cat is not None or dls.cols_cont is not None, 'no tabular columns'\n",
    "#         emb_szs= [_one_emb_sz(dls.voc, c) for c in listify(dls.cols_cat)] \n",
    "#         return TabNetTT(emb_szs=emb_szs, n_cont=len(dls.cols_cont), out_sz=dls.n_targets)\n",
    "    \n",
    "#     if dls.cols_cat is not None or dls.cols_cont is not None:\n",
    "#         emb_szs= [_one_emb_sz(dls.voc, c) for c in listify(dls.cols_cat)] \n",
    "#         return InceptionTimeD_Mixed(dls.n_channels_c, dls.n_channels_d, dls.n_targets, \n",
    "#                                     len(dls.cols_cont), emb_szs=emb_szs)\n",
    "#     else:\n",
    "#         if dls.dataset.has_xtype[1]: ##discrete channels\n",
    "#             return InceptionTimeD(dls.n_channels, dls.n_targets)\n",
    "#         else:\n",
    "#             return InceptionTimeSgm(dls.n_channels, dls.n_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fast_tabnet.core import *\n",
    "m=get_mod(ts_experiment.dls, 'transformer', dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn = Learner(ts_experiment.dls, m, get_loss_fn('leaky_loss', alpha=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_mock_learner(ts_experiment, arch):\n",
    "    #return Learner(ts_runner.db, model=ts_runner.train_params['arch'](ts_runner.db.features, ts_runner.db.c))\n",
    "    model = get_mod(ts_experiment.dls, arch=arch, dropout=0.1)\n",
    "    learn = Learner(ts_experiment.dls, model, get_loss_fn('leaky_loss', alpha=0.5))\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.learn = _get_mock_learner(ts_experiment, 'transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_base_dir(is_colab=False):\n",
    "    return Path('./') if not is_colab else Path('~/google-drive').expanduser()\n",
    "\n",
    "def _results_fn(is_colab=False, is_class=False):\n",
    "    if is_colab:\n",
    "        results_fn='results_colab.csv' if not is_class else 'results_colab_class.csv'\n",
    "    else:\n",
    "        results_fn='results_exploration.csv' if not is_class else 'results_exploration_class.csv' \n",
    "    return results_fn\n",
    "\n",
    "class EvalConfig:\n",
    "    '''\n",
    "    eval configuration wrapper\n",
    "#export\n",
    "    #constants\n",
    "    #RESULTS_DIR='experiments/results'\n",
    "    #PREDS_DIR='experiments/preds'\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    def __init__(self, is_colab, is_class, df_base_path, results_loc='experiments/results',\n",
    "                preds_loc='experiments/preds', model_loc='experiments/models', preprocess=True):\n",
    "        self.is_colab, self.is_class, self.df_base_path = is_colab, is_class, df_base_path\n",
    "        self.results_loc, self.preds_loc, self.model_loc = results_loc, preds_loc, model_loc\n",
    "        \n",
    "    @property\n",
    "    def base_dir(self): return _get_base_dir(self.is_colab)\n",
    "    @property\n",
    "    def preds_dir(self): return self.base_dir/self.preds_loc\n",
    "    @property\n",
    "    def results_dir(self): return self.base_dir/self.results_loc\n",
    "    @property\n",
    "    def model_dir(self): return self.base_dir/self.model_loc\n",
    "    @property\n",
    "    def df_results_path(self): return self.results_dir/_results_fn(self.is_colab, self.is_class)\n",
    "    @property\n",
    "    def df_results(self):\n",
    "        print(self.df_results_path)\n",
    "        if not hasattr(self, '_df_results'): \n",
    "            self._df_results = pd.read_csv(self.df_results_path)\n",
    "            pre_process_results(self._df_results)\n",
    "        return self._df_results\n",
    "            \n",
    "    @property\n",
    "    def df_base(self):\n",
    "        if not hasattr(self, '_df_base'): self._df_base = pd.read_csv(self.df_base_path)\n",
    "        return self._df_base\n",
    "    @property\n",
    "    def m_cols(self):\n",
    "        return metric_cols_classification if self.is_class else metric_cols\n",
    "    \n",
    "    def reload_df_results(self):\n",
    "        self._df_results = pd.read_csv(self.df_results_path)\n",
    "        pre_process_results(self._df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_colab=True,\n",
    "is_class=False\n",
    "eval_conf = EvalConfig(is_colab, is_class, df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_conf.model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _reload_model(ts_experiment, eval_conf, idx):\n",
    "    '''\n",
    "    load model into ts_experiment\n",
    "    '''\n",
    "    fn = eval_conf.df_results.iloc[idx]['model_fn']\n",
    "    arch = eval_conf.df_results.iloc[idx]['arch']\n",
    "    ts_experiment.learn = _get_mock_learner(ts_experiment, arch)\n",
    "    ts_experiment.learn.load(eval_conf.model_dir/Path(fn).stem)\n",
    "    return\n",
    "\n",
    "    if not test:\n",
    "        fn = eval_conf.preds_dir/eval_conf.df_results.iloc[idx]['val_preds'] \n",
    "    else:\n",
    "        fn=eval_conf.preds_dir/eval_conf.df_results.iloc[idx]['test_preds']\n",
    "    return torch.load(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls experiments/models/colab_downloads/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.learn.load(ts_experiment.modelPath('model_pretrained_13_best_combo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = [\n",
    "    '/home/johannes/google-drive/experiments/models/model_6228443993079809685',\n",
    "    '/home/johannes/google-drive/experiments/models/model_1978183445477685032',\n",
    "    '/home/johannes/google-drive/experiments/models/model_4418028675494595164',\n",
    "    '/home/johannes/google-drive/experiments/models/model_2741577789858916551',\n",
    "    '/home/johannes/google-drive/experiments/models/model_3321331134466174406',\n",
    "    '/home/johannes/google-drive/experiments/models/model_3076388975636222346',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_reload_model(ts_experiment, eval_conf, 1771)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_preds(ts_experiment, eval_conf, idxs, dl_idx=2):\n",
    "    preds = []\n",
    "    for idx in idxs:\n",
    "        _reload_model(ts_experiment, eval_conf, idx)\n",
    "        preds.append(ts_experiment.learn.get_preds(dl_idx)[0])\n",
    "    return preds\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def complement_idxs(idxs):  \n",
    "    def _c(idx):\n",
    "        return idx+1 if idx%2==0 else idx-1\n",
    "    return tensor([_c(idx) for idx in idxs.numpy()])\n",
    "\n",
    "def combine_idxs(idxs1, idxs2):\n",
    "    return list(set(idxs1.numpy()).union(set(idxs2.numpy())))\n",
    "\n",
    "def combine_idxs_2(idxs1, idxs2):\n",
    "    return list(set(idxs1.numpy()).intersection(set(idxs2.numpy())))\n",
    "\n",
    "def _get_bet_idxs(preds, threshold=None, quantile=0.9, complement=False):\n",
    "    if threshold is None: \n",
    "        threshold = np.quantile(preds, quantile) if not complement else -np.quantile(-preds, quantile)\n",
    "    print(threshold)\n",
    "    return torch.where(preds>threshold)[0] if not complement else complement_idxs(torch.where(preds<threshold)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def combo_profit(preds, y_true, threshold=0.8, quantile=0.9):\n",
    "    '''\n",
    "    combination profit\n",
    "    preds in (0,1)\n",
    "    '''\n",
    "    preds = preds.squeeze()\n",
    "    idxs_pos = torch.where(preds>= torch.quantile(preds, quantile))\n",
    "    idxs_neg = torch.where(preds<= torch.quantile(preds, 1-quantile))\n",
    "    m_value = y_true[idxs_pos].mean() + (-1)*(y_true[idxs_neg] + 4.2).mean()\n",
    "    return m_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def quantile_profit(preds, y_true, quantile=0.9, bottom=False):\n",
    "    '''\n",
    "    profit for top quantile predictions\n",
    "    '''\n",
    "    preds = preds.squeeze()\n",
    "    if not bottom:\n",
    "        idxs = torch.where(preds>= torch.quantile(preds, quantile))\n",
    "    else:\n",
    "        idxs = torch.where(preds<= torch.quantile(preds, 1-quantile))\n",
    "    m_value = y_true[idxs].mean()\n",
    "    return m_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_top_10 = partial(quantile_profit, quantile=0.9, bottom=False)\n",
    "quantile_top10.__name__ = 'top10'\n",
    "quantile_bottom_10 = partial(quantile_profit, quantile=0.9, bottom=True)\n",
    "quantile_bottom_10.__name__ = 'bottom10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_10(preds, y_true):\n",
    "    return partial(quantile_profit, quantile=0.9)(preds, y_true)\n",
    "def bottom_10(preds, y_true):\n",
    "    return partial(quantile_profit, quantile=0.9, bottom=True)(preds, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10, bottom_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p,y = avg_preds[:], torch.tensor(df_test.iloc[:].pl_ah.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_profit(p,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = [1764, 1784]\n",
    "idxs = [1685, 1684, 1683, 1682, 1681, 1680]\n",
    "idxs = [1764, 1758, 1684, 1680]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = _load_preds(ts_experiment, eval_conf, idxs, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = eval_conf.df_base\n",
    "df_test = df_base.iloc[:200000].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds = torch.cat(preds, 1).mean(1)\n",
    "df_test['preds'] = avg_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.date = pd.to_datetime(df_test.date)\n",
    "df_test['year'] = df_test.date.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.quantile(avg_preds, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 0.9\n",
    "idxs_r = _get_bet_idxs(avg_preds, quantile=q)\n",
    "idxs_c = _get_bet_idxs(avg_preds, quantile=q, complement=True)\n",
    "idxs_i = combine_idxs_2(idxs_r, idxs_c)\n",
    "idxs_u = combine_idxs(idxs_r, idxs_c)\n",
    "df_test.iloc[idxs_u][['pl_1x2', 'pl_ah', 'pl_1x2_fh', 'pl_ah_fh']].agg(['mean', 'sum', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 0.9\n",
    "idxs_r = _get_bet_idxs(avg_preds, quantile=q)\n",
    "idxs_c = _get_bet_idxs(avg_preds, quantile=q, complement=True)\n",
    "idxs_i = combine_idxs_2(idxs_r, idxs_c)\n",
    "idxs_u = combine_idxs(idxs_r, idxs_c)\n",
    "df_test.iloc[idxs_c].loc[pd.notnull(df_test.loc[idxs_c, 'horse_ah_fh'])][['pl_1x2', 'pl_ah', 'pl_1x2_fh', 'pl_ah_fh', 'pl_ou']].agg(['mean', 'sum', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs_r = _get_bet_idxs(avg_preds)\n",
    "idxs_c = _get_bet_idxs(avg_preds, complement=True)\n",
    "idxs_i = combine_idxs_2(idxs_r, idxs_c)\n",
    "df_test.iloc[idxs_i].groupby('year')[['pl_1x2', 'pl_ah']].agg(['mean', 'sum', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.iloc[idxs_i][['pl_1x2', 'pl_ah']].agg(['mean', 'sum', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.iloc[idxs_c][['pl_1x2', 'pl_ah']].agg(['mean', 'sum', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.iloc[idxs_i].query('field==\"away\"')[['pl_1x2', 'pl_ah']].agg(['mean', 'sum', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.iloc[170000].date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idxs = [1685, 1684, 1683, 1682, 1681, 1680]\n",
    "preds = _load_preds(ts_experiment, eval_conf, idxs, 2)\n",
    "avg_preds = torch.cat(preds, 1).mean(1)\n",
    "df_test = df_base.iloc[25000:]\n",
    "df_test['preds'] = avg_preds\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.date = pd.to_datetime(df_test.date)\n",
    "df_test.query('status==\"open\" and date>=datetime.now()')[['date', 'horse', 'opponent', 'preds']].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.query('status==\"open\" and date>=datetime.now()')[['date', 'horse', 'opponent', 'preds']].to_csv('transformer_ensemble.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds = torch.cat(preds, 1).mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.learn.load(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, y = ts_experiment.learn.get_preds(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = eval_conf.df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_base.iloc[25000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_base.iloc[5000:25000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['preds'] = avg_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 200\n",
    "df_test.query('status==\"open\"')[['date', 'horse', 'opponent', 'preds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val['preds'] = avg_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.quantile(avg_preds, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complement_idxs(idxs):  \n",
    "    def _c(idx):\n",
    "        return idx+1 if idx%2==0 else idx-1\n",
    "    return tensor([_c(idx) for idx in idxs.numpy()])\n",
    "\n",
    "def combine_idxs(idxs1, idxs2):\n",
    "    return list(set(idxs1.numpy()).union(set(idxs2.numpy())))\n",
    "\n",
    "def combine_idxs_2(idxs1, idxs2):\n",
    "    return list(set(idxs1.numpy()).intersection(set(idxs2.numpy())))\n",
    "\n",
    "def _get_bet_idxs(preds, threshold=None, quantile=0.9, complement=False):\n",
    "    if threshold is None: \n",
    "        threshold = np.quantile(preds, quantile) if not complement else -np.quantile(-preds, quantile)\n",
    "    print(threshold)\n",
    "    return torch.where(preds>threshold)[0] if not complement else complement_idxs(torch.where(preds<threshold)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idxs = torch.where(avg_preds<=-.99945)[0]\n",
    "\n",
    "idxs_r = _get_bet_idxs(avg_preds, quantile=0.9, complement=False)\n",
    "idxs_c = _get_bet_idxs(avg_preds, quantile=0.9, complement=True)\n",
    "idxs_i = combine_idxs_2(idxs_r, idxs_c)\n",
    "idxs_u = combine_idxs(idxs_r, idxs_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.iloc[idxs_u][['pl_1x2', 'pl_ah']].agg(['mean', 'sum', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.query('preds<-.99945')[['pl_1x2', 'pl_ah']].agg(['mean', 'sum', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = ts_experiment.learn.dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb.std(dim=(0,2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = ts_experiment.df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = torch.where(preds<-0.9998692870140076)[0]; idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.iloc[5000:25000].iloc[idxs][['pl_ah', 'pl_1x2']].agg(['mean', 'sum', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.iloc[25000].date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.quantile(preds, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_profit(preds, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers={'max_lr':[5e-5, 7e-5], 'n_epochs':[10]}\n",
    "# hypers={'max_lr':[3e-5], 'n_epochs':[10], 'alpha': [1.002, 1.004]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_top_10 = partial(quantile_profit, quantile=0.9, bottom=False)\n",
    "quantile_top10.__name__ = 'top10'\n",
    "quantile_bottom_10 = partial(quantile_profit, quantile=0.9, bottom=True)\n",
    "quantile_bottom_10.__name__ = 'bottom10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_top_90.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params['save_best'] = False\n",
    "train_params['metrics'] = [unweighted_profit, combo_profit, top_10, bottom_10]\n",
    "ts_experiment.setup_training(train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.results_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_fn = 'results_exploration.csv'\n",
    "# ts_experiment.run_experiment(df_fn=df_results_fn)\n",
    "ts_experiment.run_grid_search(hypers, df_results_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.learn.cbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ts_experiment.learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -lht ./experiments/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, y = learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_loss(preds, y, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_profit_05(preds, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn.load('model_8182037215258782875')\n",
    "learn.load('model_4436322193913987044')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, y = learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_loss(preds, y, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load('./experiments/preds/val_preds_3557453625480808387.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = F.softmax(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = torch.where(preds[:,0]>0.6)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[idxs].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = pd.read_csv(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.iloc[40000:45000]['y0'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.iloc[40000:45000][['nf0', 'nf1', 'nf2', 'y0', 'y1']].iloc[idxs].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def gamblers_loss(preds, y_true, o=1.005):\n",
    "    '''\n",
    "    regression adaption of gambler's loss\n",
    "    o is a hyperparameter\n",
    "    '''\n",
    "    #\n",
    "    preds = F.softmax(preds, dim=1)\n",
    "    outputs, reservation = preds[:, :-1].squeeze(), preds[:, -1]\n",
    "    #print(outputs, reservation)\n",
    "    # gain = torch.gather(outputs, dim=1, index=targets.unsqueeze(1)).squeeze()\n",
    "    doubling_rate = (o*outputs*y_true + reservation).log()\n",
    "    #print(doubling_rate)\n",
    "    return - doubling_rate.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TSTensor([2,3])\n",
    "t2 = TSIntTensor([3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers={'max_lr':[3e-5], 'n_epochs':[10,15]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _dict_product(params):\n",
    "            values = list(itertools.product(*params.values()))\n",
    "            return [dict(zip(params.keys(), values[i])) for i in range(len(values))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = _dict_product(hypers)\n",
    "for config in configs: print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, ytrue=ts_experiment.learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_profit(preds, ytrue, -1.99999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.df_base['y1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat([t,t2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob = ts_experiment.dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = learn.dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mod??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params['aug'] = 'randaugment'\n",
    "train_params['verbose']=False\n",
    "train_params['n_epochs']=20\n",
    "train_params['max_lr']=1e-5\n",
    "train_params['wd']=0.03\n",
    "train_params['arch'] = InceptionTimeD\n",
    "train_params['augmixss']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers={'n_epochs':[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls=ts_experiment.dls\n",
    "dls.n_channels_c, dls.n_channels_d, dls.n_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.cols_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_fn = 'results_exploration.csv'\n",
    "ts_experiment.run_grid_search(hypers, df_results_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_fn = 'results_exploration.csv'\n",
    "ts_experiment.run_grid_search(hypers, df_results_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, y_true = ts_experiment.learn.get_preds(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unweighted_profit(preds[:,1], y_true[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unweighted_profit(preds[:,0], y_true[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.rand((5,2))\n",
    "yt = torch.rand((5,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p*yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8659*0.3560"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_fn = 'results_exploration.csv'\n",
    "ts_experiment.run_grid_search(hypers, df_results_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.dls.n_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb=ts_experiment.dls.one_batch()\n",
    "ts_experiment.learn.model(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.learn.loss_func(ts_experiment.learn.model(xb),yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_loss_2d(ts_experiment.learn.model(xb),yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = ts_experiment.learn.model(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_profit(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_profit(preds[:,0], yb[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_profit(preds[:,1], yb[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(preds[:,1].detach().cpu().numpy(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigmoid??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_profit??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_loss(preds[:,0], yb[:,0]) + leaky_loss(preds[:,1], yb[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_loss(preds, yb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_loss_2d(preds, yb, alpha=0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_fn = 'results_exploration.csv'\n",
    "ts_experiment.run_grid_search(hypers, df_results_fn=df_results_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandAugment??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_fn = 'results_exploration.csv'\n",
    "ts_experiment.run_experiment(df_fn=df_results_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.dls.after_batch[1].order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.dls.after_batch[0].order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipeline??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compose_tfms??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_fn = 'results_exploration.csv'\n",
    "ts_experiment.run_experiment(df_fn=df_results_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.dls.after_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc,xd,y = ts_experiment.dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.dls.ptls[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.dls.after_batch[0].mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.dls.after_batch[0].mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc.mean((0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xd.mean((0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params['bs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.dls.bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.dls.one_batch()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params['splits'] = L(L(range(8000)), L(range(8000,9000)), L(range(9000,10000)))\n",
    "# data_params['splits'] = L(L(range(120000)), L(range(120000,160000)), L(range(160000,200000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params['splits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers = {'n_epochs': [5], 'max_lr':[1e-5]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New heading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR=Path('./')\n",
    "BASE_DIR=Path('~/google-drive').expanduser() # for colab\n",
    "\n",
    "RESULTS_DIR=BASE_DIR/'experiments/results'\n",
    "PREDS_DIR=BASE_DIR/'experiments/preds'\n",
    "# RESULT_FN='results_script.csv'\n",
    "RESULTS_FN='results_colab.csv'\n",
    "\n",
    "df_path = Path('~/coding/python/betting/experiments/datasets/bi_sample_pruned_anon.csv').expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results=pd.read_csv(BASE_DIR/RESULTS_DIR/RESULTS_FN)\n",
    "df_base = pd.read_csv(df_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.groupby('ds_id')[['val_loss', 'unweighted_profit_0_value']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _id_from_splits(splits):\n",
    "    return '_'.join([str(l[-1]+1//1000) for l in splits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_id_from_splits(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(splits[0][-1]+1)//1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=99\n",
    "df_results.query('ds_id.str.contains(\"1yhc\")').sort_values(by='unweighted_profit_0_value', ascending=False).head(29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _reload_preds(df, idx, test=False, preds_path=PREDS_DIR):\n",
    "    fn = Path(preds_path)/df.iloc[idx]['val_preds'] if not test else Path(preds_path)/df.iloc[idx]['test_preds']\n",
    "    return torch.load(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _average_preds(df, idxs, test=False, normalize=False):\n",
    "    preds = np.array([_reload_preds(df, idx, test).numpy() for idx in idxs])\n",
    "    if normalize:\n",
    "        mean,std = preds.mean(), preds.std()\n",
    "        preds = (preds-mean)/std\n",
    "    return preds.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs=np.arange(-15, -10)\n",
    "metric_cols = ['unweighted_profit_0_value', 'unweighted_profit_05_1_value']\n",
    "loss_cols = ['val_loss', 'trn_loss']\n",
    "df_results.iloc[idxs][metric_cols+loss_cols].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.iloc[idxs][metric_cols+loss_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds=_average_preds(df_results, idxs, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=ts_experiment.df_base.iloc[160000:185000]['y1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_profit(tensor(avg_preds), tensor(y_true)), unweighted_profit_05(tensor(avg_preds), tensor(y_true)), get_loss_fn('leaky_loss', alpha=0.5)(tensor(avg_preds), tensor(y_true))\n",
    "# unweighted_profit(tensor(avg_preds), tensor(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_profit(tensor(avg_preds), tensor(y_true), threshold=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(avg_preds>1.5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_avg_bet_df(df_base, idxs, df_, model_idxs, threshold=0., test=False, quantile=None):\n",
    "    trn_idxs, val_idxs, test_idxs = idxs\n",
    "    print(val_idxs)\n",
    "    avg_preds = _average_preds(df_, model_idxs, test=test, normalize=False)\n",
    "    if quantile is not None: threshold=np.quantile(avg_preds, quantile)\n",
    "    print(threshold, avg_preds.shape)\n",
    "    bet_idxs = np.where(avg_preds>threshold)[0]\n",
    "    df_res = df_base.iloc[test_idxs] if test else df_base.iloc[val_idxs]\n",
    "    return df_res.reset_index(drop=True).iloc[bet_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_results_view(df, config='default', max_rows=20, sorted=True):\n",
    "    augment_params = ['N', 'magnitude']\n",
    "    fitting_params = ['n_epochs', 'max_lr', 'wd', 'pct_start', 'div_factor']\n",
    "#     metric_cols = [c for c in df.columns if 'metric_' in c and '_value' in c]\n",
    "    metric_cols = ['unweighted_profit_0_value', 'unweighted_profit_05_1_value']\n",
    "    loss_cols = ['val_loss', 'trn_loss']\n",
    "    fn_cols=['val_preds', 'test_preds']#, 'model_fn']\n",
    "    experiment_cols = ['arch', 'bs', 'ds_id']\n",
    "    var_cols = ['Timestamp']\n",
    "#     return df[fitting_params+augment_params+metric_cols+loss_cols+experiment_cols+fn_cols+var_cols].sort_values(\n",
    "#         by=loss_cols[0], ascending=True).head(max_rows)\n",
    "    return df[fitting_params+augment_params+metric_cols+loss_cols+experiment_cols+fn_cols+var_cols].sort_values(\n",
    "        by=metric_cols[0], ascending=False).head(max_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results_view(df_results.query('ds_id.str.contains(\"1yhc\")').sort_values(by='unweighted_profit_0_value', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=ts_experiment.df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bets=get_avg_bet_df(df, ts_experiment.splits, df_results, [214, 228, 230], quantile=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bets[['y0', 'y1']].agg((['mean', 'sum', 'count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results_view(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.ds_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.iloc[200][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds = _average_preds(df_results, [176,177,178,179], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds = _average_preds(df_results, [173,174], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(avg_preds, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[160000:185000].iloc[np.where((avg_preds>1.66)[:,0])][['y0', 'y1']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val=df.iloc[160000:185000].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_config['cols_c'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bet_idxs=np.where(avg_preds[:,0]>0.3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where((avg_preds.squeeze()>0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.nanmean(df_val[col_config['cols_c'][0]].values, axis=0))\n",
    "plt.plot(np.nanmean(df_val[col_config['cols_c'][1]].values, axis=0))\n",
    "plt.plot(np.nanmean(df_val[col_config['cols_c'][2]].values, axis=0))\n",
    "plt.plot(np.nanmean(df_val[col_config['cols_c'][3]].values, axis=0))\n",
    "# plt.plot(np.nanmean(df_val.iloc[bet_idxs][col_config['cols_c'][0]].values, axis=0), linestyle='dashed')\n",
    "# plt.plot(np.nanmean(df_val.iloc[bet_idxs][col_config['cols_c'][1]].values, axis=0), linestyle='dashed')\n",
    "# plt.plot(np.nanmean(df_val.iloc[bet_idxs][col_config['cols_c'][2]].values, axis=0), linestyle='dotted')\n",
    "# plt.plot(np.nanmean(df_val.iloc[bet_idxs][col_config['cols_c'][3]].values, axis=0), linestyle='dotted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[col_config['cols_c'][0]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds_fn = df_results.iloc[179]['val_preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_preds = torch.load(Path('./experiments/preds/')/val_preds_fn)\n",
    "val_preds = torch.load(Path('~/google-drive/experiments/preds/').expanduser()/val_preds_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y = ts_experiment.df_base.iloc[160000:185000][['y0', 'y1']].values\n",
    "val_y = ts_experiment.df_base.iloc[160000:185000]['y1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.linspace(0,1,11):\n",
    "    print(i, unweighted_profit(val_preds, tensor(val_y), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(val_preds, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(val_preds>0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(val_preds>0).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.linspace(0,0.99,10):\n",
    "    print(i,unweighted_profit(val_preds, tensor(val_y), i), weighted_profit(val_preds, tensor(val_y), i) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(val_preds.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.linspace(0,0.99,10):\n",
    "    print(i, unweighted_profit(val_preds[:,0], tensor(val_y)[:,0], i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.linspace(0,0.99,10):\n",
    "    print(i, unweighted_profit(val_preds[:,1], tensor(val_y)[:,1], i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nf2'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(val_preds.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((val_preds[:,0]>0.5)*(val_preds[:,1]>0.5)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs=((val_preds[:,0]>-2)*(val_preds[:,1]>0.22)*(preds_old[:,0]>0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs=((val_preds[:,0]>-2)*(val_preds[:,0]>0)*(preds_old[:,0]>0.2))\n",
    "idxs.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(val_preds.numpy(), 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(preds_old.numpy(), 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(avg_preds_weighted, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs= avg_preds_weighted>0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ts_experiment.df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[160000:185000].iloc[np.where(idxs.squeeze())][['y0', 'y1']].agg(['count', 'mean', 'sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_profit(val_preds[:,1], tensor(val_y)[:,1], 0.22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(preds_old.squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds = torch.stack([preds_old[:,0], val_preds[:,1]], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds_weighted = 0.5*preds_old[:,0]+0.5*val_preds[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(val_preds[:,1].numpy(), 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "15/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_dir_old = Path('~/coding/python/betting/experiments/dl/nn_exps/preds/val_preds_4816317650882923079.pt').expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_old = torch.load(preds_dir_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ts_experiment.df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[np.where(preds_old.squeeze()>0.39)][['y0', 'y1']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_profit_05(preds_old, tensor(df.iloc[160000:185000]['y0'].values), 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(preds_old>0).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[160000:185000].iloc[np.where(preds_old.squeeze()>0.4)][['y0', 'y1']].agg(['count', 'mean', 'sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[160000:185000].iloc[np.where(preds_old.squeeze()>0.4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(preds_old.squeeze()>0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=np.logical_and(val_preds[:,0]>0.5, val_preds[:,1]>0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(val_y*mask.numpy()[:, None]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_profit(val_preds.squeeze(), tensor(val_y)), unweighted_profit(val_preds.squeeze(), tensor(val_y), 0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(val_preds>0.4).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(val_preds.cpu().squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fn_test = 'results4.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.run_grid_search(hypers, df_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_arch(arch:str, with_discrete=False):\n",
    "    if arch.lower()=='inception': return InceptionTimeSgm if not with_discrete else InceptionTimeD\n",
    "    elif arch.lower()=='resnet': return 'ResNet not implemented'\n",
    "    else: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastscript import *\n",
    "@call_parse\n",
    "def main(n_epochs:Param(help=\"n_epochs list\", nargs='+', type=int)=[10],\n",
    "         max_lr:Param(help=\"max_lr list\", nargs='+', type=float)=[1e-5],\n",
    "         wd:Param(help=\"wd (weight decay) hpyerparameter list\", nargs='+', type=float)=[0.03],\n",
    "         div_factor:Param(help=\"div_factor hpyerparameter list\", nargs='+', type=float)=[25.0],\n",
    "         seed:Param(help=\"seed hpyerparameter list\", nargs='+', type=int)=[1234],\n",
    "         N:Param(help=\"N hpyerparameter list\", nargs='+', type=int)=[3],\n",
    "         magnitude:Param(help=\"magnitude hpyerparameter list\", nargs='+', type=float)=[0.3],\n",
    "         alpha:Param(help=\"alpha hpyerparameter list\", nargs='+', type=float)=[0.5],\n",
    "         aug:Param(help=\"augmentation policy\", choices=[None, 'randaugment', 'augmix'], type=str)=None,\n",
    "         nrows:Param(help=\"n_epochs list\", type=int)=None,\n",
    "         bs:Param(help=\"batch size\", type=int)=128,\n",
    "         trn_end:Param(help=\"n_epochs list\", type=int)=None,\n",
    "         val_end:Param(help=\"n_epochs list\", type=int)=None,\n",
    "         test_end:Param(help=\"n_epochs list\", type=int)=None,\n",
    "         df_fn:Param(help=\"dataframe filename\", type=str)='bi_sample_anon.csv',         \n",
    "         df_dir:Param(help=\"dataframe dir\", type=str)='./data/custom',\n",
    "         df_results:Param(help=\"results dataframe filename\", type=str)='results_script.csv',\n",
    "         config_fn:Param(help=\"json column configuration filename\", type=str)='config2.json',    \n",
    "         config_id:Param(help=\"column configuration id\", type=str)='anon2hc_4c_2d_y',\n",
    "         arch:Param(help=\"model architecture\", choices=['inception', 'resnet'], type=str)='inception',\n",
    "         upper:Param(\"Convert to uppercase?\", bool_arg)=False):\n",
    "#     print(msg.upper() if upper else msg)\n",
    "    \n",
    "   \n",
    "    \n",
    "    train_params['aug']=aug\n",
    "    \n",
    "    df_path=Path(df_dir)/df_fn\n",
    "    print(df_path)\n",
    "    \n",
    "    col_config=read_config(config_id, config_fn)\n",
    "    data_params = build_data_params(df_path, col_config=col_config, nrows=nrows, trn_end=trn_end, val_end=val_end,\n",
    "                                   test_end=test_end, bs=bs)\n",
    "#     print(data_params)\n",
    "\n",
    "    train_params['metrics']=[unweighted_profit, unweighted_profit_05]\n",
    "    train_params['arch']=_get_arch(arch, col_config['cols_d'] is not None)\n",
    "    ts_experiment = TSExperiments()\n",
    "    ts_experiment.setup_data(data_params)\n",
    "    ts_experiment.setup_training(train_params)\n",
    "                                 \n",
    "    hypers = {'n_epochs': n_epochs, 'max_lr':max_lr, 'wd':wd, 'seed': seed, 'div_factor':div_factor,\n",
    "             'N':N, 'magnitude':magnitude}\n",
    "    print(hypers)\n",
    "    \n",
    "    ts_experiment.run_grid_search(hypers, df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m torchtools.experiments_2 --n_epochs 20 --trn_end 16000 --val_end 18500 --test_end 21000 --aug 'augmix' --bs 256 --max_lr 1e-5 --magnitude 0.4 --config_id 'anon10hc_6c_y' --arch 'inception' --df_result='results10.csv' --magnitude 0.5 --wd 0.01 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_data_params??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_config['cols_d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.run_experiment(df_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results=pd.read_csv(Path('./experiments/results')/df_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 99\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc, xd, y = ts_experiment.learn.dls[1].one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_params['splits'] =  L(L(range(8000)), L(range(8000,9000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params['aug']='randaugment'\n",
    "train_params['verbose']=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments = TSExperiments(train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.setup_data(df_main, data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers = {'n_epochs': [1], 'max_lr':[1e-5]}\n",
    "\n",
    "df_fn_test = 'results3.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSStandardize??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.run_grid_search(hypers, df_results_fn=df_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.learn.dls.after_batch.tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc,xd,yb = ts_experiments.learn.dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.run_grid_search(hypers, df_results_fn=df_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbs = ts_experiments.dls.after_batch[0](xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ts_experiments.dls.after_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipeline??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compose_tfms(xb, p, split_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.dls.after_batch[1](xbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.learn.dls.after_batch(xb[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.learn.dls.after_batch(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.dls.after_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.dls.after_batch[1].tfms[7].verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.dls.after_batch[1].tfms[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_noise_augs??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.dls.train.rng.sample(range(100),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.dls.train.shuffle_fn(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.run_grid_search(hypers, df_results_fn=df_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.dls.train.rng.sample(range(100),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.dls.shuffle_fn(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results=pd.read_csv(Path(ts_experiments.results_path)/df_fn_test)\n",
    "pd.options.display.max_columns=99\n",
    "df_results_fn = 'results_script.csv'\n",
    "df_results=pd.read_csv(Path('./experiments/results')/df_results_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.learn.dls[2].dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.learn.get_preds(2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalid = np.round(ts_experiments.learn.get_preds(1)[0].numpy(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fn=Path('~/google-drive/experiments/results/results_colab.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results=pd.read_csv(results_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=99\n",
    "df_results.query('n_epochs==20 and max_lr==0.0001 and bs==1024')[['ds_id', 'unweighted_profit_0_value', 'unweighted_profit_05_1_value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.sort_values(by='unweighted_profit_0_value', ascending=False)['unweighted_profit_0_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.query('name.str.contains(\"lu\")', engine='python').head())\n",
    "df_results.query('ds_id.str.contains(\"2y\")', engine='python').sort_values(\n",
    "    by='unweighted_profit_0_value', ascending=False)[[\n",
    "    'unweighted_profit_0_value', 'unweighted_profit_05_1_value']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.query('ds_id==\"bi_sample_anon_anon_10sl_4c_2d_2y_159999_184999_209999\"')[[\n",
    "    'ds_id', 'unweighted_profit_0_value', 'unweighted_profit_05_1_value', 'bs', 'wd', 'max_lr']].so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.iloc[92]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('ttools': conda)",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
