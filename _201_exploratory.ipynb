{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp experiments_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "> refactor modelling, experiment functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.0'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torchtools.core import *\n",
    "from torchtools.data import *\n",
    "from torchtools.models import *\n",
    "from torchtools.datasets import *\n",
    "from torchtools.augmentations import *\n",
    "#from torchtools.datablock import *\n",
    "from torchtools.dataloader import *\n",
    "from torchtools.experiments import *\n",
    "from torchtools.configs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fastai.basics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## most recent datasets are bi_sample_pruned_anon_222.csv and ts_experiments_anon_ts_exp_2020818.csv. make sure\n",
    "## that config and dataset correspond to each other (different naming conventions)\n",
    "/#export\n",
    "# df_path = Path('./data/custom/bi_sample_anon.csv')\n",
    "# df_path = Path('./data/custom/bi_sample_pruned_anon.csv')\n",
    "# df_path = Path('~/coding/python/betting/experiments/datasets/bi_sample_pruned_anon.csv').expanduser()\n",
    "df_path = Path('~/coding/python/betting/experiments/datasets/bi_sample_pruned_anon_222.csv').expanduser()\n",
    "df_path = Path('~/coding/python/betlib/data/processed/ts_experiments_anon_ts_exp_2020818.csv').expanduser()\n",
    "df_path = Path('~/coding/python/scrape/bets_processed.csv').expanduser()\n",
    "df_path = Path('~/coding/python/scrape/bets_anon_new.csv').expanduser()\n",
    "\n",
    "# df_path = Path('~/coding/python/betting/experiments/datasets/bi_50_218_anon.csv').expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_CONFIG = 'config2.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anon_10sl_4c_2d_1yml',\n",
       " 'anon_10sl_6c_1yml',\n",
       " 'anon_10sl_6c_1yhc',\n",
       " 'anon_10sl_6c_2y',\n",
       " 'anon_10sl_4c_2d_1yhc',\n",
       " 'anon_10sl_4c_2d_2y',\n",
       " 'anon_20sl_4c_2d_2y',\n",
       " 'anon_30sl_4c_2d_2y',\n",
       " 'anon_10sl_4c_2d_4tc_4cat_2y',\n",
       " 'anon_10sl_4c_2d_4tc_4cat_1yhc',\n",
       " 'anon_10sl_4c_1yhc',\n",
       " 'anon_10sl_6c_1yclass',\n",
       " 'anon_10sl_4c_2d_1yclass',\n",
       " 'anon_10sl_4c_2d_4tc_4cat_1yclass',\n",
       " 'tsexp_10sl_12c_1yhc',\n",
       " 'tsexp_10sl_12c_1yclass']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_keys(COL_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_id =  'anon_10sl_6c_1yclass'\n",
    "config_id = 'anon_10sl_4c_2d_1yhc'\n",
    "# config_id =  'tsexp_10sl_12c_1yclass'\n",
    "col_config = read_config(config_id, COL_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cols_c', 'cols_d', 'cols_y', 'id'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cols_c': [['x0_0',\n",
       "   'x0_1',\n",
       "   'x0_2',\n",
       "   'x0_3',\n",
       "   'x0_4',\n",
       "   'x0_5',\n",
       "   'x0_6',\n",
       "   'x0_7',\n",
       "   'x0_8',\n",
       "   'x0_9'],\n",
       "  ['x1_0',\n",
       "   'x1_1',\n",
       "   'x1_2',\n",
       "   'x1_3',\n",
       "   'x1_4',\n",
       "   'x1_5',\n",
       "   'x1_6',\n",
       "   'x1_7',\n",
       "   'x1_8',\n",
       "   'x1_9'],\n",
       "  ['x3_0',\n",
       "   'x3_1',\n",
       "   'x3_2',\n",
       "   'x3_3',\n",
       "   'x3_4',\n",
       "   'x3_5',\n",
       "   'x3_6',\n",
       "   'x3_7',\n",
       "   'x3_8',\n",
       "   'x3_9'],\n",
       "  ['x4_0',\n",
       "   'x4_1',\n",
       "   'x4_2',\n",
       "   'x4_3',\n",
       "   'x4_4',\n",
       "   'x4_5',\n",
       "   'x4_6',\n",
       "   'x4_7',\n",
       "   'x4_8',\n",
       "   'x4_9']],\n",
       " 'cols_d': [['x2_0',\n",
       "   'x2_1',\n",
       "   'x2_2',\n",
       "   'x2_3',\n",
       "   'x2_4',\n",
       "   'x2_5',\n",
       "   'x2_6',\n",
       "   'x2_7',\n",
       "   'x2_8',\n",
       "   'x2_9'],\n",
       "  ['x5_0',\n",
       "   'x5_1',\n",
       "   'x5_2',\n",
       "   'x5_3',\n",
       "   'x5_4',\n",
       "   'x5_5',\n",
       "   'x5_6',\n",
       "   'x5_7',\n",
       "   'x5_8',\n",
       "   'x5_9']],\n",
       " 'cols_y': 'y1',\n",
       " 'id': 'anon_10sl_4c_2d_1yhc'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cols_c', 'cols_d', 'cols_y', 'id'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_config.get('hcodds_col')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(col_config.get, ['hcodds_col', 'prune']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _anon_config(n_channels, n_seq, prefix='c'):\n",
    "    cols=[]\n",
    "    for i in range(n_channels):\n",
    "        cols.append([f'{prefix}{i}_{j}' for j in range(n_seq)])\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_config.get('prune')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_config.get('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = Path('~/coding/python/betting/experiments/datasets/bi_sample_pruned_anon_222.csv').expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params = build_data_params(df_path, col_config=col_config, classification=False, trn_end=160000,val_end=185000, \n",
    "                                test_end=210000, ss_dis=True, bs=256)\n",
    "# data_params = build_data_params(df_path, col_config=col_config, classification=True, trn_end=16000,val_end=18500, \n",
    "#                                 test_end=21000, ss_dis=True, bs=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_exp = TSExperiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_exp.setup_data(data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_params['loss_fn_name'] = \"crossentropy\"\n",
    "# train_params['loss_fn_name'] = \"rww\"\n",
    "# train_params['metrics'] = [accuracy]\n",
    "train_params\n",
    "train_params['aug'] = 'randaugment'\n",
    "# train_params['aug'] = ['None']\n",
    "train_params['max_lr'] = 3e-3\n",
    "train_params['weight'] = tensor([1., 1., 1., 1., 1.]) ## crossentropy weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_loss_fn??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params['loss_fn_name']='leaky_loss'\n",
    "train_params['metrics'] = [unweighted_profit, unweighted_profit_05]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_exp.setup_training(train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers={'max_lr':[3e-3], 'n_epochs':[1], 'N':[1], 'magnitude':[0.1],  'wd':[0.1], \n",
    "        'weight':[tensor([1., 10., 1., 10., 1.]) ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_exp.classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_fn='results_exploration_class.csv'\n",
    "df_results_fn='results_exploration.csv' ##regression\n",
    "ts_exp.run_grid_search(hypers, df_results_fn='results_exploration_class.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ts_exp.learn.loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_exp.learn.fit(3, lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_exp.learn.fit(3, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, y_true = ts_exp.learn.get_preds(split_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(preds, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = F.softmax(preds, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = torch.where(preds[:,1]>0.45)[0]\n",
    "len(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ts_exp.df_base.iloc[ts_exp.splits[0]]['y1'].mean())\n",
    "print(ts_exp.df_base.iloc[ts_exp.splits[1]]['y1'].mean())\n",
    "print(ts_exp.df_base.iloc[ts_exp.splits[2]]['y1'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_exp.df_base.iloc[ts_exp.splits[split_idx]].iloc[idxs][['y0', 'y1']].agg(['mean', 'sum', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_exp.df_base.iloc[ts_exp.splits[split_idx]].iloc[complement_idxs(idxs)][\n",
    "    ['y0', 'y1']].agg(['mean', 'sum', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complement_idxs(idxs):  \n",
    "    def _c(idx):\n",
    "        return idx+1 if idx%2==0 else idx-1\n",
    "    return tensor([_c(idx) for idx in idxs.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_exp.df_base.iloc[160000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CrossEntropyLossFlat(weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(df_path, nrows=25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_cols_cont=[['tc0', 'tc1', 'tc2', 'tc3']]\n",
    "tab_cols_cat=[['tcat0', 'tcat1', 'tcat2', 'tcat3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[tab_cols_cont[0]].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats=cats_from_df(df, tab_cols_cat[0], 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = items_from_df(df, col_config['cols_c'], col_config['cols_y'], 10000, tab_cols_c=tab_cols_cont[0],\n",
    "                     cols_d=col_config['cols_d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items_from_df(df, col_config['cols_c'], col_config['cols_y'], 10000, tab_cols_c=tab_cols_cont[0],\n",
    "                     cols_d=col_config['cols_d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ars = items_to_arrays(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ars[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits=TSSplitter()(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_dls(df, col_config['cols_c'], col_config['cols_y'], splits, ds_type=TSDatasets4, cols_d=col_config['cols_d'],\n",
    "              cols_cont=tab_cols_cont[0], cols_cat=tab_cols_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.one_batch()[2][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def pytorch_count_params(model):\n",
    "  \"count number trainable parameters in a pytorch model\"\n",
    "  total_params = sum(reduce( lambda a, b: a*b, x.size()) for x in model.parameters())\n",
    "  return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dloaders=TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc,xd,xtab_cont, xtab_cat, yb = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc.shape, xd.shape, xtab_cont.shape, xtab_cat.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_dls(df, col_config['cols_c'], col_config['cols_y'], splits, ds_type=TSDatasets4, cols_d=col_config['cols_d'],\n",
    "              cols_cont=tab_cols_cont[0], cols_cat=tab_cols_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.one_batch()[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _get_model(dls, arch='inception'):\n",
    "#     if hasattr(dls, 'cols_cat'):\n",
    "#         emb_szs= [_one_emb_sz(dls.voc, c) for c in dls.cols_cat]\n",
    "#         return InceptionTimeD_Mixed(dls.n_channels, dls.n_targets, len(dls.cols_cont), emb_szs=emb_szs)\n",
    "#     else:\n",
    "#         if dls.dataset.has_xtype[1]: ##discrete channels\n",
    "#             return InceptionTimeD(dls.n_channels, dls.n_targets)\n",
    "#         else:\n",
    "#             return InceptionTimeSgm(dls.n_channels, dls.n_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_dls(df, col_config['cols_c'], col_config['cols_y'], splits, ds_type=TSDatasets4, cols_d=col_config['cols_d'],\n",
    "              cols_cont=tab_cols_cont[0], cols_cat=tab_cols_cat[0])\n",
    "# dls = get_dls(df, col_config['cols_c'], col_config['cols_y'], splits, ds_type=TSDatasets4, \n",
    "#               cols_d=col_config['cols_d'])\n",
    "# dls = get_dls(df, col_config['cols_c'], col_config['cols_y'], splits, ds_type=TSDatasets4, \n",
    "#               cols_d=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment = TSExperiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params = build_data_params(df_path, col_config=col_config, nrows=None, bs=256, ss_dis=True,\n",
    "                               trn_end=160000, val_end=185000, test_end=210000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params.__getitem__('dsds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_config.get('cols_cont')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params['cols_cont']=tab_cols_cont[0]\n",
    "data_params['cols_cat']=tab_cols_cat[0]\n",
    "data_params['bs']=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params['cols_cont']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params['cols_cat']=None\n",
    "ts_experiment.setup_data(data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = ts_experiment.dls.one_batch()\n",
    "\n",
    "# list(map(lambda x: x.shape, [a,b,c,d,e]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn=get_loss_fn('leaky_loss', alpha=0.5)\n",
    "# learn = Learner(ts_experiment.dls, m, loss_func=loss_fn, metrics=None, model_dir=ts_experiment.model_path,\n",
    "#                        wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.setup_training(train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.mean(0), c.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.dls.n_channels_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def emb_sz_rule(n_cat):\n",
    "    \"Rule of thumb to pick embedding size corresponding to `n_cat`\"\n",
    "    return min(600, round(1.6 * n_cat**0.56))\n",
    "\n",
    "# Cell\n",
    "def _one_emb_sz(classes, n, sz_dict=None):\n",
    "    \"Pick an embedding size for `n` depending on `classes` if not given in `sz_dict`.\"\n",
    "    sz_dict = ifnone(sz_dict, {})\n",
    "    n_cat = len(classes[n])\n",
    "    sz = sz_dict.get(n, int(emb_sz_rule(n_cat)))  # rule of thumb\n",
    "    return n_cat,sz\n",
    "\n",
    "# Cell\n",
    "def get_emb_sz(to, sz_dict=None):\n",
    "    \"Get default embedding size from `TabularPreprocessor` `proc` or the ones in `sz_dict`\"\n",
    "    return [_one_emb_sz(to.classes, n, sz_dict) for n in to.cat_names]\n",
    "\n",
    "def _get_model(dls, arch='inception'):\n",
    "    if dls.cols_cat is not None or dls.cols_cont is not None:\n",
    "        emb_szs= [_one_emb_sz(dls.voc, c) for c in listify(dls.cols_cat)] \n",
    "        return InceptionTimeD_Mixed(dls.n_channels_c, dls.n_channels_d, dls.n_targets, \n",
    "                                    len(dls.cols_cont), emb_szs=emb_szs)\n",
    "    else:\n",
    "        if dls.dataset.has_xtype[1]: ##discrete channels\n",
    "            return InceptionTimeD(dls.n_channels, dls.n_targets)\n",
    "        else:\n",
    "            return InceptionTimeSgm(dls.n_channels, dls.n_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = _get_model(ts_experiment.dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.tab_mod.cuda()(None, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers={'n_epochs':[20]}\n",
    "df_results_fn = 'results_exploration.csv'\n",
    "ts_experiment.run_grid_search(hypers, df_results_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.run_training(n_epochs=1, loss_fn_name='leaky_loss', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params['splits']=TSSplitter()(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dls(df, data_params['cols_c'], data_params['cols_y'], data_params['splits'], ds_type=TSDatasets4,\n",
    "       cols_cont=data_params['cols_cont'], cols_cat=data_params['cols_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params['bs']=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.setup_data(data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worklflow with Discrete Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_CONFIG = 'config2.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anon_10sl_4c_2d_1yml',\n",
       " 'anon_10sl_6c_1yml',\n",
       " 'anon_10sl_6c_1yhc',\n",
       " 'anon_10sl_6c_2y',\n",
       " 'anon_10sl_4c_2d_1yhc',\n",
       " 'anon_10sl_4c_2d_2y',\n",
       " 'anon_20sl_4c_2d_2y',\n",
       " 'anon_30sl_4c_2d_2y',\n",
       " 'anon_10sl_4c_2d_4tc_4cat_2y',\n",
       " 'anon_10sl_4c_2d_4tc_4cat_1yhc',\n",
       " 'anon_10sl_4c_1yhc',\n",
       " 'anon_10sl_6c_1yclass',\n",
       " 'anon_10sl_4c_2d_1yclass',\n",
       " 'anon_10sl_4c_2d_4tc_4cat_1yclass',\n",
       " 'tsexp_10sl_12c_1yhc',\n",
       " 'tsexp_10sl_12c_1yclass']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_keys(COL_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_id =  'anon_10sl_4c_2d_1yhc'\n",
    "config_id =  'anon_10sl_4c_2d_4tc_4cat_1yhc'\n",
    "config_id =  'anon_10sl_4c_1yhc'\n",
    "config_id =  'anon_10sl_4c_2d_1yhc'\n",
    "col_config = read_config(config_id, COL_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['x0_0',\n",
       "  'x0_1',\n",
       "  'x0_2',\n",
       "  'x0_3',\n",
       "  'x0_4',\n",
       "  'x0_5',\n",
       "  'x0_6',\n",
       "  'x0_7',\n",
       "  'x0_8',\n",
       "  'x0_9'],\n",
       " ['x1_0',\n",
       "  'x1_1',\n",
       "  'x1_2',\n",
       "  'x1_3',\n",
       "  'x1_4',\n",
       "  'x1_5',\n",
       "  'x1_6',\n",
       "  'x1_7',\n",
       "  'x1_8',\n",
       "  'x1_9'],\n",
       " ['x3_0',\n",
       "  'x3_1',\n",
       "  'x3_2',\n",
       "  'x3_3',\n",
       "  'x3_4',\n",
       "  'x3_5',\n",
       "  'x3_6',\n",
       "  'x3_7',\n",
       "  'x3_8',\n",
       "  'x3_9'],\n",
       " ['x4_0',\n",
       "  'x4_1',\n",
       "  'x4_2',\n",
       "  'x4_3',\n",
       "  'x4_4',\n",
       "  'x4_5',\n",
       "  'x4_6',\n",
       "  'x4_7',\n",
       "  'x4_8',\n",
       "  'x4_9']]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_config['cols_c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# def build_data_params(df_path, trn_end=None, val_end=None, test_end=None, splitter_fn=TSSplitter(), \n",
    "#                       col_config=None, col_fn=None, bs=64, nrows=None, ss_dis=True):\n",
    "# #     assert col_config or col_fn, 'need to pass either cont. cols and y cols, or a col_fn'\n",
    "\n",
    "#     assert col_config, 'need to pass columns configuration'\n",
    "    \n",
    "#     if trn_end and val_end:\n",
    "#         splits=L(L(range(trn_end)), L(range(trn_end, val_end)))\n",
    "#         if test_end: splits.append(L(range(val_end, test_end)))\n",
    "#     else:\n",
    "#         splits = splitter_fn\n",
    "    \n",
    "#     cols_c, cols_d, cols_y, cols_config_id, cols_cont, cols_cat = map(\n",
    "#         col_config.__getitem__, ['cols_c', 'cols_d', 'cols_y', 'id', 'cols_cont', 'cols_cat'])\n",
    "\n",
    "# #     dataset_name = f'{df\n",
    "    \n",
    "#     data_params = defaultdict(lambda:None, {'df_path':df_path, 'splits':splits, 'col_config_id':cols_config_id, \n",
    "#                                             'cols_c':cols_c, 'cols_d':cols_d, 'cols_y':cols_y, 'cols_cont':cols_cont,\n",
    "#                                              'cols_cat':cols_cat, 'bs':bs,  'nrows':nrows, 'ss_dis':ss_dis})\n",
    "# #                'ds_full_path':ds_full_path, \n",
    "#                  #'dataset_name':dataset_id, \n",
    "              \n",
    "#     return data_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cols_c', 'cols_d', 'cols_y', 'id'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_config['cols_d']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/johannes/coding/python/scrape/bets_anon_new.csv')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_params = build_data_params(df_path, col_config=col_config, nrows=218000, bs=256, ss_dis=True,\n",
    "#                                trn_end=160000, val_end=185000, test_end=210000)\n",
    "data_params = build_data_params(df_path, col_config=col_config, nrows=250000, bs=256, ss_dis=True,\n",
    "                               trn_end=200000, val_end=225000, test_end=250000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['df_path', 'splits', 'col_config_id', 'cols_c', 'cols_d', 'cols_y', 'cols_cont', 'cols_cat', 'hcodds_col', 'bs', 'prune', 'nrows', 'ss_dis', 'classification'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## no timeseries columns\n",
    "# data_params['cols_c']=None\n",
    "# data_params['cols_d']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params['cols_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['arch', 'n_epochs', 'max_lr', 'wd', 'loss_fn_name', 'alpha', 'metrics', 'N', 'magnitude', 'seed', 'pct_start', 'div_factor', 'aug'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params['metrics']=[unweighted_profit, unweighted_profit_05]\n",
    "train_params['aug']='randaugment'\n",
    "# train_params['metrics']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchtools.dataloader.TSDatasets5'>\n",
      "[<class 'torchtools.data.TSTensor'>, <class 'torchtools.data.TSIntTensor'>, <class 'torchtools.data.TensorFloat'>]\n",
      "fast part\n",
      "3\n",
      "[True, True, False]\n",
      "[<class 'torchtools.data.TSTensor'>, <class 'torchtools.data.TSIntTensor'>, <class 'torchtools.data.TensorFloat'>]\n",
      "fast part\n",
      "[<class 'torchtools.data.TSTensor'>, <class 'torchtools.data.TSIntTensor'>, <class 'torchtools.data.TensorFloat'>]\n",
      "fast part\n",
      "[<class 'torchtools.data.TSTensor'>, <class 'torchtools.data.TSIntTensor'>, <class 'torchtools.data.TensorFloat'>]\n",
      "fast part\n",
      "setups torch.Size([200000, 4, 10]) False\n",
      "setups torch.Size([200000, 2, 10]) True\n"
     ]
    }
   ],
   "source": [
    "ts_experiment = TSExperiments(save_model=False) #can set save model flag here\n",
    "ts_experiment.setup_data(data_params)\n",
    "ts_experiment.setup_training(train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtools.experiments.TSExperiments at 0x7fe4c37f22e0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# class TabNetTT(nn.Module):\n",
    "#     '''\n",
    "#     convenience wrapper for pure TabNetModel models\n",
    "#     '''\n",
    "#     def __init__(self, emb_szs, n_cont, out_sz, **kwargs):\n",
    "#         super().__init__()\n",
    "#         self.tab = TabNetModel(emb_szs, n_cont, out_sz, **kwargs)\n",
    "        \n",
    "#     def forward(self, xt, xcat):\n",
    "#         xcat=xcat.long() if xcat is not None else None\n",
    "#         xt=xt.float() if xt is not None else None\n",
    "#         return self.tab(xcat, xt)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# def emb_sz_rule(n_cat):\n",
    "#     \"Rule of thumb to pick embedding size corresponding to `n_cat`\"\n",
    "#     return min(600, round(1.6 * n_cat**0.56))\n",
    "\n",
    "# # Cell\n",
    "# def _one_emb_sz(classes, n, sz_dict=None):\n",
    "#     \"Pick an embedding size for `n` depending on `classes` if not given in `sz_dict`.\"\n",
    "#     sz_dict = ifnone(sz_dict, {})\n",
    "#     n_cat = len(classes[n])\n",
    "#     sz = sz_dict.get(n, int(emb_sz_rule(n_cat)))  # rule of thumb\n",
    "#     return n_cat,sz\n",
    "\n",
    "# # Cell\n",
    "# def get_emb_sz(to, sz_dict=None):\n",
    "#     \"Get default embedding size from `TabularPreprocessor` `proc` or the ones in `sz_dict`\"\n",
    "#     return [_one_emb_sz(to.classes, n, sz_dict) for n in to.cat_names]\n",
    "\n",
    "# def get_mod(dls, arch='inception'):\n",
    "    \n",
    "#     if dls.n_channels==0:\n",
    "#         assert dls.cols_cat is not None or dls.cols_cont is not None, 'no tabular columns'\n",
    "#         emb_szs= [_one_emb_sz(dls.voc, c) for c in listify(dls.cols_cat)] \n",
    "#         return TabNetTT(emb_szs=emb_szs, n_cont=len(dls.cols_cont), out_sz=dls.n_targets)\n",
    "    \n",
    "#     if dls.cols_cat is not None or dls.cols_cont is not None:\n",
    "#         emb_szs= [_one_emb_sz(dls.voc, c) for c in listify(dls.cols_cat)] \n",
    "#         return InceptionTimeD_Mixed(dls.n_channels_c, dls.n_channels_d, dls.n_targets, \n",
    "#                                     len(dls.cols_cont), emb_szs=emb_szs)\n",
    "#     else:\n",
    "#         if dls.dataset.has_xtype[1]: ##discrete channels\n",
    "#             return InceptionTimeD(dls.n_channels, dls.n_targets)\n",
    "#         else:\n",
    "#             return InceptionTimeSgm(dls.n_channels, dls.n_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from fast_tabnet.core import *\n",
    "m=get_mod(ts_experiment.dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arch': torchtools.models.InceptionTimeD,\n",
       " 'n_epochs': 5,\n",
       " 'max_lr': 1e-05,\n",
       " 'wd': 0.03,\n",
       " 'loss_fn_name': 'leaky_loss',\n",
       " 'alpha': 0.5,\n",
       " 'metrics': [<function torchtools.core.unweighted_profit(preds, y_true, threshold=0)>,\n",
       "  <function torchtools.core.unweighted_profit_05(preds, y_true, threshold=0.5)>],\n",
       " 'N': 3,\n",
       " 'magnitude': 0.4,\n",
       " 'seed': 1234,\n",
       " 'pct_start': 0.3,\n",
       " 'div_factor': 25.0,\n",
       " 'aug': 'randaugment',\n",
       " 'bs': 256,\n",
       " 'ds_id': 'bets_anon_new_anon_10sl_4c_2d_1yhc_200_225_250',\n",
       " 'classification': False,\n",
       " 'prune': None}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(ts_experiment.dls, m, get_loss_fn('leaky_loss', alpha=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers={'max_lr':[3e-5], 'n_epochs':[10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./experiments/results'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_experiment.results_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'arch': <class 'torchtools.models.InceptionTimeD'>, 'n_epochs': 10, 'max_lr': 3e-05, 'wd': 0.03, 'loss_fn_name': 'leaky_loss', 'alpha': 0.5, 'metrics': [<function unweighted_profit at 0x7fe4c80e0040>, <function unweighted_profit_05 at 0x7fe4c80e00d0>], 'N': 3, 'magnitude': 0.4, 'seed': 1234, 'pct_start': 0.3, 'div_factor': 25.0, 'aug': 'randaugment', 'bs': 256, 'ds_id': 'bets_anon_new_anon_10sl_4c_2d_1yhc_200_225_250', 'classification': False, 'prune': None}\n",
      "pct_start: 0.3 div_factor: 25.0\n",
      "[TSStandardize:\n",
      "encodes: (NumpyTensor,object) -> encodes\n",
      "(TSTensor,object) -> encodes\n",
      "(TSIntTensor,object) -> encodes\n",
      "decodes: , TSStandardize:\n",
      "encodes: (NumpyTensor,object) -> encodes\n",
      "(TSTensor,object) -> encodes\n",
      "(TSIntTensor,object) -> encodes\n",
      "decodes: ]\n",
      "Pipeline: TSStandardize -> TSStandardize Pipeline: TSStandardize -> TSStandardize\n",
      "RandAugment:\n",
      "encodes: (TSTensor,object) -> encodes\n",
      "(TSIntTensor,object) -> encodes\n",
      "decodes: \n",
      "False\n",
      "functools.partial(<function leaky_loss at 0x7fe4cf993040>, alpha=0.5)\n",
      "Pipeline: RandAugment -> TSStandardize -> TSStandardize\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>unweighted_profit</th>\n",
       "      <th>unweighted_profit_05</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.183591</td>\n",
       "      <td>-0.305290</td>\n",
       "      <td>0.021266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>01:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.402622</td>\n",
       "      <td>-0.539826</td>\n",
       "      <td>-0.017506</td>\n",
       "      <td>-0.007654</td>\n",
       "      <td>01:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.598142</td>\n",
       "      <td>-0.624126</td>\n",
       "      <td>-0.147870</td>\n",
       "      <td>-0.006039</td>\n",
       "      <td>01:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.511859</td>\n",
       "      <td>-0.806783</td>\n",
       "      <td>-0.062018</td>\n",
       "      <td>-0.010351</td>\n",
       "      <td>01:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.921316</td>\n",
       "      <td>-0.813887</td>\n",
       "      <td>-0.035212</td>\n",
       "      <td>-0.147498</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>-0.912889</td>\n",
       "      <td>-0.787817</td>\n",
       "      <td>-0.123537</td>\n",
       "      <td>-0.045763</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>-0.923113</td>\n",
       "      <td>-0.822659</td>\n",
       "      <td>0.006807</td>\n",
       "      <td>-0.159039</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>-0.623651</td>\n",
       "      <td>-0.898590</td>\n",
       "      <td>-0.148984</td>\n",
       "      <td>0.023447</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>-0.691412</td>\n",
       "      <td>-0.858398</td>\n",
       "      <td>-0.101501</td>\n",
       "      <td>-0.106825</td>\n",
       "      <td>01:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>-0.890505</td>\n",
       "      <td>-0.906189</td>\n",
       "      <td>-0.093685</td>\n",
       "      <td>0.040680</td>\n",
       "      <td>01:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not new\n"
     ]
    }
   ],
   "source": [
    "df_results_fn = 'results_exploration.csv'\n",
    "# ts_experiment.run_experiment(df_fn=df_results_fn)\n",
    "ts_experiment.run_grid_search(hypers, df_results_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TSTensor([2,3])\n",
    "t2 = TSIntTensor([3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers={'max_lr':[3e-5], 'n_epochs':[10,15]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _dict_product(params):\n",
    "            values = list(itertools.product(*params.values()))\n",
    "            return [dict(zip(params.keys(), values[i])) for i in range(len(values))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_lr': 3e-05, 'n_epochs': 10}\n",
      "{'max_lr': 3e-05, 'n_epochs': 15}\n"
     ]
    }
   ],
   "source": [
    "configs = _dict_product(hypers)\n",
    "for config in configs: print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds, ytrue=ts_experiment.learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorFloat(-2.1184)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unweighted_profit(preds, ytrue, -1.99999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.917810878518"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_experiment.df_base['y1'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 3, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([t,t2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob = ts_experiment.dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = learn.dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mod??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params['aug'] = 'randaugment'\n",
    "train_params['verbose']=False\n",
    "train_params['n_epochs']=20\n",
    "train_params['max_lr']=1e-5\n",
    "train_params['wd']=0.03\n",
    "train_params['arch'] = InceptionTimeD\n",
    "train_params['augmixss']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers={'n_epochs':[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls=ts_experiment.dls\n",
    "dls.n_channels_c, dls.n_channels_d, dls.n_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.cols_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_fn = 'results_exploration.csv'\n",
    "ts_experiment.run_grid_search(hypers, df_results_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_fn = 'results_exploration.csv'\n",
    "ts_experiment.run_grid_search(hypers, df_results_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, y_true = ts_experiment.learn.get_preds(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unweighted_profit(preds[:,1], y_true[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unweighted_profit(preds[:,0], y_true[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.rand((5,2))\n",
    "yt = torch.rand((5,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p*yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8659*0.3560"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_fn = 'results_exploration.csv'\n",
    "ts_experiment.run_grid_search(hypers, df_results_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.dls.n_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb=ts_experiment.dls.one_batch()\n",
    "ts_experiment.learn.model(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.learn.loss_func(ts_experiment.learn.model(xb),yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_loss_2d(ts_experiment.learn.model(xb),yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = ts_experiment.learn.model(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_profit(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_profit(preds[:,0], yb[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_profit(preds[:,1], yb[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(preds[:,1].detach().cpu().numpy(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigmoid??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_profit??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_loss(preds[:,0], yb[:,0]) + leaky_loss(preds[:,1], yb[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_loss(preds, yb) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaky_loss_2d(preds, yb, alpha=0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_fn = 'results_exploration.csv'\n",
    "ts_experiment.run_grid_search(hypers, df_results_fn=df_results_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandAugment??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_fn = 'results_exploration.csv'\n",
    "ts_experiment.run_experiment(df_fn=df_results_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.dls.after_batch[1].order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.dls.after_batch[0].order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipeline??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compose_tfms??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_fn = 'results_exploration.csv'\n",
    "ts_experiment.run_experiment(df_fn=df_results_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.dls.after_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc,xd,y = ts_experiment.dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.dls.ptls[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.dls.after_batch[0].mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.dls.after_batch[0].mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc.mean((0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xd.mean((0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params['bs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.dls.bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.dls.one_batch()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params['splits'] = L(L(range(8000)), L(range(8000,9000)), L(range(9000,10000)))\n",
    "# data_params['splits'] = L(L(range(120000)), L(range(120000,160000)), L(range(160000,200000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params['splits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers = {'n_epochs': [5], 'max_lr':[1e-5]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR=Path('./')\n",
    "BASE_DIR=Path('~/google-drive').expanduser() # for colab\n",
    "\n",
    "RESULTS_DIR=BASE_DIR/'experiments/results'\n",
    "PREDS_DIR=BASE_DIR/'experiments/preds'\n",
    "# RESULT_FN='results_script.csv'\n",
    "RESULTS_FN='results_colab.csv'\n",
    "\n",
    "df_path = Path('~/coding/python/betting/experiments/datasets/bi_sample_pruned_anon.csv').expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results=pd.read_csv(BASE_DIR/RESULTS_DIR/RESULTS_FN)\n",
    "df_base = pd.read_csv(df_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.groupby('ds_id')[['val_loss', 'unweighted_profit_0_value']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _id_from_splits(splits):\n",
    "    return '_'.join([str(l[-1]+1//1000) for l in splits])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_id_from_splits(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(splits[0][-1]+1)//1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=99\n",
    "df_results.query('ds_id.str.contains(\"1yhc\")').sort_values(by='unweighted_profit_0_value', ascending=False).head(29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _reload_preds(df, idx, test=False, preds_path=PREDS_DIR):\n",
    "    fn = Path(preds_path)/df.iloc[idx]['val_preds'] if not test else Path(preds_path)/df.iloc[idx]['test_preds']\n",
    "    return torch.load(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _average_preds(df, idxs, test=False, normalize=False):\n",
    "    preds = np.array([_reload_preds(df, idx, test).numpy() for idx in idxs])\n",
    "    if normalize:\n",
    "        mean,std = preds.mean(), preds.std()\n",
    "        preds = (preds-mean)/std\n",
    "    return preds.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs=np.arange(-15, -10)\n",
    "metric_cols = ['unweighted_profit_0_value', 'unweighted_profit_05_1_value']\n",
    "loss_cols = ['val_loss', 'trn_loss']\n",
    "df_results.iloc[idxs][metric_cols+loss_cols].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.iloc[idxs][metric_cols+loss_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds=_average_preds(df_results, idxs, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true=ts_experiment.df_base.iloc[160000:185000]['y1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_profit(tensor(avg_preds), tensor(y_true)), unweighted_profit_05(tensor(avg_preds), tensor(y_true)), get_loss_fn('leaky_loss', alpha=0.5)(tensor(avg_preds), tensor(y_true))\n",
    "# unweighted_profit(tensor(avg_preds), tensor(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_profit(tensor(avg_preds), tensor(y_true), threshold=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(avg_preds>1.5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_avg_bet_df(df_base, idxs, df_, model_idxs, threshold=0., test=False, quantile=None):\n",
    "    trn_idxs, val_idxs, test_idxs = idxs\n",
    "    print(val_idxs)\n",
    "    avg_preds = _average_preds(df_, model_idxs, test=test, normalize=False)\n",
    "    if quantile is not None: threshold=np.quantile(avg_preds, quantile)\n",
    "    print(threshold, avg_preds.shape)\n",
    "    bet_idxs = np.where(avg_preds>threshold)[0]\n",
    "    df_res = df_base.iloc[test_idxs] if test else df_base.iloc[val_idxs]\n",
    "    return df_res.reset_index(drop=True).iloc[bet_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_results_view(df, config='default', max_rows=20, sorted=True):\n",
    "    augment_params = ['N', 'magnitude']\n",
    "    fitting_params = ['n_epochs', 'max_lr', 'wd', 'pct_start', 'div_factor']\n",
    "#     metric_cols = [c for c in df.columns if 'metric_' in c and '_value' in c]\n",
    "    metric_cols = ['unweighted_profit_0_value', 'unweighted_profit_05_1_value']\n",
    "    loss_cols = ['val_loss', 'trn_loss']\n",
    "    fn_cols=['val_preds', 'test_preds']#, 'model_fn']\n",
    "    experiment_cols = ['arch', 'bs', 'ds_id']\n",
    "    var_cols = ['Timestamp']\n",
    "#     return df[fitting_params+augment_params+metric_cols+loss_cols+experiment_cols+fn_cols+var_cols].sort_values(\n",
    "#         by=loss_cols[0], ascending=True).head(max_rows)\n",
    "    return df[fitting_params+augment_params+metric_cols+loss_cols+experiment_cols+fn_cols+var_cols].sort_values(\n",
    "        by=metric_cols[0], ascending=False).head(max_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results_view(df_results.query('ds_id.str.contains(\"1yhc\")').sort_values(by='unweighted_profit_0_value', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=ts_experiment.df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bets=get_avg_bet_df(df, ts_experiment.splits, df_results, [214, 228, 230], quantile=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bets[['y0', 'y1']].agg((['mean', 'sum', 'count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results_view(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.ds_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.iloc[200][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds = _average_preds(df_results, [176,177,178,179], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds = _average_preds(df_results, [173,174], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(avg_preds, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[160000:185000].iloc[np.where((avg_preds>1.66)[:,0])][['y0', 'y1']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val=df.iloc[160000:185000].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_config['cols_c'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bet_idxs=np.where(avg_preds[:,0]>0.3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where((avg_preds.squeeze()>0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.nanmean(df_val[col_config['cols_c'][0]].values, axis=0))\n",
    "plt.plot(np.nanmean(df_val[col_config['cols_c'][1]].values, axis=0))\n",
    "plt.plot(np.nanmean(df_val[col_config['cols_c'][2]].values, axis=0))\n",
    "plt.plot(np.nanmean(df_val[col_config['cols_c'][3]].values, axis=0))\n",
    "# plt.plot(np.nanmean(df_val.iloc[bet_idxs][col_config['cols_c'][0]].values, axis=0), linestyle='dashed')\n",
    "# plt.plot(np.nanmean(df_val.iloc[bet_idxs][col_config['cols_c'][1]].values, axis=0), linestyle='dashed')\n",
    "# plt.plot(np.nanmean(df_val.iloc[bet_idxs][col_config['cols_c'][2]].values, axis=0), linestyle='dotted')\n",
    "# plt.plot(np.nanmean(df_val.iloc[bet_idxs][col_config['cols_c'][3]].values, axis=0), linestyle='dotted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[col_config['cols_c'][0]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds_fn = df_results.iloc[179]['val_preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_preds = torch.load(Path('./experiments/preds/')/val_preds_fn)\n",
    "val_preds = torch.load(Path('~/google-drive/experiments/preds/').expanduser()/val_preds_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y = ts_experiment.df_base.iloc[160000:185000][['y0', 'y1']].values\n",
    "val_y = ts_experiment.df_base.iloc[160000:185000]['y1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.linspace(0,1,11):\n",
    "    print(i, unweighted_profit(val_preds, tensor(val_y), i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(val_preds, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(val_preds>0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(val_preds>0).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.linspace(0,0.99,10):\n",
    "    print(i,unweighted_profit(val_preds, tensor(val_y), i), weighted_profit(val_preds, tensor(val_y), i) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(val_preds.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.linspace(0,0.99,10):\n",
    "    print(i, unweighted_profit(val_preds[:,0], tensor(val_y)[:,0], i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.linspace(0,0.99,10):\n",
    "    print(i, unweighted_profit(val_preds[:,1], tensor(val_y)[:,1], i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nf2'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(val_preds.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((val_preds[:,0]>0.5)*(val_preds[:,1]>0.5)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs=((val_preds[:,0]>-2)*(val_preds[:,1]>0.22)*(preds_old[:,0]>0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs=((val_preds[:,0]>-2)*(val_preds[:,0]>0)*(preds_old[:,0]>0.2))\n",
    "idxs.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(val_preds.numpy(), 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(preds_old.numpy(), 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(avg_preds_weighted, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs= avg_preds_weighted>0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ts_experiment.df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[160000:185000].iloc[np.where(idxs.squeeze())][['y0', 'y1']].agg(['count', 'mean', 'sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_profit(val_preds[:,1], tensor(val_y)[:,1], 0.22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(preds_old.squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds = torch.stack([preds_old[:,0], val_preds[:,1]], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds_weighted = 0.5*preds_old[:,0]+0.5*val_preds[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(val_preds[:,1].numpy(), 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "15/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_dir_old = Path('~/coding/python/betting/experiments/dl/nn_exps/preds/val_preds_4816317650882923079.pt').expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_old = torch.load(preds_dir_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ts_experiment.df_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[np.where(preds_old.squeeze()>0.39)][['y0', 'y1']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_profit_05(preds_old, tensor(df.iloc[160000:185000]['y0'].values), 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(preds_old>0).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[160000:185000].iloc[np.where(preds_old.squeeze()>0.4)][['y0', 'y1']].agg(['count', 'mean', 'sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[160000:185000].iloc[np.where(preds_old.squeeze()>0.4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(preds_old.squeeze()>0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=np.logical_and(val_preds[:,0]>0.5, val_preds[:,1]>0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(val_y*mask.numpy()[:, None]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_profit(val_preds.squeeze(), tensor(val_y)), unweighted_profit(val_preds.squeeze(), tensor(val_y), 0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(val_preds>0.4).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unweighted_profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(val_preds.cpu().squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fn_test = 'results4.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.run_grid_search(hypers, df_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_arch(arch:str, with_discrete=False):\n",
    "    if arch.lower()=='inception': return InceptionTimeSgm if not with_discrete else InceptionTimeD\n",
    "    elif arch.lower()=='resnet': return 'ResNet not implemented'\n",
    "    else: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastscript import *\n",
    "@call_parse\n",
    "def main(n_epochs:Param(help=\"n_epochs list\", nargs='+', type=int)=[10],\n",
    "         max_lr:Param(help=\"max_lr list\", nargs='+', type=float)=[1e-5],\n",
    "         wd:Param(help=\"wd (weight decay) hpyerparameter list\", nargs='+', type=float)=[0.03],\n",
    "         div_factor:Param(help=\"div_factor hpyerparameter list\", nargs='+', type=float)=[25.0],\n",
    "         seed:Param(help=\"seed hpyerparameter list\", nargs='+', type=int)=[1234],\n",
    "         N:Param(help=\"N hpyerparameter list\", nargs='+', type=int)=[3],\n",
    "         magnitude:Param(help=\"magnitude hpyerparameter list\", nargs='+', type=float)=[0.3],\n",
    "         alpha:Param(help=\"alpha hpyerparameter list\", nargs='+', type=float)=[0.5],\n",
    "         aug:Param(help=\"augmentation policy\", choices=[None, 'randaugment', 'augmix'], type=str)=None,\n",
    "         nrows:Param(help=\"n_epochs list\", type=int)=None,\n",
    "         bs:Param(help=\"batch size\", type=int)=128,\n",
    "         trn_end:Param(help=\"n_epochs list\", type=int)=None,\n",
    "         val_end:Param(help=\"n_epochs list\", type=int)=None,\n",
    "         test_end:Param(help=\"n_epochs list\", type=int)=None,\n",
    "         df_fn:Param(help=\"dataframe filename\", type=str)='bi_sample_anon.csv',         \n",
    "         df_dir:Param(help=\"dataframe dir\", type=str)='./data/custom',\n",
    "         df_results:Param(help=\"results dataframe filename\", type=str)='results_script.csv',\n",
    "         config_fn:Param(help=\"json column configuration filename\", type=str)='config2.json',    \n",
    "         config_id:Param(help=\"column configuration id\", type=str)='anon2hc_4c_2d_y',\n",
    "         arch:Param(help=\"model architecture\", choices=['inception', 'resnet'], type=str)='inception',\n",
    "         upper:Param(\"Convert to uppercase?\", bool_arg)=False):\n",
    "#     print(msg.upper() if upper else msg)\n",
    "    \n",
    "   \n",
    "    \n",
    "    train_params['aug']=aug\n",
    "    \n",
    "    df_path=Path(df_dir)/df_fn\n",
    "    print(df_path)\n",
    "    \n",
    "    col_config=read_config(config_id, config_fn)\n",
    "    data_params = build_data_params(df_path, col_config=col_config, nrows=nrows, trn_end=trn_end, val_end=val_end,\n",
    "                                   test_end=test_end, bs=bs)\n",
    "#     print(data_params)\n",
    "\n",
    "    train_params['metrics']=[unweighted_profit, unweighted_profit_05]\n",
    "    train_params['arch']=_get_arch(arch, col_config['cols_d'] is not None)\n",
    "    ts_experiment = TSExperiments()\n",
    "    ts_experiment.setup_data(data_params)\n",
    "    ts_experiment.setup_training(train_params)\n",
    "                                 \n",
    "    hypers = {'n_epochs': n_epochs, 'max_lr':max_lr, 'wd':wd, 'seed': seed, 'div_factor':div_factor,\n",
    "             'N':N, 'magnitude':magnitude}\n",
    "    print(hypers)\n",
    "    \n",
    "    ts_experiment.run_grid_search(hypers, df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m torchtools.experiments_2 --n_epochs 20 --trn_end 16000 --val_end 18500 --test_end 21000 --aug 'augmix' --bs 256 --max_lr 1e-5 --magnitude 0.4 --config_id 'anon10hc_6c_y' --arch 'inception' --df_result='results10.csv' --magnitude 0.5 --wd 0.01 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_data_params??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_config['cols_d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.run_experiment(df_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiment.run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results=pd.read_csv(Path('./experiments/results')/df_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 99\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc, xd, y = ts_experiment.learn.dls[1].one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_params['splits'] =  L(L(range(8000)), L(range(8000,9000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params['aug']='randaugment'\n",
    "train_params['verbose']=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments = TSExperiments(train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.setup_data(df_main, data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers = {'n_epochs': [1], 'max_lr':[1e-5]}\n",
    "\n",
    "df_fn_test = 'results3.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSStandardize??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.run_grid_search(hypers, df_results_fn=df_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.learn.dls.after_batch.tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc,xd,yb = ts_experiments.learn.dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.run_grid_search(hypers, df_results_fn=df_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbs = ts_experiments.dls.after_batch[0](xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ts_experiments.dls.after_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipeline??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compose_tfms(xb, p, split_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.dls.after_batch[1](xbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.learn.dls.after_batch(xb[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.learn.dls.after_batch(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.dls.after_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.dls.after_batch[1].tfms[7].verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.dls.after_batch[1].tfms[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_noise_augs??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.dls.train.rng.sample(range(100),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.dls.train.shuffle_fn(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.run_grid_search(hypers, df_results_fn=df_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.dls.train.rng.sample(range(100),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.dls.shuffle_fn(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results=pd.read_csv(Path(ts_experiments.results_path)/df_fn_test)\n",
    "pd.options.display.max_columns=99\n",
    "df_results_fn = 'results_script.csv'\n",
    "df_results=pd.read_csv(Path('./experiments/results')/df_results_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.learn.dls[2].dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_experiments.learn.get_preds(2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalid = np.round(ts_experiments.learn.get_preds(1)[0].numpy(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_fn=Path('~/google-drive/experiments/results/results_colab.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results=pd.read_csv(results_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=99\n",
    "df_results.query('n_epochs==20 and max_lr==0.0001 and bs==1024')[['ds_id', 'unweighted_profit_0_value', 'unweighted_profit_05_1_value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.sort_values(by='unweighted_profit_0_value', ascending=False)['unweighted_profit_0_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.query('name.str.contains(\"lu\")', engine='python').head())\n",
    "df_results.query('ds_id.str.contains(\"2y\")', engine='python').sort_values(\n",
    "    by='unweighted_profit_0_value', ascending=False)[[\n",
    "    'unweighted_profit_0_value', 'unweighted_profit_05_1_value']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.query('ds_id==\"bi_sample_anon_anon_10sl_4c_2d_2y_159999_184999_209999\"')[[\n",
    "    'ds_id', 'unweighted_profit_0_value', 'unweighted_profit_05_1_value', 'bs', 'wd', 'max_lr']].so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.iloc[92]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ttools]",
   "language": "python",
   "name": "conda-env-ttools-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
