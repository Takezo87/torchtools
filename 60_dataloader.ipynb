{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader\n",
    "\n",
    "> implement a NumpyDataLoader for speedup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different approach to using fastai2 datasets and dataloaders\n",
    "- no datablocks\n",
    "- use modified tsai implementations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the NumpyDataLoader in tsai is significantly faster than using the fastaiv2 DataLoader, \n",
    "#maybe build a custom dataloader to optimize for odds data\n",
    "\n",
    "\n",
    "\n",
    "# import tsai\n",
    "# from tsai.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "#import torch\n",
    "from fastai2.torch_basics import *\n",
    "from fastai2.data.all import *\n",
    "from fastai2.callback.all import *\n",
    "\n",
    "from fastai2.data.all import *\n",
    "from fastai2.basics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import psutil\n",
    "import fastai2\n",
    "import fastcore\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torchtools.data import *\n",
    "from torchtools.datasets import *\n",
    "# from torchtools.augmentations import *\n",
    "from torchtools.datablock import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torchtools.models import *\n",
    "from torchtools.core import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "\n",
    "_verbose=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#tsai.imports\n",
    "cpus = defaults.cpus\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#tsai.utils\n",
    "def bytes2GB(byts):\n",
    "    return round(byts / math.pow(1024, 3), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastai2    : 0.0.18\n",
      "fastcore   : 0.1.18\n",
      "torch      : 1.3.1\n",
      "scipy      : 1.4.1\n",
      "numpy      : 1.18.1\n",
      "pandas     : 0.25.3\n",
      "Total RAM  : 15.56 GB\n",
      "Used RAM   :  9.54 GB\n",
      "n_cpus     : 4\n",
      "device     : cuda (GeForce GTX 950)\n"
     ]
    }
   ],
   "source": [
    "# print('tsai       :', tsai.__version__)\n",
    "print('fastai2    :', fastai2.__version__)\n",
    "print('fastcore   :', fastcore.__version__)\n",
    "print('torch      :', torch.__version__)\n",
    "print('scipy      :', sp.__version__)\n",
    "print('numpy      :', np.__version__)\n",
    "print('pandas     :', pd.__version__)\n",
    "print(f'Total RAM  : {bytes2GB(psutil.virtual_memory().total):5.2f} GB')\n",
    "print(f'Used RAM   : {bytes2GB(psutil.virtual_memory().used):5.2f} GB')\n",
    "print('n_cpus     :', cpus)\n",
    "iscuda = torch.cuda.is_available()\n",
    "if iscuda: print('device     : {} ({})'.format(device, torch.cuda.get_device_name(0)))\n",
    "else: print('device     :', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#tsai.utils\n",
    "#export\n",
    "def totensor(o):\n",
    "    if isinstance(o, torch.Tensor): return o\n",
    "    elif isinstance(o, np.ndarray):  return torch.from_numpy(o)\n",
    "    assert False, f\"Can't convert {type(o)} to torch.Tensor\"\n",
    "\n",
    "\n",
    "def toarray(o):\n",
    "    if isinstance(o, np.ndarray): return o\n",
    "    elif isinstance(o, torch.Tensor): return o.cpu().numpy()\n",
    "    assert False, f\"Can't convert {type(o)} to np.array\"\n",
    "\n",
    "\n",
    "def to3dtensor(o):\n",
    "    o = totensor(o)\n",
    "    if o.ndim == 3: return o\n",
    "    elif o.ndim == 1: return o[None, None]\n",
    "    elif o.ndim == 2: return o[:, None]\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "\n",
    "\n",
    "def to2dtensor(o):\n",
    "    o = totensor(o)\n",
    "    if o.ndim == 2: return o\n",
    "    elif o.ndim == 1: return o[None]\n",
    "    elif o.ndim == 3: return o[0]\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "\n",
    "\n",
    "def to1dtensor(o):\n",
    "    o = totensor(o)\n",
    "    if o.ndim == 1: return o\n",
    "    elif o.ndim == 3: return o[0,0]\n",
    "    if o.ndim == 2: return o[0]\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "\n",
    "\n",
    "def to3darray(o):\n",
    "    o = toarray(o)\n",
    "    if o.ndim == 3: return o\n",
    "    elif o.ndim == 1: return o[None, None]\n",
    "    elif o.ndim == 2: return o[:, None]\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "\n",
    "\n",
    "def to2darray(o):\n",
    "    o = toarray(o)\n",
    "    if o.ndim == 2: return o\n",
    "    elif o.ndim == 1: return o[None]\n",
    "    elif o.ndim == 3: return o[0]\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "\n",
    "\n",
    "def to1darray(o):\n",
    "    o = toarray(o)\n",
    "    if o.ndim == 1: return o\n",
    "    elif o.ndim == 3: o = o[0,0]\n",
    "    elif o.ndim == 2: o = o[0]\n",
    "    assert False, f'Please, review input dimensions {o.ndim}'\n",
    "    \n",
    "    \n",
    "def to3d(o):\n",
    "    if o.ndim == 3: return o\n",
    "    if isinstance(o, np.ndarray): return to3darray(o)\n",
    "    if isinstance(o, torch.Tensor): return to3dtensor(o)\n",
    "    \n",
    "    \n",
    "def to2d(o):\n",
    "    if o.ndim == 2: return o\n",
    "    if isinstance(o, np.ndarray): return to2darray(o)\n",
    "    if isinstance(o, torch.Tensor): return to2dtensor(o)\n",
    "    \n",
    "    \n",
    "def to1d(o):\n",
    "    if o.ndim == 1: return o\n",
    "    if isinstance(o, np.ndarray): return to1darray(o)\n",
    "    if isinstance(o, torch.Tensor): return to1dtensor(o)\n",
    "    \n",
    "    \n",
    "def to2dPlus(o):\n",
    "    if o.ndim >= 2: return o\n",
    "    if isinstance(o, np.ndarray): return to2darray(o)\n",
    "    elif isinstance(o, torch.Tensor): return to2dtensor(o)\n",
    "    \n",
    "    \n",
    "def to3dPlus(o):\n",
    "    if o.ndim >= 3: return o\n",
    "    if isinstance(o, np.ndarray): return to3darray(o)\n",
    "    elif isinstance(o, torch.Tensor): return to3dtensor(o)\n",
    "    \n",
    "    \n",
    "def to2dPlusTensor(o):\n",
    "    return to2dPlus(totensor(o))\n",
    "\n",
    "\n",
    "def to2dPlusArray(o):\n",
    "    return to2dPlus(toarray(o))\n",
    "\n",
    "\n",
    "def to3dPlusTensor(o):\n",
    "    return to3dPlus(totensor(o))\n",
    "\n",
    "\n",
    "def to3dPlusArray(o):\n",
    "    return to3dPlus(toarray(o))\n",
    "\n",
    "\n",
    "def Todtype(dtype):\n",
    "    def _to_type(o, dtype=dtype):\n",
    "        if o.dtype == dtype: return o\n",
    "        elif isinstance(o, torch.Tensor): o = o.to(dtype=dtype)\n",
    "        elif isinstance(o, np.ndarray): o = o.astype(dtype)\n",
    "        return o\n",
    "    return _to_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#tsai.utils\n",
    "#export\n",
    "def itemify(*o, tup_id=None): \n",
    "    items = L(*o).zip()\n",
    "    if tup_id is not None: return L([item[tup_id] for item in items])\n",
    "    else: return items\n",
    "    \n",
    "def ifnoneelse(a, b, c=None):\n",
    "    \"`b` if `a` is None else `c`\"\n",
    "    return b if a is None else ifnone(c, a)\n",
    "\n",
    "def cycle_dl(dl):\n",
    "    for _ in dl: _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#fastcore.foundations\n",
    "def _is_array(x): return hasattr(x,'__array__') or hasattr(x,'iloc')\n",
    "def _listify(o):\n",
    "    if o is None: return []\n",
    "    if isinstance(o, list): return o\n",
    "    if isinstance(o, str) or _is_array(o): return [o]\n",
    "    if is_iter(o): return list(o)\n",
    "    return [o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#tsai.utils\n",
    "def stack(o, axis=0):\n",
    "    if isinstance(o[0], torch.Tensor): return torch.stack(tuple(o), dim=axis)\n",
    "    else: return np.stack(o, axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumpyDatasets:\n",
    "- types for X and y: _xtype, _ytype (with show method)\n",
    "- itemify(X) and itemify(y), (X[i],), are returned since we zip only a single iterable, therefore selction for [0] needed\n",
    "- items: (itemify(X), itemify(y))\n",
    "- init tfms\n",
    "- init tls from zip(items, tfms)\n",
    "- init n_inp\n",
    "- init types for transformed lists\n",
    "- ptls:  type(ptl(it)), ptls: tensor versions of the transformed lists, e.g. normally just stacked items of the tls --> creating these ptls takes a long time, but it is only a one time expense\n",
    "\n",
    "\n",
    "NumpyDatasets: items (X,y)\n",
    "(fastai)Datasets: items[[X1,y1], ... [Xn,yn]]\n",
    "\n",
    "Datasets is a FilteredBase subclass --> handles splits fastai v2 style, subsets, train, valid, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#tsai.data.core\n",
    "class NumpyTensor(TensorBase):\n",
    "    \"Returns a `tensor` with subclass `NumpyTensor` that has a show method\"\n",
    "    def __new__(cls, o, **kwargs):\n",
    "        if isinstance(o, (list, L)): o = stack(o)\n",
    "        res = cast(tensor(o), cls)\n",
    "        res._meta = kwargs\n",
    "        return res\n",
    "    def __getitem__(self, idx):\n",
    "        res = super().__getitem__(idx)\n",
    "        return res.as_subclass(type(self))\n",
    "    def __repr__(self):\n",
    "        if self.numel() == 1: return f'{self}'\n",
    "        else: return f'NumpyTensor(shape:{list(self.shape)})'\n",
    "    def show(self, ax=None, ctx=None, title=None, title_color='black', **kwargs):\n",
    "        if self.ndim != 2: self = type(self)(to2dtensor(self))\n",
    "        ax = ifnone(ax,ctx)\n",
    "        if ax is None: fig, ax = plt.subplots(**kwargs)\n",
    "        ax.plot(self.T)\n",
    "        ax.axis(xmin=0, xmax=self.shape[-1] - 1)\n",
    "        ax.set_title(title, weight='bold', color=title_color)\n",
    "        plt.tight_layout()\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#tsai.data.core\n",
    "class NumpyDatasets(Datasets):\n",
    "    \"A dataset that creates tuples from X (and y) and applies `tfms` of type item_tfms\"\n",
    "    _xtype, _ytype = NumpyTensor, None # Expected X and y output types (must have a show method)\n",
    "    def __init__(self, X=None, y=None, items=None, tfms=None, tls=None, n_inp=None, dl_type=None, inplace=True, **kwargs):\n",
    "        self.inplace = inplace\n",
    "        if tls is None:\n",
    "            X = itemify(X, tup_id=0)\n",
    "            y = itemify(y, tup_id=0) if y is not None else y\n",
    "            items = tuple((X,)) if y is None else tuple((X,y))\n",
    "            self.tfms = L(ifnone(tfms,[None]*len(ifnone(tls,items))))\n",
    "        self.tls = L(tls if tls else [TfmdLists(item, t, **kwargs) for item,t in zip(items,self.tfms)])\n",
    "        self.n_inp = (1 if len(self.tls)==1 else len(self.tls)-1) if n_inp is None else n_inp\n",
    "        if len(self.tls[0]) > 0:\n",
    "            self.types = L([ifnone(_typ, type(tl[0]) if isinstance(tl[0], torch.Tensor) else tensor) \n",
    "                            for tl,_typ in zip(self.tls, [self._xtype, self._ytype])])\n",
    "            self.ptls = L([tl if not self.inplace else tl[:] if type(tl[0]).__name__ == 'memmap' \n",
    "                           else tensor(stack(tl[:])) for tl in self.tls])\n",
    "\n",
    "    def __getitem__(self, it):\n",
    "        return tuple([typ(ptl[it]) for i,(ptl,typ) in enumerate(zip(self.ptls,self.types))])\n",
    "\n",
    "    def subset(self, i): return type(self)(tls=L(tl.subset(i) for tl in self.tls), n_inp=self.n_inp, inplace=self.inplace, tfms=self.tfms)\n",
    "\n",
    "    def _new(self, X, *args, y=None, **kwargs):\n",
    "        items = ifnoneelse(y,tuple((X,)),tuple((X, y)))\n",
    "        return super()._new(items, tfms=self.tfms, do_setup=False, **kwargs)\n",
    "\n",
    "    def show_at(self, idx, **kwargs):\n",
    "        self.show(self[idx], **kwargs)\n",
    "        plt.show()\n",
    "\n",
    "    @property\n",
    "    def items(self): return tuple([tl.items for tl in self.tls])\n",
    "    @items.setter\n",
    "    def items(self, vs):\n",
    "        for tl,c in zip(self.tls, vs): tl.items = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#tsai.data.core\n",
    "#original\n",
    "class TSDatasets(NumpyDatasets):\n",
    "    \"A dataset that creates tuples from X (and y) and applies `item_tfms`\"\n",
    "    _xtype, _ytype = TSTensor, None # Expected X and y output types (torch.Tensor - default - or subclass)\n",
    "    def __init__(self, X=None, y=None, items=None, sel_vars=None, sel_steps=None, tfms=None, tls=None, n_inp=None, dl_type=None, \n",
    "                 inplace=True, **kwargs):\n",
    "        self.inplace = inplace\n",
    "        if tls is None: \n",
    "            X = itemify(X, tup_id=0)\n",
    "            y = itemify(y, tup_id=0) if y is not None else y\n",
    "            items = tuple((X)) if y is None else tuple((X,y))\n",
    "            self.tfms = L(ifnone(tfms,[None]*len(ifnone(tls,items))))\n",
    "        self.sel_vars = ifnone(sel_vars, slice(None))\n",
    "        self.sel_steps = ifnone(sel_steps,slice(None))\n",
    "        self.tls = L(tls if tls else [TfmdLists(item, t, **kwargs) for item,t in zip(items,self.tfms)])\n",
    "        self.n_inp = (1 if len(self.tls)==1 else len(self.tls)-1) if n_inp is None else n_inp\n",
    "        if len(self.tls[0]) > 0: \n",
    "            self.ptls = L([tl if not self.inplace else tl[:] if type(tl[0]).__name__ == 'memmap' else tensor(tl[:]) for tl in self.tls])\n",
    "            self.types = [ifnone(_typ, type(tl[0]) if isinstance(tl[0], torch.Tensor) else tensor) for tl,_typ in zip(self.tls, [self._xtype, self._ytype])]\n",
    "    \n",
    "    def __getitem__(self, it):\n",
    "        return tuple([typ(ptl[it])[...,self.sel_vars, self.sel_steps] if i==0 else typ(ptl[it]) for i,(ptl,typ) in enumerate(zip(self.ptls,self.types))])\n",
    "    \n",
    "    def subset(self, i): return type(self)(tls=L(tl.subset(i) for tl in self.tls), n_inp=self.n_inp, \n",
    "                                           inplace=self.inplace, tfms=self.tfms, sel_vars=self.sel_vars, sel_steps=self.sel_steps)\n",
    "    @property\n",
    "    def vars(self): return self[0][0].shape[-2]\n",
    "    @property\n",
    "    def len(self): return self[0][0].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#tsai.data.core\n",
    "## slightly adapted version\n",
    "##NOTE TODO: Why does _ytype=TensorFloat not work (autograd fails)\n",
    "class TSDatasets2(NumpyDatasets):\n",
    "    \"A dataset that creates tuples from X (and y) and applies `item_tfms`\"\n",
    "    _xtype, _xdistype, _ytype = TSTensor, TSIntTensor, None # Expected X and y output types (torch.Tensor - default - or subclass)\n",
    "    def __init__(self, X=None, X_dis=None, y=None, items=None, sel_vars=None, sel_steps=None, tfms=None, tls=None, n_inp=None, dl_type=None,\n",
    "                 inplace=True, **kwargs):\n",
    "        self.inplace = inplace\n",
    "        if tls is None:\n",
    "            X = itemify(to3darray(X), tup_id=0)\n",
    "            X_dis = itemify(to3darray(X_dis), tup_id=0) if X_dis is not None else X_dis\n",
    "            y = itemify(y, tup_id=0) if y is not None else y\n",
    "            items = tuple((X,)) if y is None else tuple((X,y))\n",
    "            if X_dis is not None: items = tuple((X, X_dis, y)) if y is not None else tuple(X, X_dis,)\n",
    "            self.tfms = L(ifnone(tfms,[None]*len(ifnone(tls,items))))\n",
    "            \n",
    "#         if X_dis is not None: self.X_dis = X_dis\n",
    "       \n",
    "        self.sel_vars = ifnone(sel_vars, slice(None))\n",
    "        self.sel_steps = ifnone(sel_steps,slice(None))\n",
    "        self.tls = L(tls if tls else [TfmdLists(item, t, **kwargs) for item,t in zip(items,self.tfms)])\n",
    "        self.n_inp = (1 if len(self.tls)==1 else len(self.tls)-1) if n_inp is None else n_inp\n",
    "        if len(self.tls[0]) > 0:\n",
    "            _tls_types = [self._xtype, self._ytype] if len(self.tls)==2 else [self._xtype, self._xdistype, self._ytype]\n",
    "            print(_tls_types)\n",
    "#             print(len(self.tls))\n",
    "#             for tl,_typ in zip(self.tls, _tls_types):\n",
    "#                 print (len(tl), _typ, type(tl[0]), isinstance(tl[0], torch.Tensor))\n",
    "            self.types = L([ifnone(_typ, type(tl[0]) if isinstance(tl[0], torch.Tensor) else tensor) for \n",
    "                            tl,_typ in zip(self.tls, _tls_types)])\n",
    "            self.ptls = L([tl if not self.inplace else tl[:] if type(tl[0]).__name__ == 'memmap' else \n",
    "                           tensor(stack(tl[:])) for tl in self.tls])\n",
    "\n",
    "    def __getitem__(self, it):\n",
    "        \n",
    "#         for i,(ptl,typ) in enumerate(zip(self.ptls,self.types)):\n",
    "#             print (i, typ)\n",
    "        \n",
    "#         return tuple([typ(ptl[it])[...,self.sel_vars, self.sel_steps] if i==0 else \n",
    "#                       typ(ptl[it]) for i,(ptl,typ) in enumerate(zip(self.ptls,self.types))])\n",
    "        ## do not enable slicing for now \n",
    "        return tuple([typ(ptl[it]) for i,(ptl,typ) in enumerate(zip(self.ptls,self.types))])\n",
    "    \n",
    "\n",
    "    def subset(self, i): return type(self)(tls=L(tl.subset(i) for tl in self.tls), n_inp=self.n_inp, \n",
    "                                           inplace=self.inplace, tfms=self.tfms,\n",
    "                                           sel_vars=self.sel_vars, sel_steps=self.sel_steps)\n",
    "    @property\n",
    "    def vars(self): return self[0][0].shape[-2]\n",
    "    @property\n",
    "    def len(self): return self[0][0].shape[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#tsai.data.core\n",
    "## slightly adapted version\n",
    "##NOTE TODO: Why does _ytype=TensorFloat not work (autograd fails)\n",
    "class TSDatasets3(NumpyDatasets):\n",
    "    \"A dataset that creates tuples from X (and y) and applies `item_tfms`\"\n",
    "    _xtype, _xdistype, _ytype = TSTensor, TSIntTensor, None # Expected X and y output types (torch.Tensor - default - or subclass)\n",
    "    def __init__(self, X=None, X_dis=None, y=None, items=None, sel_vars=None, sel_steps=None, tfms=None, tls=None, n_inp=None, dl_type=None,\n",
    "                 inplace=True, **kwargs):\n",
    "        self.inplace = inplace\n",
    "      \n",
    "        if tls is None:\n",
    "            X = itemify(to3darray(X), tup_id=0)\n",
    "            X_dis = itemify(to3darray(X_dis), tup_id=0) if X_dis is not None else X_dis\n",
    "            #toarray(y) only needed if y-elements are not scalars, toarray is time consuming\n",
    "            y = itemify(toarray(y), tup_id=0) if y is not None else y\n",
    "            items = tuple((X,)) if y is None else tuple((X,y))\n",
    "            if X_dis is not None: items = tuple((X, X_dis, y)) if y is not None else tuple(X, X_dis,)\n",
    "            self.tfms = L(ifnone(tfms,[None]*len(ifnone(tls,items))))\n",
    "            \n",
    "#         if X_dis is not None: self.X_dis = X_dis\n",
    "       \n",
    "        self.sel_vars = ifnone(sel_vars, slice(None))\n",
    "        self.sel_steps = ifnone(sel_steps,slice(None))\n",
    "#         self.splits_help = splits\n",
    "        self.tls = L(tls if tls else [TfmdLists(item, t, **kwargs) for item,t in zip(items,self.tfms)])\n",
    "        self.n_inp = (1 if len(self.tls)==1 else len(self.tls)-1) if n_inp is None else n_inp\n",
    "        if len(self.tls[0]) > 0:\n",
    "            _tls_types = [self._xtype, self._ytype] if len(self.tls)==2 else [self._xtype, self._xdistype, self._ytype]\n",
    "#             print(_tls_types)\n",
    "#             print(len(self.tls))\n",
    "#             for tl,_typ in zip(self.tls, _tls_types):\n",
    "#                 print (len(tl), _typ, type(tl[0]), isinstance(tl[0], torch.Tensor))\n",
    "            self.types = L([ifnone(_typ, type(tl[0]) if isinstance(tl[0], torch.Tensor) else tensor) for \n",
    "                            tl,_typ in zip(self.tls, _tls_types)])\n",
    "    \n",
    "            self.types = L([ifnone(_typ, type(tl[0]) if isinstance(tl[0], torch.nn.Sequential) else tensor) for \n",
    "                            tl,_typ in zip(self.tls, _tls_types)])\n",
    "            if self.inplace and X and y: self.ptls=L(\n",
    "                [tensor(X), tensor(y)]) if not X_dis else L([tensor(X), tensor(X_dis), tensor(y)])\n",
    "            else:\n",
    "                self.ptls = L([tl if not self.inplace else tl[:] if type(tl[0]).__name__ == 'memmap' else \n",
    "                               tensor(stack(tl[:])) for tl in self.tls])\n",
    "\n",
    "    def __getitem__(self, it):\n",
    "        \n",
    "#         for i,(ptl,typ) in enumerate(zip(self.ptls,self.types)):\n",
    "#             print (i, typ)\n",
    "        \n",
    "#         return tuple([typ(ptl[it])[...,self.sel_vars, self.sel_steps] if i==0 else \n",
    "#                       typ(ptl[it]) for i,(ptl,typ) in enumerate(zip(self.ptls,self.types))])\n",
    "        ## do not enable slicing for now \n",
    "        return tuple([typ(ptl[it]) for i,(ptl,typ) in enumerate(zip(self.ptls,self.types))])\n",
    "    \n",
    "\n",
    "    def subset(self, i): \n",
    "        if self.inplace:\n",
    "            X = self.ptls[0][self.splits[i]]\n",
    "            y = self.ptls[-1][self.splits[i]]\n",
    "            X_dis = None if len(self.ptls)==2 else self.ptls[1][self.splits[i]]\n",
    "            #if X_dis:print(X.shape, y.shape, X_dis.shape)\n",
    "            res = type(self)(X=X, X_dis=X_dis, y=y, n_inp=self.n_inp, \n",
    "                                           inplace=self.inplace, tfms=self.tfms,\n",
    "                                           sel_vars=self.sel_vars, sel_steps=self.sel_steps)\n",
    "            res.set_split_idx_fixed(i)\n",
    "            return res\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            return type(self)(tls=L(tl.subset(i) for tl in self.tls), n_inp=self.n_inp, \n",
    "                                           inplace=self.inplace, tfms=self.tfms,\n",
    "                                           sel_vars=self.sel_vars, sel_steps=self.sel_steps)\n",
    "    @property\n",
    "    def vars(self): return self[0][0].shape[-2]\n",
    "    @property\n",
    "    def len(self): return self[0][0].shape[-1]\n",
    "    \n",
    "    ## do not confuse with set_split_idx contextmanager in fastai2 Datasets\n",
    "    def set_split_idx_fixed(self, i):\n",
    "        for tl in self.tls: tl.tfms.split_idx = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_xs??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#tsai.data.core\n",
    "## slightly adapted version\n",
    "##NOTE TODO: Why does _ytype=TensorFloat not work (autograd fails)\n",
    "class TSDatasets4(NumpyDatasets):\n",
    "    \"A dataset that creates tuples from X (and y) and applies `item_tfms`\"\n",
    "    _xtype, _xdistype, _xtabctype, _xtabcattype, _ytype = TSTensor, TSIntTensor, None, None, None # Expected X and y output types (torch.Tensor - default - or subclass)\n",
    "    def __init__(self, X=None, X_dis=None, y=None, items=None, sel_vars=None, sel_steps=None, tfms=None, tls=None, n_inp=None, dl_type=None,\n",
    "                 inplace=True, X_tabc=None, X_tabcat=None, **kwargs):\n",
    "        self.inplace = inplace\n",
    "        self.has_xtype=[X is not None, X_dis is not None, X_tabc is not None, X_tabcat is not None]\n",
    "      \n",
    "        if tls is None:\n",
    "            X = itemify(to3darray(X), tup_id=0) if X is not None else X\n",
    "            X_dis = itemify(to3darray(X_dis), tup_id=0) if X_dis is not None else X_dis\n",
    "            X_tabc = itemify(toarray(X_tabc), tup_id=0) if X_tabc is not None else X_tabc\n",
    "            X_tabcat = itemify(toarray(X_tabcat), tup_id=0) if X_tabcat is not None else X_tabcat\n",
    "            #toarray(y) only needed if y-elements are not scalars, toarray is time consuming\n",
    "            y = itemify(toarray(y), tup_id=0) if y is not None else y\n",
    "            items = tuple((X,)) if y is None else tuple(x for x in [X,X_dis, X_tabc, X_tabcat, y] if x is not None)\n",
    "#             if X_dis is not None: items = tuple((X, X_dis, y)) if y is not None else tuple(X, X_dis,)\n",
    "            self.tfms = L(ifnone(tfms,[None]*len(ifnone(tls,items))))\n",
    "            \n",
    "#         if X_dis is not None: self.X_dis = X_dis\n",
    "       \n",
    "        self.sel_vars = ifnone(sel_vars, slice(None))\n",
    "        self.sel_steps = ifnone(sel_steps,slice(None))\n",
    "#         self.splits_help = splits\n",
    "        self.tls = L(tls if tls else [TfmdLists(item, t, **kwargs) for item,t in zip(items,self.tfms)])\n",
    "        self.n_inp = (1 if len(self.tls)==1 else len(self.tls)-1) if n_inp is None else n_inp\n",
    "        if len(self.tls[0]) > 0:\n",
    "#             print(_xtype)\n",
    "            _tls_types=[t for x,t in zip(\n",
    "                [X,X_dis, X_tabc, X_tabcat, y], [self._xtype, self._xdistype, \n",
    "                                                 self._xtabctype, self._xtabcattype, self._ytype]) \n",
    "                        if x is not None]                                           \n",
    "                                                        \n",
    "            print(_tls_types)             \n",
    "            #_tls_types = [self._xtype, self._ytype] if len(self.tls)==2 else [self._xtype, self._xdistype, self._ytype]\n",
    "#             print(_tls_types)\n",
    "#             print(len(self.tls))\n",
    "#             for tl,_typ in zip(self.tls, _tls_types):\n",
    "#                 print (len(tl), _typ, type(tl[0]), isinstance(tl[0], torch.Tensor))\n",
    "            self.types = L([ifnone(_typ, type(tl[0]) if isinstance(tl[0], torch.Tensor) else tensor) for \n",
    "                            tl,_typ in zip(self.tls, _tls_types)])\n",
    "    \n",
    "#             self.types = L([ifnone(_typ, type(tl[0]) if isinstance(tl[0], torch.nn.Sequential) else tensor) for \n",
    "#                             tl,_typ in zip(self.tls, _tls_types)])\n",
    "\n",
    "            if self.inplace and X and y: \n",
    "                \n",
    "                self.ptls=L([tensor(x) for x in [X,X_dis, X_tabc, X_tabcat] if x is not None]+[tensor(y)])\n",
    "#                 [tensor(X), tensor(y)]) if not X_dis else L([tensor(X), tensor(X_dis), tensor(y)])\n",
    "\n",
    "\n",
    "#             if self.inplace and X and y: self.ptls=L(\n",
    "#                 [tensor(X), tensor(y)]) if not X_dis else L([tensor(X), tensor(X_dis), tensor(y)])\n",
    "            else:\n",
    "                self.ptls = L([tl if not self.inplace else tl[:] if type(tl[0]).__name__ == 'memmap' else \n",
    "                               tensor(stack(tl[:])) for tl in self.tls])\n",
    "\n",
    "    def __getitem__(self, it):\n",
    "        \n",
    "#         for i,(ptl,typ) in enumerate(zip(self.ptls,self.types)):\n",
    "#             print (i, typ)\n",
    "        \n",
    "#         return tuple([typ(ptl[it])[...,self.sel_vars, self.sel_steps] if i==0 else \n",
    "#                       typ(ptl[it]) for i,(ptl,typ) in enumerate(zip(self.ptls,self.types))])\n",
    "        ## do not enable slicing for now \n",
    "        return tuple([typ(ptl[it]) for i,(ptl,typ) in enumerate(zip(self.ptls,self.types))])\n",
    "    \n",
    "\n",
    "    def subset(self, i): \n",
    "        if self.inplace:\n",
    "            X_type_idxs = [i for i in range(4) if self.has_xtype[i]]\n",
    "            Xs = ['X', 'X_dis', 'X_tabc', 'X_tabcat']\n",
    "            X_dict=defaultdict(lambda:None)\n",
    "            for j,k in enumerate(X_type_idxs):\n",
    "                X_dict[Xs[k]]=  self.ptls[j][self.splits[i]]\n",
    "            \n",
    "            X,X_dis,X_tabc,X_tabcat = map(X_dict.__getitem__, Xs)\n",
    "            \n",
    "        \n",
    "            \n",
    "#             X = None if self.has_xtype[0] is False else self.ptls[0][self.splits[i]]\n",
    "#             X_dis = None if self.has_xtype[1] is False else self.ptls[1-self.has_xtype[0]][self.splits[i]]\n",
    "#             X_tabc = None if self.has_xtype[2] is False else self.ptls[\n",
    "#                 2-self.has_xtype[0]-self.has_xtype[1]][self.splits[i]]\n",
    "#             X_tabcat = None if self.has_xtype[3] is False else self.ptls[\n",
    "#                 3-self.has_xtype[0]-self.has_xtype[1]-self.has_xtype[2]][self.splits[i]]][self.splits[i]]\n",
    "            y = self.ptls[-1][self.splits[i]]\n",
    "\n",
    "            #if X_dis:print(X.shape, y.shape, X_dis.shape)\n",
    "            res = type(self)(X=X, X_dis=X_dis, X_tabc=X_tabc, X_tabcat=X_tabcat, y=y, n_inp=self.n_inp, \n",
    "                                           inplace=self.inplace, tfms=self.tfms,\n",
    "                                           sel_vars=self.sel_vars, sel_steps=self.sel_steps)\n",
    "            res.set_split_idx_fixed(i)\n",
    "            return res\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            return type(self)(tls=L(tl.subset(i) for tl in self.tls), n_inp=self.n_inp, \n",
    "                                           inplace=self.inplace, tfms=self.tfms,\n",
    "                                           sel_vars=self.sel_vars, sel_steps=self.sel_steps)\n",
    "    @property\n",
    "    def vars(self): return self[0][0].shape[-2]\n",
    "    @property\n",
    "    def len(self): return self[0][0].shape[-1]\n",
    "    \n",
    "    ## do not confuse with set_split_idx contextmanager in fastai2 Datasets\n",
    "    def set_split_idx_fixed(self, i):\n",
    "        for tl in self.tls: tl.tfms.split_idx = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TSDatasets5:\n",
    "- we basically drop the usage of TfmdLists for performance reasons\n",
    "- item transforms like Categorize and Categorify have to be done before creating the Datasets -> pass vocabs to dataloaders\n",
    "- we use arrays and tensors instead of the lists for fast indexing\n",
    "- batch_tfms are still working\n",
    "- allow passing of Tensor types instead of item transforms\n",
    "- X_c, X_d, X_tcont, X_tcat: continuous timeseries, discrete timeseries, continuous tabular, categorical tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#tsai.data.core\n",
    "## adapted version\n",
    "\n",
    "##Note: For this version of Datasets, item transforms are not propagated, transformed lists more or less pointless?? It is much faster though\n",
    "\n",
    "class TSDatasets5(NumpyDatasets):\n",
    "    \"A dataset that creates tuples from X (and y) and applies `item_tfms`\"\n",
    "    _xctype, _xdtype, _xtconttype, _xtcattype, _ytype = TSTensor, TSIntTensor, None, None, None # Expected X and y output types (torch.Tensor - default - or subclass)\n",
    "    def __init__(self, X_c=None, X_d=None, y=None, items=None, tfms=None, tls=None, n_inp=None, dl_type=None,\n",
    "                 inplace=True, X_tcont=None, X_tcat=None, has_x=None, _ytype=None, **kwargs):\n",
    "        self.inplace = inplace ## should be always True for this implementation\n",
    "        self._ytype = _ytype\n",
    "        self.has_x = ifnone(has_x, [X_c is not None, X_d is not None, \n",
    "                                            X_tcont is not None, X_tcat is not None])\n",
    "      \n",
    "        if tls is None: ## always None in this implementation\n",
    "            X_c = itemify(to3darray(X_c), tup_id=0) if X_c is not None else X_c\n",
    "            X_d = itemify(to3darray(X_d), tup_id=0) if X_d is not None else X_d\n",
    "            X_tcont = itemify(toarray(X_tcont), tup_id=0) if X_tcont is not None else X_tcont\n",
    "            X_tcat = itemify(toarray(X_tcat), tup_id=0) if X_tcat is not None else X_tcat\n",
    "            #toarray(y) only needed if y-elements are not scalars, toarray is time consuming\n",
    "            y = itemify(toarray(y), tup_id=0) if y is not None else y\n",
    "            items = tuple((X_c,)) if y is None else tuple(x for x in [X_c, X_d, X_tcont, X_tcat, y] \n",
    "                                                          if x is not None)\n",
    "            self.tfms = L(ifnone(tfms,[None]*len(ifnone(tls,items))))\n",
    "      \n",
    "        self.tls = L(tls if tls else [TfmdLists(item, t, **kwargs) for item,t in zip(items,self.tfms)])\n",
    "        self.n_inp = (1 if len(self.tls)==1 else len(self.tls)-1) if n_inp is None else n_inp\n",
    "        if len(self.tls[0]) > 0:\n",
    "#             print(_xtype)\n",
    "            _tls_types=L([self._xctype, self._xdtype, self._xtconttype, self._xtcattype])[self.has_x]+L([self._ytype])\n",
    "#             _tls_types=[t for x,t in zip(self.has_x, [self._xctype, self._xdtype, self._xtconttype, self._xtcattype, self._ytype]) \n",
    "#                         if x]                                           \n",
    "            print(_tls_types)             \n",
    "        \n",
    "            self.types = [ifnone(_typ, type(tl[0]) if isinstance(tl[0], torch.Tensor) else tensor) for \n",
    "                            tl,_typ in zip(self.tls, _tls_types)]\n",
    "\n",
    "            if self.inplace: \n",
    "                print('fast part')\n",
    "                self.ptls=L([tensor(x) for x in [X_c, X_d, X_tcont, X_tcat,y] if x is not None])\n",
    "            else:\n",
    "        #this part should never be called in this implementation, observe that the item transforms\n",
    "        #in the original fastai2 datasets are applied by slicing into the TfmdLists\n",
    "                print('slow part')\n",
    "                self.ptls = L([tl if not self.inplace else tl[:] if type(tl[0]).__name__ == 'memmap' else \n",
    "                               tensor(stack(tl[:])) for tl in self.tls])\n",
    "\n",
    "    def __getitem__(self, it):\n",
    "        return tuple([typ(ptl[it]) for i,(ptl,typ) in enumerate(zip(self.ptls,self.types))])\n",
    "    \n",
    "#     @property\n",
    "    def subset(self, i): \n",
    "#         return type(self)(tls=L(tl.subset(i) for tl in self.tls), n_inp=self.n_inp, \n",
    "#                                            inplace=self.inplace, tfms=self.tfms,\n",
    "#                                            sel_vars=self.sel_vars, sel_steps=self.sel_steps, \n",
    "#                           has_xtype=self.has_xtype)\n",
    "        if self.inplace:\n",
    "            Xs = [x[self.splits[i]] for x in self.ptls[:-1]]\n",
    "            X_c,X_d,X_tcont,X_tcat = map_xs(Xs, self.has_x)\n",
    "            y = np.array(self.ptls[-1][self.splits[i]])\n",
    "\n",
    "            #if X_dis:print(X.shape, y.shape, X_dis.shape)\n",
    "            res = type(self)(X_c=X_c, X_d=X_d, X_tcont=X_tcont, X_tcat=X_tcat, y=y, n_inp=self.n_inp, \n",
    "                                           inplace=self.inplace, tfms=self.tfms, _ytype=self._ytype)\n",
    "            res.set_split_idx_fixed(i)\n",
    "            return res\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            return type(self)(tls=L(tl.subset(i) for tl in self.tls), n_inp=self.n_inp, \n",
    "                                           inplace=self.inplace, tfms=self.tfms,\n",
    "                                           sel_vars=self.sel_vars, sel_steps=self.sel_steps)\n",
    "    @property\n",
    "    def vars(self): return self[0][0].shape[-2]\n",
    "    @property\n",
    "    def len(self): return self[0][0].shape[-1]\n",
    "    \n",
    "    ## do not confuse with set_split_idx contextmanager in fastai2 Datasets\n",
    "    def set_split_idx_fixed(self, i):\n",
    "        for tl in self.tls: tl.tfms.split_idx = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fastaiv2 DataLoader:  \n",
    "`def create_batch(self, b): return (fa_collate,fa_convert)[self.prebatched](b)`  \n",
    "- collate collates several tensors together into one (batch)-tensor\n",
    "- convert array->tensor \n",
    "`def create_item(self, s):  return next(self.it) if s is None else self.dataset[s]`\n",
    "\n",
    "\n",
    "no need for collating and converting in the NumpyDataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumpyDataLoader:\n",
    "- it is a subclass of TfmdDL, TfmdDL is a subclass of the standard v2 Dataloader:\n",
    "\n",
    "The following parts are redefined:\n",
    "- create_batch: slice instead of collate and convert (already collated and converted)\n",
    "- create_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumpyDataLoader setup:\n",
    "- for nm in _batch_tfms (after_item, before_batch, after_batch)\n",
    "- after_item.setup(self) is called --> Pipelines, and Dataloader as parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DataLoader.__iter__`:  \n",
    " - for b in _loaders[self.fake_l.num_workers==0](self.fake_l): just chooses the right loader (multiproc or not), casts self.fake_l to this loader, and then iterates over that  loader:\n",
    " - casts b to correct device\n",
    " - yields after_batch(b)\n",
    "- after_batch in DataLoader is noop, it is a Pipeline of optional transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#tsai.data.core\n",
    "\n",
    "class NumpyTensorBlock():\n",
    "    def __init__(self, type_tfms=None, item_tfms=None, batch_tfms=None, dl_type=None, dls_kwargs=None):\n",
    "        self.type_tfms  =                 L(type_tfms)\n",
    "        self.item_tfms  = ToNumpyTensor + L(item_tfms)\n",
    "        self.batch_tfms =                 L(batch_tfms)\n",
    "        self.dl_type,self.dls_kwargs = dl_type,({} if dls_kwargs is None else dls_kwargs)\n",
    "        \n",
    "class TSTensorBlock():\n",
    "    def __init__(self, type_tfms=None, item_tfms=None, batch_tfms=None, dl_type=None, dls_kwargs=None):\n",
    "        self.type_tfms  =              L(type_tfms)\n",
    "        self.item_tfms  = ToTSTensor + L(item_tfms)\n",
    "        self.batch_tfms =              L(batch_tfms)\n",
    "        self.dl_type,self.dls_kwargs = dl_type,({} if dls_kwargs is None else dls_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#tsai.data.core\n",
    "_batch_tfms = ('after_item','before_batch','after_batch')\n",
    "\n",
    "class NumpyDataLoader(TfmdDL):\n",
    "    idxs = None\n",
    "    do_item = noops # create batch returns indices\n",
    "    def __init__(self, dataset, bs=64, shuffle=False, num_workers=None, verbose=False, do_setup=True, batch_tfms=None, **kwargs):\n",
    "        '''batch_tfms == after_batch (either can be used)'''\n",
    "        if num_workers is None: num_workers = min(16, defaults.cpus)\n",
    "        for nm in _batch_tfms: \n",
    "            if nm == 'after_batch' and batch_tfms is not None: kwargs[nm] = Pipeline(batch_tfms)\n",
    "            else: kwargs[nm] = Pipeline(kwargs.get(nm,None))\n",
    "        bs = min(bs, len(dataset))\n",
    "        super().__init__(dataset, bs=bs, shuffle=shuffle, num_workers=num_workers, **kwargs)\n",
    "        if do_setup:\n",
    "            for nm in _batch_tfms:\n",
    "                pv(f\"Setting up {nm}: {kwargs[nm]}\", verbose)\n",
    "                kwargs[nm].setup(self)\n",
    "\n",
    "    def create_batch(self, b):\n",
    "        it = b if self.shuffle else slice(b[0], b[0] + self.bs)\n",
    "        self.idxs = b\n",
    "        return self.dataset[it]\n",
    "\n",
    "    def create_item(self, s): return s\n",
    "\n",
    "    def get_idxs(self):\n",
    "        idxs = Inf.count if self.indexed else Inf.nones\n",
    "        if self.n is not None: idxs = list(range(len(self.dataset)))\n",
    "        if self.shuffle: idxs = self.shuffle_fn(idxs)\n",
    "        return idxs\n",
    "\n",
    "    @delegates(plt.subplots)\n",
    "    def show_batch(self, b=None, ctxs=None, max_n=9, nrows=3, ncols=3, figsize=(16, 10), **kwargs):\n",
    "        b = self.one_batch()\n",
    "        db = self.decode_batch(b, max_n=max_n)\n",
    "        if figsize is None: figsize = (ncols*6, max_n//ncols*4)\n",
    "        if ctxs is None: ctxs = get_grid(min(len(db), nrows*ncols), nrows=None, ncols=ncols, figsize=figsize, **kwargs)\n",
    "        for i,ctx in enumerate(ctxs): show_tuple(db[i], ctx=ctx)\n",
    "\n",
    "    @delegates(plt.subplots)\n",
    "    def show_results(self, b, preds, ctxs=None, max_n=9, nrows=3, ncols=3, figsize=(16, 10), **kwargs):\n",
    "        t = self.decode_batch(b, max_n=max_n)\n",
    "        p = self.decode_batch((b[0],preds), max_n=max_n)\n",
    "        if figsize is None: figsize = (ncols*6, max_n//ncols*4)\n",
    "        if ctxs is None: ctxs = get_grid(min(len(t), nrows*ncols), nrows=None, ncols=ncols, figsize=figsize, **kwargs)\n",
    "        for i,ctx in enumerate(ctxs): \n",
    "            title = f'True: {t[i][1]}\\nPred: {p[i][1]}'\n",
    "            color = 'green' if t[i][1] == p[i][1] else 'red'\n",
    "            t[i][0].show(ctx=ctx, title=title, title_color=color)\n",
    "\n",
    "@delegates(plt.subplots)\n",
    "def show_tuple(tup, **kwargs):\n",
    "    \"Display a timeseries plot from a decoded tuple\"\n",
    "    tup[0].show(title='unlabeled' if len(tup) == 1 else tup[1], **kwargs)\n",
    "    \n",
    "class TSDataLoader(NumpyDataLoader): \n",
    "    @property\n",
    "    def vars(self): return self.dataset[0][0].shape[-2]\n",
    "    @property\n",
    "    def len(self): return self.dataset[0][0].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#tsai.data.core\n",
    "\n",
    "_batch_tfms = ('after_item','before_batch','after_batch')\n",
    "\n",
    "class NumpyDataLoaders(DataLoaders):\n",
    "    _xblock = NumpyTensorBlock\n",
    "    _dl_type = NumpyDataLoader \n",
    "    def __init__(self, *loaders, path='.', device=default_device()):\n",
    "        self.loaders,self.path = list(loaders),Path(path)\n",
    "        self.device = device\n",
    "        \n",
    "    @classmethod\n",
    "    @delegates(DataLoaders.from_dblock)\n",
    "    def from_numpy(cls, X, y=None, splitter=None, valid_pct=0.2, seed=0, item_tfms=None, batch_tfms=None, **kwargs):\n",
    "        \"Create timeseries dataloaders from arrays (X and y, unless unlabeled)\"\n",
    "        if splitter is None: splitter = RandomSplitter(valid_pct=valid_pct, seed=seed)\n",
    "        getters = [ItemGetter(0), ItemGetter(1)] if y is not None else [ItemGetter(0)]\n",
    "        dblock = DataBlock(blocks=(cls._xblock, CategoryBlock),\n",
    "                           getters=getters,\n",
    "                           splitter=splitter,\n",
    "                           item_tfms=item_tfms,\n",
    "                           batch_tfms=batch_tfms)\n",
    "\n",
    "        source = itemify(X) if y is None else itemify(X,y)\n",
    "        return cls.from_dblock(dblock, source, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def from_dsets(cls, *ds, path='.', bs=64, num_workers=0, batch_tfms=None, device=None, \n",
    "                   shuffle_train=True, **kwargs):\n",
    "        default = (shuffle_train,) + (False,) * (len(ds)-1)\n",
    "        defaults = {'shuffle': default, 'drop_last': default}\n",
    "        kwargs = merge(defaults, {k: tuplify(v, match=ds) for k,v in kwargs.items()})\n",
    "        kwargs = [{k: v[i] for k,v in kwargs.items()} for i in range_of(ds)]\n",
    "        if not is_listy(bs): bs = [bs]\n",
    "        if len(bs) != len(ds): bs = bs * len(ds)\n",
    "        device = ifnone(device,default_device())\n",
    "        return cls(*[cls._dl_type(d, bs=b, num_workers=num_workers, batch_tfms=batch_tfms, **k) \\\n",
    "                     for d,k,b in zip(ds, kwargs, bs)], path=path, device=device)\n",
    "\n",
    "class TSDataLoaders(NumpyDataLoaders):\n",
    "    _xblock = TSTensorBlock\n",
    "    _dl_type = TSDataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#tsai.data.transform, slightly modified for optional discrete channels\n",
    "class TSStandardize(Transform):\n",
    "    \"Standardize/destd batch of `NumpyTensor` or `TSTensor`\"\n",
    "    parameters, order = L('mean', 'std'), 99\n",
    "    def __init__(self, mean=None, std=None, by_sample=False, by_var=False, verbose=False, discrete=False):\n",
    "        self.mean = tensor(mean) if mean is not None else None\n",
    "        self.std = tensor(std) if std is not None else None\n",
    "        self.by_sample, self.by_var = by_sample, by_var\n",
    "        if by_sample and by_var: self.axes = (2)\n",
    "        elif by_sample: self.axes = (1, 2)\n",
    "        elif by_var: self.axes = (0, 2)\n",
    "        else: self.axes = ()\n",
    "        self.verbose = verbose\n",
    "        self.discrete=discrete\n",
    "\n",
    "    @classmethod\n",
    "    def from_stats(cls, mean, std): return cls(mean, std)\n",
    "\n",
    "    def setups(self, dl: DataLoader):\n",
    "        if self.mean is None or self.std is None:\n",
    "            pv(f'{self.__class__.__name__} setup mean={self.mean}, std={self.std}, by_sample={self.by_sample}, by_var={self.by_var}', self.verbose)\n",
    "#             x, *_ = dl.one_batch() ##??\n",
    "#             assert not self.discrete or len(dl.ptls)==3\n",
    "            x = dl.ptls[0] if not self.discrete else dl.ptls[1]## modification\n",
    "            self.mean, self.std = x.float().mean(self.axes, keepdim=self.axes!=()), x.float().std(self.axes, keepdim=self.axes!=()) + 1e-7\n",
    "            pv(f'mean: {self.mean}  std: {self.std}\\n', self.verbose)\n",
    "\n",
    "    def encodes(self, x:(NumpyTensor, TSTensor)):\n",
    "        if self.discrete: return x\n",
    "        pv('standardize cont encodes', self.verbose)\n",
    "        if self.by_sample: self.mean, self.std = x.mean(self.axes, keepdim=self.axes!=()), x.std(self.axes, keepdim=self.axes!=()) + 1e-7\n",
    "        return (x - self.mean) / self.std\n",
    "    \n",
    "    def encodes(self, x:(TSIntTensor)):\n",
    "        if not self.discrete: return x\n",
    "        pv('standardize int encodes', self.verbose)\n",
    "        if self.by_sample: self.mean, self.std = x.mean(self.axes, keepdim=self.axes!=()), x.std(self.axes, keepdim=self.axes!=()) + 1e-7\n",
    "        return (x - self.mean) / self.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# #standardization for discrete channels\n",
    "# class TSStandardizeD(Transform):\n",
    "#     \"Standardize/destd batch of `NumpyTensor` or `TSTensor`\"\n",
    "#     parameters, order = L('mean', 'std'), 99\n",
    "#     def __init__(self, mean=None, std=None, by_sample=False, by_var=False, verbose=False):\n",
    "#         self.mean = tensor(mean) if mean is not None else None\n",
    "#         self.std = tensor(std) if std is not None else None\n",
    "#         self.by_sample, self.by_var = by_sample, by_var\n",
    "#         if by_sample and by_var: self.axes = (2)\n",
    "#         elif by_sample: self.axes = (1, 2)\n",
    "#         elif by_var: self.axes = (0, 2)\n",
    "#         else: self.axes = ()\n",
    "#         self.verbose = verbose\n",
    "\n",
    "#     @classmethod\n",
    "#     def from_stats(cls, mean, std): return cls(mean, std)\n",
    "\n",
    "#     def setups(self, dl: DataLoader):\n",
    "#         if self.mean is None or self.std is None:\n",
    "#             pv(f'{self.__class__.__name__} setup mean={self.mean}, std={self.std}, by_sample={self.by_sample}, by_var={self.by_var}', self.verbose)\n",
    "# #             x, *_ = dl.one_batch() ##??\n",
    "#             x = dl.ptls[1] ## modification\n",
    "#             self.mean, self.std = x.mean(self.axes, keepdim=self.axes!=()), x.std(self.axes, keepdim=self.axes!=()) + 1e-7\n",
    "#             pv(f'mean: {self.mean}  std: {self.std}\\n', self.verbose)\n",
    "\n",
    "#     def encodes(self, x:(NumpyTensor, TSTensor)): \n",
    "#         pv('standardize encodes', self.verbose)\n",
    "#         if self.by_sample: self.mean, self.std = x.mean(self.axes, keepdim=self.axes!=()), x.std(self.axes, keepdim=self.axes!=()) + 1e-7\n",
    "#         return (x - self.mean) / self.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def mul_min(x:(torch.Tensor, TSTensor, NumpyTensor), axes=(), keepdim=False):\n",
    "    if axes == (): return retain_type(x.min(), x)\n",
    "    axes = reversed(sorted(axes if is_listy(axes) else [axes]))\n",
    "    min_x = x\n",
    "    for ax in axes: min_x, _ = min_x.min(ax, keepdim)\n",
    "    return retain_type(min_x, x)\n",
    "\n",
    "@patch\n",
    "def mul_max(x:(torch.Tensor, TSTensor, NumpyTensor), axes=(), keepdim=False):\n",
    "    if axes == (): return retain_type(x.max(), x)\n",
    "    axes = reversed(sorted(axes if is_listy(axes) else [axes]))\n",
    "    max_x = x\n",
    "    for ax in axes: max_x, _ = max_x.max(ax, keepdim)\n",
    "    return retain_type(max_x, x)\n",
    "\n",
    "\n",
    "class TSNormalize(Transform):\n",
    "    \"Normalize/denorm batch of `NumpyTensor` or `TSTensor`\"\n",
    "    parameters, order = L('min', 'max'), 99\n",
    "\n",
    "    def __init__(self, min=None, max=None, range_min=-1, range_max=1, by_sample=True, by_var=False, verbose=False):\n",
    "        self.min = tensor(min) if min is not None else None\n",
    "        self.max = tensor(max) if max is not None else None\n",
    "        self.range_min, self.range_max = range_min, range_max\n",
    "        self.by_sample, self.by_var = by_sample, by_var\n",
    "        if by_sample and by_var: self.axes = (2)\n",
    "        elif by_sample: self.axes = (1, 2)\n",
    "        elif by_var: self.axes = (0, 2)\n",
    "        else: self.axes = ()\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    @classmethod\n",
    "    def from_stats(cls, min, max, range_min=0, range_max=1): return cls(min, max, self.range_min, self.range_max)\n",
    "\n",
    "    def setups(self, dl: DataLoader):\n",
    "        if self.min is None or self.max is None:\n",
    "            pv(f'{self.__class__.__name__} setup min={self.min}, max={self.max}, range_min={self.range_min}, range_max={self.range_max}, by_sample={self.by_sample}, by_var={self.by_var}',  self.verbose)\n",
    "#             x, *_ = dl.one_batch()\n",
    "            x = dl.ptls[0] \n",
    "            self.min, self.max = x.mul_min(self.axes, keepdim=self.axes!=()), x.mul_max(self.axes, keepdim=self.axes!=())\n",
    "            pv(f'min: {self.min}  max: {self.max}\\n', self.verbose)\n",
    "\n",
    "    def encodes(self, x:(NumpyTensor, TSTensor)):\n",
    "        if self.by_sample: self.min, self.max = x.mul_min(self.axes, keepdim=self.axes!=()), x.mul_max(self.axes, keepdim=self.axes!=())\n",
    "        return ((x - self.min) / (self.max - self.min)) * (self.range_max - self.range_min) + self.range_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def items_to_arrays(items):\n",
    "    '''convert list of item tuples into X,y numpy arrays (for use with numpy dataloader)'''\n",
    "#     return np.stack([x[0] for x in items]), np.stack([x[1] for x in items])\n",
    "    return tuple(np.stack([x[i] for x in items]) for i in range(len(items[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 20000\n",
    "df_main = pd.read_csv('./data/custom/bi_sample_anon.csv', nrows=nrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "items is a list of (x,y) tuples  \n",
    "methods called when passing items to DataBlock:\n",
    "- DataBlock.datasets(items, ....)\n",
    "- Dataset(items, ...)\n",
    "- TfmdList(items, ...)\n",
    "- L(items, ...)\n",
    "- CollBase.__init__(items, ...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtools.configs import *\n",
    "config_id =  'anon_10sl_4c_2d_2y'\n",
    "col_config = read_config(config_id, 'config2.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## [(x_1, y_1), ..., (x_n, y_n)]\n",
    "# items = df_to_items(df_main, x_cols, dep, n_train)[0]\n",
    "cols_c, cols_d, cols_y = L(['cols_c', 'cols_d', 'cols_y']).map(col_config.get)\n",
    "n_train = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_from_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 4, 10)\n",
      "(20000, 2, 10)\n"
     ]
    }
   ],
   "source": [
    "items = items_from_df(df_main, cols_c, cols_y, n_train, cols_d=cols_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  -7.8431373,  100.       ,   -6.497726 ,  -24.509804 ,\n",
       "          -33.22259  ,  -42.735043 ,  -55.24862  ,  -56.497173 ,\n",
       "          -30.674847 ,  100.       ],\n",
       "        [ 100.       ,    0.       ,    0.       ,    0.       ,\n",
       "            0.       ,    0.       ,    0.       ,    0.       ,\n",
       "            0.       ,    0.       ],\n",
       "        [ -17.301039 ,  100.       ,  -30.674847 ,  -54.945053 ,\n",
       "         -227.27272  ,  -27.855154 , -400.       , -147.05882  ,\n",
       "         -100.       ,  -94.33962  ],\n",
       "        [   0.       ,    0.       ,    0.       ,    0.       ,\n",
       "            0.       ,    0.       ,    0.       ,    0.       ,\n",
       "            0.       ,    0.       ]], dtype=float32),\n",
       " array([[ 0,  1, -1, -2, -1,  0,  0,  0, -2,  1],\n",
       "        [ 0,  1,  0, -1, -1, -1, -1,  0, -1, -2]], dtype=int16),\n",
       " array([-56.49717514,   0.        ]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X,y = items_to_arrays(items)\n",
    "Xc,Xd,y = items_to_arrays(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [(20000, 4, 10),(20000, 2, 10),(20000, 2)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L((Xc,Xd,y)).attrgot('shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 4, 10), (20000, 2, 10), (20000, 2))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xc.shape, Xd.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##use FixedSplitter\n",
    "# splits = [L(range(160000)), L(range(160000,185000))]\n",
    "splits = FixedSplitter()(df_main)\n",
    "# splits = [L(range(1600)), L(range(1600,1850))]\n",
    "tfms  = [None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15 ms, sys: 0 ns, total: 15 ms\n",
      "Wall time: 33.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nsets = NumpyDatasets(Xc[:100], y[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits=TSSplitter()(df_main.iloc[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dsets = TSDatasets3(X=X[:100], y=y[:100], tfms=tfms, splits=splits, inplace=True)\n",
    "dsets = TSDatasets3(X=Xc[:100], X_dis=Xd[:100], y=y[:100], splits=splits, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TSTensor([[  -7.8431,  100.0000,   -6.4977,  -24.5098,  -33.2226,  -42.7350,\n",
       "           -55.2486,  -56.4972,  -30.6748,  100.0000],\n",
       "         [ 100.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000],\n",
       "         [ -17.3010,  100.0000,  -30.6748,  -54.9451, -227.2727,  -27.8552,\n",
       "          -400.0000, -147.0588, -100.0000,  -94.3396],\n",
       "         [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
       "             0.0000,    0.0000,    0.0000,    0.0000]]),\n",
       " TSIntTensor([[ 0,  1, -1, -2, -1,  0,  0,  0, -2,  1],\n",
       "         [ 0,  1,  0, -1, -1, -1, -1,  0, -1, -2]], dtype=torch.int16),\n",
       " tensor([-56.4972,   0.0000]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsets.train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert isinstance(dsets[0][-1], TensorFloat)\n",
    "assert isinstance(dsets[0][0], TSTensor)\n",
    "assert isinstance(dsets[0][1], TSIntTensor)\n",
    "assert isinstance(dsets[0][2], Tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "def _test_dls_type(dls):\n",
    "    ob = dls.one_batch()\n",
    "#     print(len(ob))\n",
    "    xc,y=ob[0],ob[-1]\n",
    "    xd = ob[1] if len(ob)==3 else None\n",
    "    assert isinstance(xc, TSTensor)\n",
    "    assert isinstance(y, Tensor)\n",
    "    if xd is not None: assert isinstance(xd, TSIntTensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "def _test_dls(Xc, y, test=False, X_dis=None):\n",
    "    '''\n",
    "    create timeseries dataloaders and test batch types\n",
    "    parameters:\n",
    "    test: create train,valid,test datasets\n",
    "    X_dis: discrete channels\n",
    "    '''\n",
    "    splits=TSSplitter(test=test)(y)\n",
    "    dsets = TSDatasets3(X=Xc, X_dis=X_dis, y=y, splits=splits, inplace=True)\n",
    "    dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[256, 512], num_workers=0)\n",
    "    _test_dls_type(dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "_test_dls(Xc[:1000], y[:1000])\n",
    "_test_dls(Xc[:1000], y[:1000], test=True)\n",
    "_test_dls(Xc[:1000], y[:1000], X_dis=Xd[:1000], test=False)\n",
    "_test_dls(Xc[:1000], y[:1000], X_dis=Xd[:1000], test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "#standardization\n",
    "#batch size bigger than training set, otherwise batch stats can be off\n",
    "dsets = TSDatasets3(X=Xc[:100], X_dis=Xd, y=y[:100], splits=splits, inplace=True)\n",
    "batch_tfms = [TSStandardize(by_var=True), TSStandardize(by_var=True, discrete=True)]\n",
    "dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[256, 512], num_workers=0, batch_tfms=batch_tfms)\n",
    "\n",
    "xc,xd,y=dls.one_batch()\n",
    "\n",
    "axis=(0,2)\n",
    "assert torch.allclose(xc.mean(axis), torch.zeros_like(xc.mean(axis)), atol=1e-5)\n",
    "assert torch.allclose(xd.mean(axis), torch.zeros_like(xd.mean(axis)), atol=1e-5)\n",
    "assert torch.allclose(xc.std(axis), torch.ones_like(xc.std(axis)))\n",
    "assert torch.allclose(xd.std(axis), torch.ones_like(xd.std(axis)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TSTensor([[[-0.6893, -0.4247, -0.8155,  ..., -1.0551, -0.3370,  1.1285],\n",
       "          [-0.0117, -0.0117, -0.0117,  ..., -0.0117, -0.0117, -0.0117],\n",
       "          [ 1.1373, -0.3002, -2.1141,  ..., -0.4290,  1.1373,  1.1373],\n",
       "          [ 0.0217,  0.0217,  0.0217,  ...,  0.0217,  0.0217,  0.0217]],\n",
       " \n",
       "         [[-0.4409, -0.2637, -0.0917,  ..., -0.0369,  1.1285, -0.1568],\n",
       "          [ 1.2647, -2.5142,  1.2647,  ..., -0.0117, -0.0117, -0.0117],\n",
       "          [ 1.1373,  1.1373, -0.9681,  ...,  1.1373,  1.1373, -0.7068],\n",
       "          [-2.0296,  0.0217,  0.0217,  ...,  0.0217,  0.0217,  0.0217]],\n",
       " \n",
       "         [[ 1.1285, -0.9876,  1.1285,  ..., -0.1383, -0.3074, -1.0060],\n",
       "          [ 2.5410, -2.3322,  2.5410,  ..., -0.0117, -0.0117, -0.0117],\n",
       "          [ 1.1373,  1.1373,  1.1373,  ..., -0.7215, -0.4829, -0.5929],\n",
       "          [ 1.3038,  2.5858,  2.5858,  ...,  0.0217,  0.0217,  0.0217]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.1285, -0.5098, -0.9202,  ..., -0.3545, -0.7742, -0.6172],\n",
       "          [ 2.5410, -3.2428, -0.0117,  ..., -0.0117, -0.0117, -0.0117],\n",
       "          [-0.2848, -0.2928, -0.9507,  ...,  1.1373,  1.1373, -0.6973],\n",
       "          [ 1.3038, -3.1052,  0.0217,  ...,  0.0217,  0.0217,  0.0217]],\n",
       " \n",
       "         [[ 1.1285, -0.4129,  1.1285,  ...,  1.1285, -0.9527, -0.2338],\n",
       "          [-0.0117, -0.0117, -0.0117,  ..., -0.0117, -0.0117, -0.0117],\n",
       "          [ 1.1373, -0.4309, -0.4045,  ..., -0.2848, -0.9593, -0.3546],\n",
       "          [ 0.0217,  0.0217,  0.0217,  ...,  0.0217,  0.0217,  0.0217]],\n",
       " \n",
       "         [[-1.7802, -0.4564, -1.0551,  ..., -0.2128,  1.1285,  1.1285],\n",
       "          [-0.0117, -0.0117, -0.0117,  ..., -0.0117, -0.0117, -0.0117],\n",
       "          [-3.3456, -0.4146,  1.1373,  ..., -0.5425,  1.1373, -0.4852],\n",
       "          [-2.5683,  0.0217,  0.0217,  ...,  0.0217,  0.0217,  0.0217]]],\n",
       "        device='cuda:0'),\n",
       " TSIntTensor([[[-0.6005, -0.6005,  0.0091,  ..., -1.8198, -1.8198,  1.8381],\n",
       "          [ 0.5999, -0.6182, -0.0091,  ..., -1.2273,  1.2090,  0.5999]],\n",
       " \n",
       "         [[ 0.0091, -1.2101, -0.6005,  ..., -1.2101,  0.6188,  0.0091],\n",
       "          [ 0.5999,  1.2090, -1.2273,  ...,  1.2090,  1.8181, -0.0091]],\n",
       " \n",
       "         [[ 1.2284, -0.6005,  1.2284,  ..., -2.4294, -0.6005, -0.6005],\n",
       "          [ 0.5999,  1.8181,  0.5999,  ..., -0.0091, -0.0091, -0.0091]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 1.8381, -0.6005,  0.0091,  ..., -0.6005, -1.2101, -0.6005],\n",
       "          [-0.0091, -0.6182, -0.6182,  ...,  0.5999,  0.5999, -0.6182]],\n",
       " \n",
       "         [[ 1.2284,  0.0091,  1.2284,  ...,  1.8381,  0.0091,  0.0091],\n",
       "          [ 0.5999, -0.0091, -1.2273,  ..., -0.0091, -0.6182, -1.8364]],\n",
       " \n",
       "         [[ 0.0091, -0.6005,  0.0091,  ...,  0.0091,  0.6188,  1.2284],\n",
       "          [-0.0091, -0.6182,  0.5999,  ..., -0.0091,  1.2090, -0.6182]]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ -37.5940,   -0.0000],\n",
       "         [ 100.0000,  100.0000],\n",
       "         [ -49.0196,    0.0000],\n",
       "         [ 100.0000,   -0.0000],\n",
       "         [-111.1111, -113.6364],\n",
       "         [ 100.0000,   -0.0000],\n",
       "         [ -44.2478,   50.0000],\n",
       "         [ -27.7008,  -96.1538],\n",
       "         [ -76.3359,   -0.0000],\n",
       "         [ 100.0000,   -0.0000],\n",
       "         [ 100.0000,  100.0000],\n",
       "         [ 100.0000,   -0.0000],\n",
       "         [ 100.0000,  100.0000],\n",
       "         [ -21.3675,   -0.0000],\n",
       "         [ -52.6316,  -85.4701],\n",
       "         [ 100.0000,  100.0000],\n",
       "         [ 100.0000,   -0.0000],\n",
       "         [ -56.4972,    0.0000],\n",
       "         [ -22.8311,  100.0000],\n",
       "         [ 100.0000,   -0.0000],\n",
       "         [ 100.0000,  100.0000],\n",
       "         [ -21.8818,   -0.0000],\n",
       "         [ 100.0000,  100.0000],\n",
       "         [ 100.0000,  100.0000],\n",
       "         [ 100.0000,  100.0000],\n",
       "         [ -27.6243, -108.6957],\n",
       "         [ -49.0196,   -0.0000],\n",
       "         [ 100.0000,   -0.0000],\n",
       "         [ -94.3396,   -0.0000],\n",
       "         [ -82.6446, -112.3596],\n",
       "         [ -33.3333,  100.0000],\n",
       "         [ -57.1429,   -0.0000],\n",
       "         [ -94.3396,   -0.0000],\n",
       "         [ -21.3220,  -56.8182],\n",
       "         [ -94.3396,   -0.0000],\n",
       "         [ -64.9351,    0.0000],\n",
       "         [-109.8901, -109.8901],\n",
       "         [ -27.5482,   -0.0000],\n",
       "         [ 100.0000,  100.0000],\n",
       "         [ -43.2900,   -0.0000],\n",
       "         [ -25.5754,  100.0000],\n",
       "         [ -29.0698,   -0.0000],\n",
       "         [ -24.0964,  -52.0833],\n",
       "         [ -39.3701,   -0.0000],\n",
       "         [ -73.5294,  -48.0769],\n",
       "         [ -29.6736,   -0.0000],\n",
       "         [ -54.9451,   -0.0000],\n",
       "         [ -52.6316,   -0.0000],\n",
       "         [ 100.0000,   50.0000],\n",
       "         [ 100.0000,  100.0000],\n",
       "         [ -83.3333, -109.8901],\n",
       "         [ -88.4956,  -88.4956],\n",
       "         [ -29.4118,  100.0000],\n",
       "         [ -39.6825,   -0.0000],\n",
       "         [ -92.5926,  -92.5926],\n",
       "         [ -33.4448,  -84.0336],\n",
       "         [ -48.5437,   50.0000],\n",
       "         [ -13.8504,  100.0000],\n",
       "         [ -15.3139,   -0.0000],\n",
       "         [ -58.1395, -113.6364],\n",
       "         [-188.6792,  -84.7458],\n",
       "         [ 100.0000,  100.0000],\n",
       "         [ 100.0000,   -0.0000],\n",
       "         [ 100.0000,    0.0000],\n",
       "         [ 100.0000,   -0.0000],\n",
       "         [-107.5269, -107.5269],\n",
       "         [ -39.3701,  -98.0392],\n",
       "         [  -8.6957,  -89.2857],\n",
       "         [-217.3913,  -80.0000],\n",
       "         [ -69.9301,  -45.8716],\n",
       "         [ -50.7614,   -0.0000],\n",
       "         [ 100.0000,   50.0000],\n",
       "         [-119.0476, -119.0476],\n",
       "         [ -12.0773,  -81.9672],\n",
       "         [ -66.6667,   -0.0000],\n",
       "         [ 100.0000,  100.0000],\n",
       "         [  -5.8928,    0.0000],\n",
       "         [ -14.2857,  100.0000],\n",
       "         [ -29.5858,   -0.0000],\n",
       "         [ -52.0833,    0.0000]], device='cuda:0'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first(dls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TSTensor([[[-1.0761, -0.4409, -1.5308,  ...,  1.1285,  1.1285, -0.2716],\n",
       "          [-0.0117, -0.0117, -0.0117,  ..., -0.0117, -0.0117, -0.0117],\n",
       "          [-0.6790, -0.4146,  1.1373,  ..., -0.4309,  1.1373, -0.4028],\n",
       "          [ 0.0217,  0.0217,  0.0217,  ...,  0.0217,  0.0217,  0.0217]],\n",
       " \n",
       "         [[-0.1614,  1.1285, -0.4751,  ..., -1.5981, -0.1835, -0.1634],\n",
       "          [-2.6432, -0.0117, -0.0117,  ..., -0.0117, -0.0117, -0.0117],\n",
       "          [-0.1988, -0.2716, -0.3979,  ..., -0.5149, -0.2417, -0.3090],\n",
       "          [-2.1330,  0.0217,  0.0217,  ...,  0.0217,  0.0217,  0.0217]],\n",
       " \n",
       "         [[ 1.1285, -0.4977, -0.9202,  ..., -0.5025, -1.4119, -0.5173],\n",
       "          [-0.0117, -0.0117, -0.0117,  ..., -0.0117, -0.0117, -0.0117],\n",
       "          [-0.2443,  1.1373, -0.1544,  ..., -0.4463, -0.3270, -0.2238],\n",
       "          [ 0.0217,  0.0217,  0.0217,  ...,  0.0217,  0.0217,  0.0217]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.6893, -0.1948, -0.4145,  ..., -0.4564, -0.3404, -0.3699],\n",
       "          [-0.0117, -0.0117, -0.0117,  ..., -0.0117, -0.0117, -0.0117],\n",
       "          [-0.6790, -0.4235, -0.6143,  ..., -0.3680,  1.1373,  1.1373],\n",
       "          [ 0.0217,  0.0217,  0.0217,  ...,  0.0217,  0.0217,  0.0217]],\n",
       " \n",
       "         [[-0.4372, -0.1617, -0.0958,  ..., -0.9612,  1.1285, -0.4954],\n",
       "          [-0.0117, -0.0117, -0.0117,  ..., -0.0117, -0.0117, -0.0117],\n",
       "          [-0.0622, -0.5929, -0.1619,  ..., -0.2496, -0.2379, -0.1975],\n",
       "          [ 2.5858,  0.0217,  0.0217,  ...,  0.0217,  0.0217,  0.0217]],\n",
       " \n",
       "         [[-0.4179, -0.8093, -0.3046,  ..., -0.4391,  1.1285, -0.4129],\n",
       "          [-0.0117, -0.0117, -0.0117,  ..., -0.0117, -0.0117, -0.0117],\n",
       "          [-0.3572,  1.1373, -0.2617,  ..., -0.8373,  1.1373, -0.7317],\n",
       "          [ 0.0217,  0.0217,  0.0217,  ...,  0.0217,  0.0217,  0.0217]]],\n",
       "        device='cuda:0'),\n",
       " TSIntTensor([[[-0.6005,  0.0091,  0.0091,  ...,  1.2284,  0.6188,  0.0091],\n",
       "          [-0.0091, -0.6182,  1.2090,  ..., -0.0091,  1.8181, -0.6182]],\n",
       " \n",
       "         [[-1.8198,  1.2284, -0.6005,  ..., -1.2101, -0.6005,  0.0091],\n",
       "          [-0.6182, -0.0091, -0.6182,  ..., -0.0091, -0.6182, -0.6182]],\n",
       " \n",
       "         [[ 1.2284, -1.2101,  0.0091,  ...,  0.0091,  0.0091,  0.0091],\n",
       "          [-0.6182,  0.5999, -1.2273,  ..., -0.6182, -1.8364, -0.0091]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.0091, -1.2101, -1.2101,  ..., -0.6005, -0.6005, -2.4294],\n",
       "          [-0.6182, -0.6182, -0.0091,  ..., -1.2273,  1.2090,  0.5999]],\n",
       " \n",
       "         [[-1.2101, -1.8198,  0.0091,  ..., -1.2101,  0.6188, -0.6005],\n",
       "          [-0.0091, -0.6182, -1.2273,  ..., -0.6182, -0.6182, -0.0091]],\n",
       " \n",
       "         [[-1.8198, -0.6005, -1.2101,  ..., -1.2101,  1.2284, -0.6005],\n",
       "          [-0.6182,  0.5999, -0.6182,  ..., -0.6182,  0.5999, -0.0091]]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ -54.9451,   -0.0000],\n",
       "         [ -12.0773,  -81.9672],\n",
       "         [ 100.0000,   -0.0000],\n",
       "         [ -92.5926,  -92.5926],\n",
       "         [ 100.0000,  100.0000],\n",
       "         [ 100.0000,   -0.0000],\n",
       "         [ -66.6667,   -0.0000],\n",
       "         [ 100.0000,  100.0000],\n",
       "         [ -27.6243, -108.6957],\n",
       "         [ -13.8504,  100.0000],\n",
       "         [ 100.0000,  100.0000],\n",
       "         [ 100.0000,   -0.0000],\n",
       "         [-188.6792,  -84.7458],\n",
       "         [ 100.0000,   -0.0000],\n",
       "         [-119.0476, -119.0476],\n",
       "         [ -82.6446, -112.3596],\n",
       "         [ -21.3675,   -0.0000],\n",
       "         [-217.3913,  -80.0000],\n",
       "         [ -21.3220,  -56.8182],\n",
       "         [ -64.9351,    0.0000],\n",
       "         [ -48.5437,   50.0000],\n",
       "         [ -73.5294,  -48.0769],\n",
       "         [ -39.6825,   -0.0000],\n",
       "         [ -39.3701,   -0.0000],\n",
       "         [ -49.0196,   -0.0000],\n",
       "         [ -56.4972,    0.0000],\n",
       "         [ 100.0000,   -0.0000],\n",
       "         [ 100.0000,  100.0000],\n",
       "         [ -58.1395, -113.6364],\n",
       "         [ 100.0000,  100.0000],\n",
       "         [ -14.2857,  100.0000],\n",
       "         [ 100.0000,  100.0000],\n",
       "         [ -83.3333, -109.8901],\n",
       "         [ -29.5858,   -0.0000],\n",
       "         [ -44.2478,   50.0000],\n",
       "         [ -29.0698,   -0.0000],\n",
       "         [  -5.8928,    0.0000],\n",
       "         [ -52.0833,    0.0000],\n",
       "         [ -25.5754,  100.0000],\n",
       "         [ -52.6316,  -85.4701],\n",
       "         [ -29.4118,  100.0000],\n",
       "         [-111.1111, -113.6364],\n",
       "         [ 100.0000,  100.0000],\n",
       "         [ -43.2900,   -0.0000],\n",
       "         [ -39.3701,  -98.0392],\n",
       "         [ 100.0000,  100.0000],\n",
       "         [ -33.3333,  100.0000],\n",
       "         [ -27.7008,  -96.1538],\n",
       "         [ -69.9301,  -45.8716],\n",
       "         [ -88.4956,  -88.4956],\n",
       "         [ -33.4448,  -84.0336],\n",
       "         [-109.8901, -109.8901],\n",
       "         [ 100.0000,   50.0000],\n",
       "         [ -22.8311,  100.0000],\n",
       "         [ -76.3359,   -0.0000],\n",
       "         [-107.5269, -107.5269],\n",
       "         [  -8.6957,  -89.2857],\n",
       "         [ 100.0000,  100.0000],\n",
       "         [ 100.0000,  100.0000],\n",
       "         [ -94.3396,   -0.0000],\n",
       "         [ -50.7614,   -0.0000],\n",
       "         [ -49.0196,    0.0000],\n",
       "         [ 100.0000,   -0.0000],\n",
       "         [ -37.5940,   -0.0000],\n",
       "         [ 100.0000,  100.0000],\n",
       "         [ -52.6316,   -0.0000],\n",
       "         [ -94.3396,   -0.0000],\n",
       "         [ -94.3396,   -0.0000],\n",
       "         [ -29.6736,   -0.0000],\n",
       "         [ 100.0000,   -0.0000],\n",
       "         [ -27.5482,   -0.0000],\n",
       "         [ 100.0000,    0.0000],\n",
       "         [ 100.0000,   -0.0000],\n",
       "         [ -24.0964,  -52.0833],\n",
       "         [ 100.0000,   50.0000],\n",
       "         [ 100.0000,  100.0000],\n",
       "         [ 100.0000,   -0.0000],\n",
       "         [ -15.3139,   -0.0000],\n",
       "         [ -21.8818,   -0.0000],\n",
       "         [ -57.1429,   -0.0000]], device='cuda:0'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test assignment works\n",
    "dls.train = dls.train.new(bs=4)\n",
    "assert dls.train.one_batch()[0].shape[0]==4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "#basic modelling\n",
    "model = InceptionTimeD(6,2)\n",
    "loss_fn = get_loss_fn('leaky_loss', alpha=0.5)\n",
    "learn_small = Learner(model=model, loss_func=loss_fn, dls=dls, metrics=unweighted_profit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>unweighted_profit</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.002952</td>\n",
       "      <td>-0.282860</td>\n",
       "      <td>0.774638</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.333843</td>\n",
       "      <td>-0.302086</td>\n",
       "      <td>1.147772</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-2.719226</td>\n",
       "      <td>-0.288546</td>\n",
       "      <td>1.147772</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-5.514769</td>\n",
       "      <td>-0.275979</td>\n",
       "      <td>-4.462143</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-8.043970</td>\n",
       "      <td>-0.277527</td>\n",
       "      <td>0.827712</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_small.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = learn_small.get_preds(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load data frame\n",
    "- (create a configuration: x_cols, y_cols [n_train optional]) read config in from configs module\n",
    "- create X,y from df and configuration\n",
    "- create splits and transforms\n",
    "- create dsets\n",
    "- define batch tranforms\n",
    "- create dls from datasets\n",
    "- define loss and model\n",
    "- create Learner -> learn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nbdev]",
   "language": "python",
   "name": "conda-env-nbdev-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
