{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#hide\n",
    "import torch.nn.functional as F\n",
    "import torch as torch\n",
    "from functools import partial\n",
    "from fastai.basics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def test():\n",
    "    '''a test function'''\n",
    "    print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def leaky_loss(preds, y_true, alpha=0.05):\n",
    "    '''\n",
    "    objective function, including negative predictions with factor alpha\n",
    "    '''\n",
    "    loss_1 = (F.leaky_relu(preds, alpha).squeeze()*y_true.float()).mean()*(-1)\n",
    "    #loss_1.requires_grad_()\n",
    "    #assert loss_1.requires_grad == True\n",
    "    # loss_1.requires_grad_(True)\n",
    "    return loss_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.tensor([-0.5, 0.7, 0.2, -1.5])\n",
    "y_true = torch.tensor([100., 100., 100., 100.])\n",
    "assert leaky_loss(preds, y_true) == (-0.5*100*0.05 + 0.7*100 + 0.2*100 + -1.5*100*0.05)/(4*-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_2d = torch.tensor([[100., -90.], [-420., -110], [100.,100.], [-96., 100.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_2d.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(42.0625)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(F.leaky_relu(preds, 0.5)*y_true_2d.T).mean()*(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([0.7, 0.3])[:, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -50.0000, -588.0000,   40.0000,  144.0000],\n",
       "        [  11.2500,  -38.5000,   10.0000,  -37.5000]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(F.leaky_relu(preds, 0.5)*y_true_2d.T)*torch.tensor([2, 0.5])[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-71.2156)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((F.leaky_relu(preds, 0.05)*y_true_2d.T)*torch.tensor([2, 0.5])[:, None]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def leaky_loss_2d(preds, y_true, alpha=0.05, weights=None):\n",
    "    '''\n",
    "    objective function, including negative predictions with factor alpha\n",
    "    weights: target variable weights\n",
    "    '''\n",
    "    assert len(y_true.shape)==2, 'y_true needs to be 2d'\n",
    "     # weight of the first y-value\n",
    "    prod = (F.leaky_relu(preds, alpha).squeeze()*y_true.float())\n",
    "    print(prod)\n",
    "    if weights:\n",
    "        prod.mul_(torch.tensor(weights)[:, None])\n",
    "#     print(prod)\n",
    "    loss_1 = prod.mean()*(-1)\n",
    "    loss_1.requires_grad_(True)\n",
    "    return loss_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert torch.allclose(leaky_loss_2d(preds, y_true_2d), (F.leaky_relu(preds, 0.05)*y_true_2d.T).mean()*(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leaky_loss_2d(preds, y_true_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leaky_loss_2d(preds, y_true_2d, weight=[1.,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leaky_loss_2d(preds, y_true_2d, weight=[1.,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=torch.tensor([1., 2.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.mul_(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-0.5*100*0.05 + 0.7*100 + 0.2*100 + -1.5*100*0.05)/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def one_hot(t, k=5):\n",
    "    '''\n",
    "    one-hot enconcoding of t with k values\n",
    "    '''\n",
    "    ohc = torch.zeros(t.shape[0], k)\n",
    "    ohc[range(t.shape[0]), t]=1\n",
    "    return ohc.to(t.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def create_rww_categorical_crossentropy(k, loss_type, fn_weights=None, fp_weights=None, return_weights=False):\n",
    "    \"\"\"Real-World-Weighted crossentropy between an output tensor and a target tensor.\n",
    "\n",
    "    The loss_types other than rww_categorical_crossentropy reimplement existing \n",
    "    functions in Keras but are not as well optimized. \n",
    "    These loss_types are usable directly, but, are more useful when calling \n",
    "    return_weights=True, which then returns fn and fp weights matrixes of size (k,k). \n",
    "    Editing those to reflect real world costs, then passing them back into \n",
    "    create_rww_crossentropy with loss_type \"rww_crossentropy\" is the recommended approach. \n",
    "\n",
    "    Example Usage: \n",
    "\n",
    "    Suppose you have three classes: cat, dog, and other.\n",
    "\n",
    "    Cat is one-hot encoded as [1,0,0], dog as [0,1,0], other as [0,0,1]\n",
    "\n",
    "    The the following code increases the incremental penalty of \n",
    "    mislabeling a true target 0 (cat) with a false label 1 (dog) at a cost of 99, \n",
    "    versus the default of zero. Note that the existing fn_weights also has a \n",
    "    default cost of 1 for missing the true target of 1, for a total cost of \n",
    "    100 versus the default cost of 1. \n",
    "\n",
    "    fn_weights, fp_weights = create_rww_categorical_crossentropy(10, \"categorical_crossentropy\", return_weights=True)\n",
    "    fp_weights[0, 1] = 99\n",
    "    loss = create_rww_categorical_crossentropy(10, \"rww_crossentropy\", fn_weights, fp_weights)\n",
    "\n",
    "    ... \n",
    "\n",
    "    The fn and fp weights are easy to reason about. \n",
    "\n",
    "    fn_weights is [x1, __, __]\n",
    "                [__, x2, __]\n",
    "                [__, __, x3]\n",
    "\n",
    "    x1 represents the scale of the cost for a fn for cat, x2 for dog, and x3 for other.\n",
    "\n",
    "    This is calculated as fn_weight * log(y_pred). \n",
    "\n",
    "    In the case of loss_type=categorical_crossentropy, \n",
    "    x1, x2, and x3 all equal the value one. \n",
    "    All elements not on the main axis must equal zero. \n",
    "\n",
    "    Note that fn_weights could have been represented as a vector, \n",
    "    not a matrix, however, we use a matrix to keep symmetry with \n",
    "    fp_weights, and, to prepare for \n",
    "    multi-label classification. \n",
    "\n",
    "    ...\n",
    "\n",
    "    fp_weights is concerned with the costs of the fps from the other classes. \n",
    "\n",
    "    fp_weights of [__, x1, x2]\n",
    "                [x3, __, x4]\n",
    "                [x5, x6, __]\n",
    "\n",
    "    x1 represents the cost of predicting 1 for dog, when it should be 0 for cat. \n",
    "    x2 represents predicting 2 for other, when the target is 0 for cat. \n",
    "    x3 represents predicing 0 for cat, when the target is 1 for dog.\n",
    "    etc. \n",
    "\n",
    "    Args:\n",
    "    * k: 2 or more for number of categories, including \"other\". \n",
    "    * loss_type: \"categorical_crossentropy\" to initialize to \n",
    "      standard softmax_crossentropy behavior, \n",
    "      or \"weighted_categorical_crossentropy\" for standard behavior, or, \n",
    "      or \"rww_crossentropy\" for full weight matrix of all possible fn/fp combinations. \n",
    "    * fn_weights: a numpy array of shape (k,k). The main diagonal can\n",
    "      contain non-zero values; all other values must be zero. \n",
    "    * fp_weights: a numpy array of shape (k,k) to define specific combinations \n",
    "      of false positive. The main diag should be zeros. \n",
    "    * return_weights: If False (default), returns cost function. If True, \n",
    "      returns fn and fp weights as np.array. \n",
    "    Returns:\n",
    "    * retval: Loss function for use Keras.model.fit, or if return_weights\n",
    "      arg is True, the fn_weights and fp_weights matrixes. \n",
    "    \"\"\"\n",
    "\n",
    "    full_fn_weights = None\n",
    "    full_fp_weights = None\n",
    "\n",
    "    anti_eye = np.ones((k,k)) - np.eye(k)\n",
    "\n",
    "    if (loss_type==\"categorical_crossentropy\"):\n",
    "        full_fn_weights = np.identity((k))\n",
    "        full_fp_weights = np.zeros((k, k)) # Softmax crossentropy ignores fp.\n",
    "\n",
    "    elif(loss_type==\"weighted_categorical_crossentropy\"):\n",
    "        full_fn_weights = np.eye(k) * fn_weights\n",
    "        full_fp_weights = np.zeros((k, k)) # softmax crossentropy ignores fp\n",
    "\n",
    "    elif(loss_type==\"rww_crossentropy\"):\n",
    "#         assert not np.count_nonzero(fn_weights * anti_eye)\n",
    "#         assert not np.count_nonzero(fp_weights * np.eye(k))\n",
    "\n",
    "        full_fn_weights = fn_weights\n",
    "        # Novel piece: allow any combination of fp.\n",
    "        full_fp_weights = fp_weights\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"unknown loss_type: \" + str(loss_type))\n",
    "\n",
    "        \n",
    "    fn_wt = tensor(full_fn_weights)\n",
    "    fp_wt = tensor(full_fp_weights)\n",
    "#     fn_wt = K.constant(full_fn_weights) # (k,k), always sparse along main diag. \n",
    "#     fp_wt = K.constant(full_fp_weights) # (k,k), always dense except main diag. \n",
    "\n",
    "    def loss_function(preds, y_true):\n",
    "        '''\n",
    "        '''\n",
    "#     output = torch.clip(output, K.epsilon(), 1 - K.epsilon()) \n",
    "        output = F.log_softmax(preds, dim=-1)\n",
    "        target = one_hot(y_true)\n",
    "    \n",
    "    \n",
    "        logs = output\n",
    "        logs_1_sub  = (1-F.softmax(preds, dim=-1)).log()    #     logs = K.log(output) # shape (m, k), dense. 1 is good. \n",
    "    #     logs_1_sub = K.log(1-output) # shape (m, k), dense. 0 is good. \n",
    "#         print(target.shape, fp_wt.shape)\n",
    "        m_full_fn_weights = target.matmul(fn_wt) # (m,k) . (k, k)\n",
    "        m_full_fp_weights = target.matmul(fp_wt) # (m,k) . (k, k)\n",
    "\n",
    "        return - torch.mean(m_full_fn_weights * logs + \n",
    "                        m_full_fp_weights * logs_1_sub)\n",
    "\n",
    "    if (return_weights):\n",
    "        return full_fn_weights, full_fp_weights\n",
    "    else:\n",
    "        return loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = tensor([0.25, 0.5, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3863, -0.6931, -1.3863])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2877, -0.6931, -0.2877])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-op).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ahc_fp_weights(w=10):\n",
    "    '''\n",
    "    rww weight matrix for false positives\n",
    "    tensor([[ 0.,  0.,  1., 10.,  1.],\n",
    "        [ 0.,  0.,  1., 10.,  1.],\n",
    "        [ 1.,  1.,  0.,  1.,  1.],\n",
    "        [10., 10.,  1.,  0.,  0.],\n",
    "        [10., 10.,  1.,  0.,  0.]])\n",
    "    '''\n",
    "    fp_w = torch.ones(5,5)\n",
    "    for i in range(5):\n",
    "        fp_w[i,i] = 0\n",
    "    fp_w[0,1]=0\n",
    "    fp_w[0,3]=w\n",
    "    fp_w[0,3]=w\n",
    "    fp_w[1,0]=0\n",
    "    fp_w[1,3]=w\n",
    "    fp_w[1,3]=w\n",
    "    fp_w[3,4]=0\n",
    "    fp_w[3,0]=w\n",
    "    fp_w[3,1]=w\n",
    "    fp_w[4,3]=0\n",
    "    fp_w[4,0]=w\n",
    "    fp_w[4,1]=w\n",
    "    return fp_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1926, 0.1799, 0.2859, 0.1309, 0.2107],\n",
       "        [0.2236, 0.2554, 0.1256, 0.1980, 0.1974],\n",
       "        [0.1238, 0.1867, 0.1799, 0.2611, 0.2485],\n",
       "        [0.1782, 0.2636, 0.1266, 0.1480, 0.2836],\n",
       "        [0.2278, 0.2135, 0.1423, 0.1430, 0.2733],\n",
       "        [0.1645, 0.1544, 0.2719, 0.1887, 0.2205],\n",
       "        [0.1783, 0.1475, 0.1925, 0.3418, 0.1399],\n",
       "        [0.2581, 0.1326, 0.2680, 0.1872, 0.1542],\n",
       "        [0.1447, 0.2308, 0.1636, 0.1756, 0.2853],\n",
       "        [0.2735, 0.1660, 0.1259, 0.1645, 0.2701],\n",
       "        [0.2254, 0.2459, 0.1607, 0.2058, 0.1622],\n",
       "        [0.1556, 0.2099, 0.1379, 0.2205, 0.2761]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.to()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ahc_rww_loss(weight=tensor([1.,10.,1.,10.,1.]), w=10):\n",
    "#     fp_weights = ahc_fp_weights().to(default_device())\n",
    "    fp_weights = ahc_fp_weights()\n",
    "#     fn_weights = (weight*torch.eye(5)).to(default_device())\n",
    "    fn_weights = (weight*torch.eye(5))\n",
    "#     print(fn_weights)\n",
    "    fp=fp_weights.to(default_device())\n",
    "    fn=fn_weights.to(default_device())\n",
    "    loss = create_rww_categorical_crossentropy(5, 'rww_crossentropy',\n",
    "                                               return_weights=False, fn_weights=fn, \n",
    "                                               fp_weights=fp)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ahc_rww_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = F.softmax(torch.rand((12,5)), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.randint(5, (12,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.7196, device='cuda:0')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(preds.to(default_device()), targets.to(default_device())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-39-1da1db7d5c04>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-39-1da1db7d5c04>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    loss(preds, targets), CrossEntropyLossFlat()(preds.to(default_device(), targets.to(default_device())\u001b[0m\n\u001b[0m                                                                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "CrossEntropyLossFlat()(preds.to(default_device(), targets.to(default_device()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def unweighted_profit(preds, y_true, threshold=0):\n",
    "    '''\n",
    "    metric, negative predictions ignored, y_true of positive predictions equally weighted\n",
    "    '''\n",
    "    m_value = ((preds.squeeze()>threshold).float()*y_true.float()).mean()\n",
    "    return m_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def unweighted_profit_05(preds, y_true, threshold=0.5):\n",
    "    '''\n",
    "    metric, negative predictions ignored, y_true of positive predictions equally weighted\n",
    "    '''\n",
    "    m_value = ((preds.squeeze()>threshold).float()*y_true.float()).mean()\n",
    "    return m_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert unweighted_profit(preds, y_true) == (-0.5*100*0 + 1*100 + 1*100 + -1.5*100*0)/(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def weighted_profit(preds, y_true, threshold=0):\n",
    "    '''\n",
    "    metric, negative predictions ignored, results weighted by positive predictions\n",
    "    adding threshold possible\n",
    "    '''\n",
    "    loss_1 = ((preds.squeeze()>threshold).float()*(preds.squeeze())*y_true.float()).mean()\n",
    "    return loss_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert weighted_profit(preds, y_true) == (-0.5*100*0 + 0.7*100 + 0.2*100 + -1.5*100*0)/(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_loss_fn(loss_fn_name, **kwargs):\n",
    "    '''\n",
    "    wrapper to create a partial with a more convenient __name__ attribute\n",
    "    '''\n",
    "    if loss_fn_name == 'leaky_loss':\n",
    "        assert kwargs.get('alpha', None) is not None, 'need to specify alpha with leaky_loss'\n",
    "        _loss_fn = partial(leaky_loss, alpha=kwargs['alpha'])\n",
    "        _loss_fn.__name__ = loss_fn_name\n",
    "        return _loss_fn\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'leaky_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-c5a50ba0bac0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mget_loss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'leaky_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mleaky_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-7f7f7d148c47>\u001b[0m in \u001b[0;36mget_loss_fn\u001b[0;34m(loss_fn_name, **kwargs)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mloss_fn_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'leaky_loss'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'alpha'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'need to specify alpha with leaky_loss'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0m_loss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleaky_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alpha'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0m_loss_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_loss_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'leaky_loss' is not defined"
     ]
    }
   ],
   "source": [
    "assert get_loss_fn('leaky_loss', alpha=0.5)(preds, y_true) == leaky_loss(preds, y_true, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_loss_fn_class(loss_fn_name, weight=None):\n",
    "    '''\n",
    "    loss function buildier for classification tasks\n",
    "    '''\n",
    "#     weights = tensor([1., 10., 1, .10, 1.])\n",
    "    if loss_fn_name == 'rww': return ahc_rww_loss()\n",
    "    else:\n",
    "        print(f'crosse entropy weigts {weight}')\n",
    "        return CrossEntropyLossFlat() if weight is None else CrossEntropyLossFlat(weight=weight.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#fastcore.foundations\n",
    "def is_array(x): return hasattr(x,'__array__') or hasattr(x,'iloc')\n",
    "def listify(o):\n",
    "    if o is None: return []\n",
    "    if isinstance(o, list): return o\n",
    "    if isinstance(o, str) or is_array(o): return [o]\n",
    "    if is_iter(o): return list(o)\n",
    "    return [o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def map_xs(xs, xs_mask):\n",
    "    '''\n",
    "    xs: i-tuple of tensors\n",
    "    xs_mask: length j>=i mask\n",
    "    xs_id: lenght j>=i string list of x identifiers \n",
    "    '''\n",
    "    assert np.array(xs_mask).sum()==len(xs)\n",
    "    res = np.array([None]*len(xs_mask))\n",
    "    res[np.where(xs_mask)[0]]=xs\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def FixedSplitter(end_train=10000, end_valid=15000):\n",
    "    def _inner(o, **kwargs):\n",
    "        return L(range(0, end_train)), L(range(end_train, end_valid))\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def TSSplitter(train_perc=0.8, test=False):\n",
    "    def _inner(o, **kwargs):\n",
    "        l = len(o)\n",
    "        end_train = int(l*train_perc)\n",
    "        end_val = l if not test else int(l*(train_perc+(1-train_perc)*0.5))\n",
    "        end_test = l\n",
    "        if test: return L(range(end_train), range(end_train, end_val), range(end_val, end_test))\n",
    "        return L(range(end_train), range(end_train, end_val))\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = [1]*1000\n",
    "splits = TSSplitter()\n",
    "splits_test = TSSplitter(test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [range(0, 800),range(800, 900),range(900, 1000)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits_test(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [range(0, 800),range(800, 1000)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ttools]",
   "language": "python",
   "name": "conda-env-ttools-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
